#!/usr/bin/env python3
"""
DCMNet Training Script for CO2 ESP Data

This script trains a DCMNet model on the preclassified CO2 ESP data
generated by fix_and_split_cli.py. It predicts electrostatic potentials
using distributed multipoles.

Usage:
    python trainer.py --train-efd ../preclassified_data/energies_forces_dipoles_train.npz \
                      --train-grid ../preclassified_data/grids_esp_train.npz \
                      --valid-efd ../preclassified_data/energies_forces_dipoles_valid.npz \
                      --valid-grid ../preclassified_data/grids_esp_valid.npz
    
    # Or with custom settings:
    python trainer.py --train-efd ../preclassified_data/energies_forces_dipoles_train.npz \
                      --train-grid ../preclassified_data/grids_esp_train.npz \
                      --valid-efd ../preclassified_data/energies_forces_dipoles_valid.npz \
                      --valid-grid ../preclassified_data/grids_esp_valid.npz \
                      --batch-size 16 \
                      --epochs 500 \
                      --n-dcm 3
"""

import sys
import argparse
from pathlib import Path
import numpy as np
import pickle
from typing import Dict, Tuple

# Add mmml to path
repo_root = Path(__file__).parent / "../../.."
sys.path.insert(0, str(repo_root.resolve()))

import jax
import jax.numpy as jnp
from mmml.dcmnet.dcmnet.modules import MessagePassingModel
from mmml.dcmnet.dcmnet.training import train_model
from mmml.dcmnet.dcmnet.data import prepare_datasets


def load_co2_data(efd_file: Path, grid_file: Path) -> Dict:
    """
    Load CO2 data from NPZ files and prepare for DCMnet training.
    
    Parameters
    ----------
    efd_file : Path
        Path to energies_forces_dipoles NPZ file
    grid_file : Path
        Path to grids_esp NPZ file
        
    Returns
    -------
    Dict
        Combined data dictionary with all required keys
    """
    efd_data = np.load(efd_file)
    grid_data = np.load(grid_file)
    
    # Combine into single dictionary
    data = {
        'R': grid_data['R'],  # Atomic coordinates [Angstrom]
        'Z': grid_data['Z'],  # Atomic numbers
        'N': grid_data['N'],  # Number of atoms
        'esp': grid_data['esp'],  # ESP values [Hartree/e]
        'vdw_surface': grid_data['vdw_surface'],  # Grid coords [Angstrom]
        'Dxyz': grid_data.get('Dxyz', efd_data['Dxyz']),  # Dipoles [Debye]
    }
    
    # Also include energies if available for reference
    if 'E' in efd_data:
        data['E'] = efd_data['E']
    
    return data


def main():
    parser = argparse.ArgumentParser(
        description="Train DCMNet on CO2 ESP data",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # Data arguments
    parser.add_argument(
        '--train-efd',
        type=Path,
        required=True,
        help='Path to training EFD NPZ file'
    )
    parser.add_argument(
        '--train-grid',
        type=Path,
        required=True,
        help='Path to training grid NPZ file'
    )
    parser.add_argument(
        '--valid-efd',
        type=Path,
        required=True,
        help='Path to validation EFD NPZ file'
    )
    parser.add_argument(
        '--valid-grid',
        type=Path,
        required=True,
        help='Path to validation grid NPZ file'
    )
    
    # Model hyperparameters
    parser.add_argument('--features', '--n-feat', type=int, default=32,
                       help='Number of features per atom')
    parser.add_argument('--max-degree', type=int, default=2,
                       help='Maximum spherical harmonic degree')
    parser.add_argument('--num-iterations', '--n-mp', type=int, default=2,
                       help='Number of message passing iterations')
    parser.add_argument('--num-basis-functions', '--n-basis', type=int, default=32,
                       help='Number of radial basis functions')
    parser.add_argument('--cutoff', type=float, default=10.0,
                       help='Cutoff distance in Angstroms')
    parser.add_argument('--n-dcm', type=int, default=3,
                       help='Number of distributed multipoles per atom')
    parser.add_argument('--include-pseudotensors', action='store_true',
                       help='Include pseudotensor features')
    
    # Training hyperparameters
    parser.add_argument('--batch-size', type=int, default=32,
                       help='Batch size')
    parser.add_argument('--epochs', '--num-epochs', type=int, default=100,
                       help='Number of epochs')
    parser.add_argument('--learning-rate', '--lr', type=float, default=0.001,
                       help='Learning rate')
    parser.add_argument('--esp-weight', '--esp-w', type=float, default=10000.0,
                       help='Weight for ESP loss')
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed')
    
    # Training options
    parser.add_argument('--restart', type=str, default=None,
                       help='Path to restart checkpoint')
    parser.add_argument('--name', type=str, default='co2_dcmnet',
                       help='Experiment name')
    parser.add_argument('--output-dir', type=Path, default=Path('./checkpoints'),
                       help='Output directory for checkpoints')
    parser.add_argument('--print-freq', type=int, default=10,
                       help='Print frequency (batches)')
    parser.add_argument('--save-freq', type=int, default=5,
                       help='Checkpoint save frequency (epochs)')
    parser.add_argument('--verbose', action='store_true', default=True,
                       help='Verbose output')
    
    args = parser.parse_args()
    
    print("="*70)
    print("DCMNet Training - CO2 ESP Data")
    print("="*70)
    
    # Validate input files
    for fname, fpath in [
        ('Train EFD', args.train_efd),
        ('Train Grid', args.train_grid),
        ('Valid EFD', args.valid_efd),
        ('Valid Grid', args.valid_grid)
    ]:
        if not fpath.exists():
            print(f"‚ùå Error: {fname} file not found: {fpath}")
            sys.exit(1)
    
    print(f"\nüìÅ Data Files:")
    print(f"  Train EFD:  {args.train_efd}")
    print(f"  Train Grid: {args.train_grid}")
    print(f"  Valid EFD:  {args.valid_efd}")
    print(f"  Valid Grid: {args.valid_grid}")
    
    # Setup output directory
    args.output_dir.mkdir(exist_ok=True, parents=True)
    print(f"  Output: {args.output_dir / args.name}")
    
    # Load data
    print(f"\n{'#'*70}")
    print("# Loading Data")
    print(f"{'#'*70}")
    
    if args.verbose:
        print(f"\nLoading training data...")
    train_data_raw = load_co2_data(args.train_efd, args.train_grid)
    
    if args.verbose:
        print(f"Loading validation data...")
    valid_data_raw = load_co2_data(args.valid_efd, args.valid_grid)
    
    print(f"\n‚úÖ Data loaded:")
    print(f"  Training samples: {len(train_data_raw['R'])}")
    print(f"  Validation samples: {len(valid_data_raw['R'])}")
    print(f"  Data keys: {list(train_data_raw.keys())}")
    
    # Prepare datasets (convert to DCMnet format with edge lists, etc.)
    print(f"\nPreparing datasets (computing edge lists, etc.)...")
    train_data, valid_data = prepare_datasets(
        train_data_raw,
        valid_data_raw,
        cutoff=args.cutoff,
        batch_size=args.batch_size,
    )
    
    print(f"‚úÖ Datasets prepared")
    print(f"  Training batches: {len(train_data)}")
    print(f"  Validation batches: {len(valid_data)}")
    
    # Build model
    print(f"\n{'#'*70}")
    print("# Building Model")
    print(f"{'#'*70}")
    
    print(f"\nModel hyperparameters:")
    print(f"  Features: {args.features}")
    print(f"  Max degree: {args.max_degree}")
    print(f"  Message passing iterations: {args.num_iterations}")
    print(f"  Basis functions: {args.num_basis_functions}")
    print(f"  Cutoff: {args.cutoff} √Ö")
    print(f"  Distributed multipoles per atom: {args.n_dcm}")
    print(f"  Include pseudotensors: {args.include_pseudotensors}")
    
    model = MessagePassingModel(
        features=args.features,
        max_degree=args.max_degree,
        num_iterations=args.num_iterations,
        num_basis_functions=args.num_basis_functions,
        cutoff=args.cutoff,
        n_dcm=args.n_dcm,
        include_pseudotensors=args.include_pseudotensors,
    )
    
    print(f"\n‚úÖ Model created: DCMNet (n_dcm={args.n_dcm})")
    
    # Training setup
    print(f"\n{'#'*70}")
    print("# Training Setup")
    print(f"{'#'*70}")
    
    print(f"\nTraining hyperparameters:")
    print(f"  Batch size: {args.batch_size}")
    print(f"  Epochs: {args.epochs}")
    print(f"  Learning rate: {args.learning_rate}")
    print(f"  ESP weight: {args.esp_weight}")
    print(f"  Random seed: {args.seed}")
    
    # Load restart parameters if provided
    restart_params = None
    if args.restart:
        print(f"\nüìÇ Loading restart checkpoint: {args.restart}")
        with open(args.restart, 'rb') as f:
            restart_params = pickle.load(f)
        print(f"‚úÖ Checkpoint loaded")
    
    # Initialize JAX random key
    key = jax.random.PRNGKey(args.seed)
    
    # Start training
    print(f"\n{'='*70}")
    print("STARTING TRAINING")
    print(f"{'='*70}\n")
    
    try:
        final_params = train_model(
            key=key,
            model=model,
            train_data=train_data,
            valid_data=valid_data,
            num_epochs=args.epochs,
            learning_rate=args.learning_rate,
            batch_size=args.batch_size,
            esp_w=args.esp_weight,
            restart_params=restart_params,
            name=args.name,
            output_dir=args.output_dir,
            print_freq=args.print_freq,
            save_freq=args.save_freq,
        )
        
        # Save final model
        final_path = args.output_dir / f"{args.name}_final.pkl"
        with open(final_path, 'wb') as f:
            pickle.dump(final_params, f)
        
        print(f"\n{'='*70}")
        print("‚úÖ TRAINING COMPLETE!")
        print(f"{'='*70}")
        print(f"\nFinal parameters saved to: {final_path}")
        print(f"\nTo use the trained model:")
        print(f"  from mmml.dcmnet.dcmnet.modules import MessagePassingModel")
        print(f"  import pickle")
        print(f"  ")
        print(f"  # Load parameters")
        print(f"  with open('{final_path}', 'rb') as f:")
        print(f"      params = pickle.load(f)")
        print(f"  ")
        print(f"  # Create model and predict")
        print(f"  model = MessagePassingModel(...)")
        print(f"  mono, dipo = model.apply(params, Z, R, dst_idx, src_idx)")
        print(f"  ")
        print(f"  # Calculate ESP")
        print(f"  from mmml.dcmnet.dcmnet.electrostatics import calc_esp")
        print(f"  esp_pred = calc_esp(mono, dipo, R, vdw_surface)")
        
    except KeyboardInterrupt:
        print(f"\n\n‚ö†Ô∏è  Training interrupted by user")
        print(f"Checkpoints saved to: {args.output_dir}")
        sys.exit(0)
    except Exception as e:
        print(f"\n\n‚ùå Training failed with error:")
        print(f"  {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

