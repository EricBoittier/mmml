{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce1a70c-eea0-43eb-a14b-e0433adb80e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovely_jax enabled for enhanced array visualization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CudaDevice(id=0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import *\n",
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3e1440-6d11-48d1-a104-299ce80d8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookArgs:\n",
    "    \"\"\"\n",
    "    Helper class to mimic argparse.Namespace for Jupyter notebooks.\n",
    "    Example:\n",
    "        args = NotebookArgs(\n",
    "            train_efd=\"../preclassified_data/energies_forces_dipoles_train.npz\",\n",
    "            train_grid=\"../preclassified_data/grids_esp_train.npz\",\n",
    "            valid_efd=\"../preclassified_data/energies_forces_dipoles_valid.npz\",\n",
    "            valid_grid=\"../preclassified_data/grids_esp_valid.npz\",\n",
    "            batch_size=16,\n",
    "            epochs=500,\n",
    "            n_dcm=3,\n",
    "            verbose=True,\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # Default values ‚Äî should match argparse defaults\n",
    "        defaults = dict(\n",
    "            train_efd=None,\n",
    "            train_grid=None,\n",
    "            valid_efd=None,\n",
    "            valid_grid=None,\n",
    "            features=128,\n",
    "            max_degree=3,\n",
    "            num_iterations=2,\n",
    "            num_basis_functions=128,\n",
    "            cutoff=10.0,\n",
    "            n_dcm=6,\n",
    "            include_pseudotensors=False,\n",
    "            batch_size=1000,\n",
    "            epochs=100,\n",
    "            learning_rate=0.001,\n",
    "            esp_weight=10000.0,\n",
    "            seed=42,\n",
    "            restart=None,\n",
    "            name='co2_dcmnet',\n",
    "            output_dir='./checkpoints',\n",
    "            print_freq=10,\n",
    "            save_freq=5,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # Update defaults with user-specified values\n",
    "        defaults.update(kwargs)\n",
    "\n",
    "        # Assign all attributes\n",
    "        for key, val in defaults.items():\n",
    "            setattr(self, key, val)\n",
    "\n",
    "    def as_dict(self):\n",
    "        \"\"\"Return arguments as a plain dict (useful for logging).\"\"\"\n",
    "        return vars(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f86473-7bf8-4fa8-8739-f3f5e02d052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import main, load_co2_data\n",
    "\n",
    "\n",
    "args = NotebookArgs(\n",
    "    train_efd=Path(\"../preclassified_data/energies_forces_dipoles_train.npz\"),\n",
    "    train_grid=Path(\"../preclassified_data/grids_esp_train.npz\"),\n",
    "    valid_efd=Path(\"../preclassified_data/energies_forces_dipoles_valid.npz\"),\n",
    "    valid_grid=Path(\"../preclassified_data/grids_esp_valid.npz\"),\n",
    "    output_dir=Path(\"./output\"),\n",
    "    batch_size=1000,\n",
    "    epochs=5000,\n",
    "    learning_rate=5e-4,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0be27f-d4ce-4eba-a2fb-1a2484038baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can call your functions directly\n",
    "train_data = load_co2_data(args.train_efd, args.train_grid)\n",
    "valid_data = load_co2_data(args.valid_efd, args.valid_grid)\n",
    "\n",
    "# Or if your `main()` function expects args like from argparse:\n",
    "# \n",
    "\n",
    "len(valid_data[\"R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34194dd0-de56-4c42-8bcf-5131b122eda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "train_model(\n",
       "    key,\n",
       "    model,\n",
       "    train_data,\n",
       "    valid_data,\n",
       "    num_epochs,\n",
       "    learning_rate,\n",
       "    batch_size,\n",
       "    writer,\n",
       "    ndcm,\n",
       "    esp_w=\u001b[32m1.0\u001b[39m,\n",
       "    chg_w=\u001b[32m0.01\u001b[39m,\n",
       "    restart_params=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    ema_decay=\u001b[32m0.999\u001b[39m,\n",
       "    num_atoms=\u001b[32m60\u001b[39m,\n",
       "    use_grad_clip=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    grad_clip_norm=\u001b[32m2.0\u001b[39m,\n",
       "    mono_imputation_fn=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    distance_weighting=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    distance_scale=\u001b[32m2.0\u001b[39m,\n",
       "    distance_min=\u001b[32m0.5\u001b[39m,\n",
       "    esp_magnitude_weighting=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    charge_conservation_w=\u001b[32m1.0\u001b[39m,\n",
       "    esp_grid_units=\u001b[33m'angstrom'\u001b[39m,\n",
       "    radii_cutoff_multiplier=\u001b[32m2.0\u001b[39m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Train DCMNet model with ESP and monopole losses.\n",
       "\n",
       "Performs full training loop with validation, logging, and checkpointing.\n",
       "Uses exponential moving average (EMA) for parameter smoothing and saves\n",
       "best parameters based on validation loss.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "key : jax.random.PRNGKey\n",
       "    Random key for training\n",
       "model : MessagePassingModel\n",
       "    DCMNet model instance\n",
       "train_data : dict\n",
       "    Training dataset dictionary\n",
       "valid_data : dict\n",
       "    Validation dataset dictionary\n",
       "num_epochs : int\n",
       "    Number of training epochs\n",
       "learning_rate : float\n",
       "    Learning rate for optimization\n",
       "batch_size : int\n",
       "    Batch size for training\n",
       "writer : SummaryWriter\n",
       "    TensorBoard writer for logging\n",
       "ndcm : int\n",
       "    Number of distributed multipoles per atom\n",
       "esp_w : float, optional\n",
       "    Weight for ESP loss term, by default 1.0\n",
       "chg_w : float, optional\n",
       "    Weight for charge/monopole loss term, by default 0.01\n",
       "restart_params : Any, optional\n",
       "    Parameters to restart from, by default None\n",
       "ema_decay : float, optional\n",
       "    Exponential moving average decay rate, by default 0.999\n",
       "num_atoms : int, optional\n",
       "    Maximum number of atoms for batching, by default 60\n",
       "use_grad_clip : bool, optional\n",
       "    Whether to use gradient clipping, by default False\n",
       "grad_clip_norm : float, optional\n",
       "    Maximum gradient norm for clipping, by default 2.0\n",
       "mono_imputation_fn : callable, optional\n",
       "    Function to impute monopoles if missing from batches. Should take a batch dict\n",
       "    and return monopoles with shape (batch_size * num_atoms,). By default None\n",
       "distance_weighting : bool, optional\n",
       "    Whether to apply distance-based weighting to ESP loss. Errors further from atoms\n",
       "    will have HIGHER weight (reversed from typical). By default False\n",
       "distance_scale : float, optional\n",
       "    Scale parameter for distance weighting (in Angstroms). Larger values give slower\n",
       "    increase with distance. Weight = exp((distance - distance_min) / distance_scale),\n",
       "    normalized to have mean=1. By default 2.0\n",
       "distance_min : float, optional\n",
       "    Minimum distance for weighting (in Angstroms). Distances below this are clamped\n",
       "    to avoid singularities. By default 0.5\n",
       "esp_magnitude_weighting : bool, optional\n",
       "    Whether to weight by ESP magnitude instead of distance. Errors at points with\n",
       "    larger |ESP| values will have LOWER weight. This reduces the impact of points\n",
       "    where nuclear-electron shielding occurs and ESP approaches singularity (near\n",
       "    atomic nuclei). By default False\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "tuple\n",
       "    (final_params, final_valid_loss)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/mmml/dcmnet/dcmnet/training.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?prepare_datasets\n",
    "?train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8c7e7b-b633-4124-9e0c-1186c963533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_charge_predictor import load_charge_data\n",
    "\n",
    "# # Use only HF level\n",
    "# R, Z, mono = load_charge_data(csv_file, scheme='Hirshfeld', level='hf')\n",
    "\n",
    "# # Use only MP2 level\n",
    "# R, Z, mono = load_charge_data(csv_file, scheme='Hirshfeld', level='mp2')\n",
    "\n",
    "# # Use all levels (default)\n",
    "# R, Z, mono = load_charge_data(csv_file, scheme='Hirshfeld', level=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d56ade3-5d28-4693-81c5-23e5d645abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CO2 Charge Predictor Training Example\n",
      "======================================================================\n",
      "\n",
      "Loading data...\n",
      "Loaded 27540 rows from ../detailed_charges/df_charges_long.csv\n",
      "Available schemes: ['Hirshfeld' 'VDD' 'Becke' 'ADCH' 'CHELPG' 'MK' 'CM5' 'MBIS' 'MBIS_raw']\n",
      "Available levels: ['hf' 'mp2']\n",
      "Using level: mp2, 13770 rows\n",
      "Using scheme: MBIS_raw, 1530 rows\n",
      "Found 510 unique geometry+level combinations\n",
      "\n",
      "Prepared data:\n",
      "  R shape: (510, 3, 3)\n",
      "  Z shape: (510, 3)\n",
      "  mono shape: (510, 3)\n",
      "\n",
      "Training models...\n",
      "\n",
      "======================================================================\n",
      "Training Gradient Boosting Charge Predictors\n",
      "======================================================================\n",
      "\n",
      "Computing molecular features...\n",
      "Feature matrix shape: (510, 12)\n",
      "\n",
      "======================================================================\n",
      "Training model for atom 0 (Z=6)\n",
      "======================================================================\n",
      "  Train samples: 408\n",
      "  Test samples: 102\n",
      "  Charge range: [0.7880, 1.4690]\n",
      "  Charge mean: 1.1948, std: 0.1349\n",
      "\n",
      "  Training...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0149           0.0029            0.17s\n",
      "         2           0.0114          -0.0006            0.16s\n",
      "         3           0.0096           0.0039            0.15s\n",
      "         4           0.0080           0.0027            0.14s\n",
      "         5           0.0063           0.0007            0.14s\n",
      "         6           0.0054           0.0023            0.14s\n",
      "         7           0.0045           0.0012            0.13s\n",
      "         8           0.0033          -0.0006            0.13s\n",
      "         9           0.0029           0.0015            0.13s\n",
      "        10           0.0023           0.0005            0.13s\n",
      "        20           0.0003           0.0001            0.11s\n",
      "        30           0.0000           0.0000            0.10s\n",
      "        40           0.0000           0.0000            0.08s\n",
      "        50           0.0000           0.0000            0.07s\n",
      "        60           0.0000          -0.0000            0.05s\n",
      "        70           0.0000          -0.0000            0.04s\n",
      "        80           0.0000          -0.0000            0.03s\n",
      "        90           0.0000          -0.0000            0.01s\n",
      "       100           0.0000          -0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000576\n",
      "    RMSE: 0.000735\n",
      "    R¬≤:   0.999970\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.006144\n",
      "    RMSE: 0.016929\n",
      "    R¬≤:   0.984799\n",
      "\n",
      "======================================================================\n",
      "Training model for atom 1 (Z=8)\n",
      "======================================================================\n",
      "  Train samples: 408\n",
      "  Test samples: 102\n",
      "  Charge range: [-0.7345, -0.2623]\n",
      "  Charge mean: -0.5146, std: 0.1162\n",
      "\n",
      "  Training...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0109           0.0024            0.14s\n",
      "         2           0.0086           0.0011            0.13s\n",
      "         3           0.0072           0.0026            0.13s\n",
      "         4           0.0060           0.0019            0.13s\n",
      "         5           0.0048           0.0007            0.13s\n",
      "         6           0.0039           0.0011            0.13s\n",
      "         7           0.0033           0.0012            0.13s\n",
      "         8           0.0025          -0.0003            0.12s\n",
      "         9           0.0021           0.0009            0.12s\n",
      "        10           0.0017           0.0004            0.12s\n",
      "        20           0.0002           0.0000            0.11s\n",
      "        30           0.0000           0.0000            0.09s\n",
      "        40           0.0000           0.0000            0.08s\n",
      "        50           0.0000           0.0000            0.07s\n",
      "        60           0.0000          -0.0000            0.05s\n",
      "        70           0.0000           0.0000            0.04s\n",
      "        80           0.0000          -0.0000            0.03s\n",
      "        90           0.0000           0.0000            0.01s\n",
      "       100           0.0000           0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000329\n",
      "    RMSE: 0.000414\n",
      "    R¬≤:   0.999987\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.002548\n",
      "    RMSE: 0.008003\n",
      "    R¬≤:   0.995176\n",
      "\n",
      "======================================================================\n",
      "Training model for atom 2 (Z=8)\n",
      "======================================================================\n",
      "  Train samples: 408\n",
      "  Test samples: 102\n",
      "  Charge range: [-0.7345, -0.4785]\n",
      "  Charge mean: -0.6802, std: 0.0374\n",
      "\n",
      "  Training...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0012           0.0002            0.14s\n",
      "         2           0.0008          -0.0004            0.14s\n",
      "         3           0.0008           0.0005            0.13s\n",
      "         4           0.0006          -0.0002            0.13s\n",
      "         5           0.0005           0.0001            0.13s\n",
      "         6           0.0005           0.0005            0.13s\n",
      "         7           0.0004           0.0000            0.13s\n",
      "         8           0.0003          -0.0000            0.13s\n",
      "         9           0.0003           0.0001            0.13s\n",
      "        10           0.0002           0.0000            0.12s\n",
      "        20           0.0000           0.0000            0.11s\n",
      "        30           0.0000           0.0000            0.09s\n",
      "        40           0.0000          -0.0000            0.08s\n",
      "        50           0.0000           0.0000            0.07s\n",
      "        60           0.0000           0.0000            0.05s\n",
      "        70           0.0000           0.0000            0.04s\n",
      "        80           0.0000           0.0000            0.03s\n",
      "        90           0.0000           0.0000            0.01s\n",
      "       100           0.0000           0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000322\n",
      "    RMSE: 0.000406\n",
      "    R¬≤:   0.999876\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.003140\n",
      "    RMSE: 0.008604\n",
      "    R¬≤:   0.956313\n",
      "\n",
      "======================================================================\n",
      "Saving models to charge_predictor_MBIS_raw.pkl\n",
      "======================================================================\n",
      "Saved models and metadata\n",
      "\n",
      "======================================================================\n",
      "Training Complete!\n",
      "======================================================================\n",
      "\n",
      "Model saved to: charge_predictor_hirshfeld.pkl\n",
      "\n",
      "To use with DCMNet training:\n",
      "  from train_charge_predictor_usage import create_mono_imputation_fn_from_gb\n",
      "  mono_imputation_fn = create_mono_imputation_fn_from_gb('charge_predictor_hirshfeld.pkl')\n",
      "  train_model(..., mono_imputation_fn=mono_imputation_fn)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Quick example: Train charge predictor on CO2 data\n",
    "\n",
    "This script demonstrates how to train the gradient boosting charge predictor\n",
    "using the CO2 charge data.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from train_charge_predictor import load_charge_data, train_charge_predictor\n",
    "\n",
    "# Path to your data\n",
    "data_file = Path(\"../detailed_charges/df_charges_long.csv\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CO2 Charge Predictor Training Example\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load data - you can choose different schemes: Hirshfeld, VDD, Becke, etc.\n",
    "# and levels: hf, mp2\n",
    "print(\"\\nLoading data...\")\n",
    "R, Z, mono = load_charge_data(data_file, scheme='MBIS_raw', level='mp2')\n",
    "\n",
    "# Train models\n",
    "print(\"\\nTraining models...\")\n",
    "results = train_charge_predictor(\n",
    "    R=R,\n",
    "    Z=Z,\n",
    "    mono=mono,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    save_path=\"charge_predictor_MBIS_raw.pkl\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel saved to: charge_predictor_hirshfeld.pkl\")\n",
    "print(\"\\nTo use with DCMNet training:\")\n",
    "print(\"  from train_charge_predictor_usage import create_mono_imputation_fn_from_gb\")\n",
    "print(\"  mono_imputation_fn = create_mono_imputation_fn_from_gb('charge_predictor_hirshfeld.pkl')\")\n",
    "print(\"  train_model(..., mono_imputation_fn=mono_imputation_fn)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0eb290-1485-491f-bdb3-b5c0b9c8beb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m mono_imputation_fn(batch: Dict) -> jax.Array\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Impute monopoles for a batch.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "batch : dict\n",
       "    Batch dictionary containing 'Z', 'R', 'dst_idx', 'src_idx', 'batch_segments'\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "jnp.ndarray\n",
       "    Atomic monopoles with shape (batch_size * num_atoms,)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/examples/co2/dcmnet_train/train_charge_predictor_usage.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train_charge_predictor_usage import create_mono_imputation_fn_from_gb\n",
    "mono_imputation_fn = create_mono_imputation_fn_from_gb('charge_predictor_MBIS_raw.pkl')\n",
    "mono_imputation_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1131023a-d1ff-49c4-96de-891eb6014c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 3), (60, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"R\"][0].shape, train_data[\"R\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14acf1e9-ca77-4d24-b00a-c7fc70017fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['R', 'Z', 'N', 'esp', 'vdw_surface', 'Dxyz', 'E'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ceffbf2-ff6f-41db-a6c7-eb93e7a0f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize JAX random key\n",
    "key = jax.random.PRNGKey(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d03962-203a-4f0d-9e50-85bd9675565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Data Files:\n",
      "  Train EFD:  ../preclassified_data/energies_forces_dipoles_train.npz\n",
      "  Train Grid: ../preclassified_data/grids_esp_train.npz\n",
      "  Valid EFD:  ../preclassified_data/energies_forces_dipoles_valid.npz\n",
      "  Valid Grid: ../preclassified_data/grids_esp_valid.npz\n",
      "  Output: output/co2_dcmnet\n",
      "\n",
      "######################################################################\n",
      "# Loading Data\n",
      "######################################################################\n",
      "\n",
      "Loading training data...\n",
      "Loading validation data...\n",
      "\n",
      "‚úÖ Data loaded:\n",
      "  Training samples: 8000\n",
      "  Validation samples: 1000\n",
      "  Data keys: ['R', 'Z', 'N', 'esp', 'vdw_surface', 'Dxyz', 'E']\n",
      "\n",
      "Preparing datasets (computing edge lists, etc.)...\n",
      "‚úÖ Datasets prepared\n",
      "  Training batches: 7\n",
      "  Validation batches: 7\n",
      "\n",
      "######################################################################\n",
      "# Building Model\n",
      "######################################################################\n",
      "\n",
      "Model hyperparameters:\n",
      "  Features: 128\n",
      "  Max degree: 4\n",
      "  Message passing iterations: 4\n",
      "  Basis functions: 128\n",
      "  Cutoff: 10.0 √Ö\n",
      "  Distributed multipoles per atom: 6\n",
      "  Include pseudotensors: False\n",
      "\n",
      "‚úÖ Model created: DCMNet (n_dcm=6)\n",
      "\n",
      "######################################################################\n",
      "# Training Setup\n",
      "######################################################################\n",
      "\n",
      "Training hyperparameters:\n",
      "  Batch size: 1000\n",
      "  Epochs: 5000\n",
      "  Learning rate: 0.0005\n",
      "  ESP weight: 10000.0\n",
      "  Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import Dict, Tuple, Optional, Any, Mapping\n",
    "\n",
    "# Add mmml to path\n",
    "# repo_root = Path(__file__).parent / \"../../..\"\n",
    "# sys.path.insert(0, str(repo_root.resolve()))\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from mmml.dcmnet.dcmnet.modules import MessagePassingModel\n",
    "from mmml.dcmnet.dcmnet.training import train_model\n",
    "# from mmml.dcmnet.dcmnet.data import prepare_datasets\n",
    "\n",
    "# Validate input files\n",
    "for fname, fpath in [\n",
    "    ('Train EFD', args.train_efd),\n",
    "    ('Train Grid', args.train_grid),\n",
    "    ('Valid EFD', args.valid_efd),\n",
    "    ('Valid Grid', args.valid_grid)\n",
    "]:\n",
    "    if not fpath.exists():\n",
    "        print(f\"‚ùå Error: {fname} file not found: {fpath}\")\n",
    "        raise FileNotFoundError(f\"{fname} file not found: {fpath}\")\n",
    "\n",
    "print(f\"\\nüìÅ Data Files:\")\n",
    "print(f\"  Train EFD:  {args.train_efd}\")\n",
    "print(f\"  Train Grid: {args.train_grid}\")\n",
    "print(f\"  Valid EFD:  {args.valid_efd}\")\n",
    "print(f\"  Valid Grid: {args.valid_grid}\")\n",
    "\n",
    "# Setup output directory\n",
    "args.output_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"  Output: {args.output_dir / args.name}\")\n",
    "\n",
    "# Load data\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Loading Data\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "if args.verbose:\n",
    "    print(f\"\\nLoading training data...\")\n",
    "train_data_raw = load_co2_data(args.train_efd, args.train_grid)\n",
    "\n",
    "if args.verbose:\n",
    "    print(f\"Loading validation data...\")\n",
    "valid_data_raw = load_co2_data(args.valid_efd, args.valid_grid)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded:\")\n",
    "print(f\"  Training samples: {len(train_data_raw['R'])}\")\n",
    "print(f\"  Validation samples: {len(valid_data_raw['R'])}\")\n",
    "print(f\"  Data keys: {list(train_data_raw.keys())}\")\n",
    "\n",
    "# Prepare datasets (convert to DCMnet format with edge lists, etc.)\n",
    "print(f\"\\nPreparing datasets (computing edge lists, etc.)...\")\n",
    "# train_data, valid_data = prepare_datasets(\n",
    "#     train_data_raw,\n",
    "#     valid_data_raw,\n",
    "#     num_valid = \n",
    "#     # cutoff=args.cutoff,\n",
    "#     # batch_size=args.batch_size,\n",
    "# )\n",
    "train_data = train_data_raw\n",
    "valid_data = valid_data_raw\n",
    "print(f\"‚úÖ Datasets prepared\")\n",
    "print(f\"  Training batches: {len(train_data)}\")\n",
    "print(f\"  Validation batches: {len(valid_data)}\")\n",
    "\n",
    "# Build model\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Building Model\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "print(f\"\\nModel hyperparameters:\")\n",
    "print(f\"  Features: {args.features}\")\n",
    "print(f\"  Max degree: {args.max_degree}\")\n",
    "print(f\"  Message passing iterations: {args.num_iterations}\")\n",
    "print(f\"  Basis functions: {args.num_basis_functions}\")\n",
    "print(f\"  Cutoff: {args.cutoff} √Ö\")\n",
    "print(f\"  Distributed multipoles per atom: {args.n_dcm}\")\n",
    "print(f\"  Include pseudotensors: {args.include_pseudotensors}\")\n",
    "\n",
    "model = MessagePassingModel(\n",
    "    features=args.features,\n",
    "    max_degree=args.max_degree,\n",
    "    num_iterations=args.num_iterations,\n",
    "    num_basis_functions=args.num_basis_functions,\n",
    "    cutoff=args.cutoff,\n",
    "    n_dcm=args.n_dcm,\n",
    "    include_pseudotensors=args.include_pseudotensors,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model created: DCMNet (n_dcm={args.n_dcm})\")\n",
    "\n",
    "# Training setup\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Training Setup\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "print(f\"\\nTraining hyperparameters:\")\n",
    "print(f\"  Batch size: {args.batch_size}\")\n",
    "print(f\"  Epochs: {args.epochs}\")\n",
    "print(f\"  Learning rate: {args.learning_rate}\")\n",
    "print(f\"  ESP weight: {args.esp_weight}\")\n",
    "print(f\"  Random seed: {args.seed}\")\n",
    "\n",
    "# Load restart parameters if provided\n",
    "restart_params = None\n",
    "if args.restart:\n",
    "    print(f\"\\nüìÇ Loading restart checkpoint: {args.restart}\")\n",
    "    with open(args.restart, 'rb') as f:\n",
    "        restart_params = pickle.load(f)\n",
    "    print(f\"‚úÖ Checkpoint loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b751cd86-5781-4308-b6e0-bbe3467035fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "prepare_datasets(\n",
       "    key,\n",
       "    num_train,\n",
       "    num_valid,\n",
       "    filename,\n",
       "    natoms=\u001b[32m60\u001b[39m,\n",
       "    clean=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    esp_mask=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    clip_esp=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Prepare datasets for training and validation.\n",
       "\n",
       "Wrapper function that calls prepare_multiple_datasets and then\n",
       "creates train/validation splits and dictionaries.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "key : jax.random.PRNGKey\n",
       "    Random key for dataset shuffling\n",
       "num_train : int\n",
       "    Number of training samples\n",
       "num_valid : int\n",
       "    Number of validation samples\n",
       "filename : str or list\n",
       "    Filename(s) to load datasets from\n",
       "clean : bool, optional\n",
       "    Whether to filter failed calculations, by default False\n",
       "esp_mask : bool, optional\n",
       "    Whether to create ESP masks, by default False\n",
       "clip_esp : bool, optional\n",
       "    Whether to clip ESP to first 1000 points, by default False\n",
       "natoms : int, optional\n",
       "    Maximum number of atoms per system, by default 60\n",
       "\n",
       "Returns\n",
       "-------\n",
       "tuple\n",
       "    A tuple containing train_data and valid_data dictionaries\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/mmml/dcmnet/dcmnet/data.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prepare_datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab49c8d7-f477-4f02-a29b-4eafcec321fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0052505,  0.0033848,  0.037617 , ...,  0.0093954, -0.023834 ,\n",
       "         0.0059184],\n",
       "       [ 0.0043249,  0.0058309, -0.0074244, ..., -0.017754 ,  0.013946 ,\n",
       "        -0.006544 ],\n",
       "       [ 0.018399 ,  0.011036 ,  0.0095978, ..., -0.011879 , -0.010322 ,\n",
       "         0.0057994],\n",
       "       ...,\n",
       "       [ 0.042213 ,  0.032696 , -0.011879 , ..., -0.0024751,  0.032268 ,\n",
       "         0.015244 ],\n",
       "       [-0.0083788,  0.0076804, -0.010421 , ..., -0.010508 ,  0.0033204,\n",
       "        -0.0011256],\n",
       "       [-0.031544 , -0.0094387, -0.0063055, ..., -0.014822 , -0.002533 ,\n",
       "        -0.0051037]], shape=(8000, 3000), dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"esp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d10d14-db80-4f1d-92f5-4673cee5b50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "train_model(\n",
       "    key,\n",
       "    model,\n",
       "    train_data,\n",
       "    valid_data,\n",
       "    num_epochs,\n",
       "    learning_rate,\n",
       "    batch_size,\n",
       "    writer,\n",
       "    ndcm,\n",
       "    esp_w=\u001b[32m1.0\u001b[39m,\n",
       "    chg_w=\u001b[32m0.01\u001b[39m,\n",
       "    restart_params=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    ema_decay=\u001b[32m0.999\u001b[39m,\n",
       "    num_atoms=\u001b[32m60\u001b[39m,\n",
       "    use_grad_clip=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    grad_clip_norm=\u001b[32m2.0\u001b[39m,\n",
       "    mono_imputation_fn=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    distance_weighting=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    distance_scale=\u001b[32m2.0\u001b[39m,\n",
       "    distance_min=\u001b[32m0.5\u001b[39m,\n",
       "    esp_magnitude_weighting=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    charge_conservation_w=\u001b[32m1.0\u001b[39m,\n",
       "    esp_grid_units=\u001b[33m'angstrom'\u001b[39m,\n",
       "    radii_cutoff_multiplier=\u001b[32m2.0\u001b[39m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Train DCMNet model with ESP and monopole losses.\n",
       "\n",
       "Performs full training loop with validation, logging, and checkpointing.\n",
       "Uses exponential moving average (EMA) for parameter smoothing and saves\n",
       "best parameters based on validation loss.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "key : jax.random.PRNGKey\n",
       "    Random key for training\n",
       "model : MessagePassingModel\n",
       "    DCMNet model instance\n",
       "train_data : dict\n",
       "    Training dataset dictionary\n",
       "valid_data : dict\n",
       "    Validation dataset dictionary\n",
       "num_epochs : int\n",
       "    Number of training epochs\n",
       "learning_rate : float\n",
       "    Learning rate for optimization\n",
       "batch_size : int\n",
       "    Batch size for training\n",
       "writer : SummaryWriter\n",
       "    TensorBoard writer for logging\n",
       "ndcm : int\n",
       "    Number of distributed multipoles per atom\n",
       "esp_w : float, optional\n",
       "    Weight for ESP loss term, by default 1.0\n",
       "chg_w : float, optional\n",
       "    Weight for charge/monopole loss term, by default 0.01\n",
       "restart_params : Any, optional\n",
       "    Parameters to restart from, by default None\n",
       "ema_decay : float, optional\n",
       "    Exponential moving average decay rate, by default 0.999\n",
       "num_atoms : int, optional\n",
       "    Maximum number of atoms for batching, by default 60\n",
       "use_grad_clip : bool, optional\n",
       "    Whether to use gradient clipping, by default False\n",
       "grad_clip_norm : float, optional\n",
       "    Maximum gradient norm for clipping, by default 2.0\n",
       "mono_imputation_fn : callable, optional\n",
       "    Function to impute monopoles if missing from batches. Should take a batch dict\n",
       "    and return monopoles with shape (batch_size * num_atoms,). By default None\n",
       "distance_weighting : bool, optional\n",
       "    Whether to apply distance-based weighting to ESP loss. Errors further from atoms\n",
       "    will have HIGHER weight (reversed from typical). By default False\n",
       "distance_scale : float, optional\n",
       "    Scale parameter for distance weighting (in Angstroms). Larger values give slower\n",
       "    increase with distance. Weight = exp((distance - distance_min) / distance_scale),\n",
       "    normalized to have mean=1. By default 2.0\n",
       "distance_min : float, optional\n",
       "    Minimum distance for weighting (in Angstroms). Distances below this are clamped\n",
       "    to avoid singularities. By default 0.5\n",
       "esp_magnitude_weighting : bool, optional\n",
       "    Whether to weight by ESP magnitude instead of distance. Errors at points with\n",
       "    larger |ESP| values will have LOWER weight. This reduces the impact of points\n",
       "    where nuclear-electron shielding occurs and ESP approaches singularity (near\n",
       "    atomic nuclei). By default False\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "tuple\n",
       "    (final_params, final_valid_loss)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/mmml/dcmnet/dcmnet/training.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7898866a-5479-4810-85e9-1127e0499c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Aligning ESP Grids\n",
      "======================================================================\n",
      "\n",
      "Aligning training data...\n",
      "‚úÖ Aligned ESP grids to molecular reference frames\n",
      "   Number of samples: 8000\n",
      "\n",
      "   Sample 0 details:\n",
      "     Atom COM:        [0.         0.14525378 0.11470596]\n",
      "     Grid COM before: [[3.25342429 3.24367862 3.3973045 ]\n",
      " [3.29037849 3.42968506 3.37285263]\n",
      " [3.26749158 3.2349472  3.04755038]\n",
      " ...\n",
      " [3.23463851 3.24004016 3.27062503]\n",
      " [3.23331557 3.19962463 3.1881812 ]\n",
      " [3.29324486 3.22379038 3.37600344]]\n",
      "     Grid COM after:  [2.56091444e-16 1.45253775e-01 1.14705956e-01]\n",
      "     Offset corrected: [3.25342429 3.09842484 3.28259855] √Ö\n",
      "\n",
      "   Sense check:\n",
      "     Alignment error: 1.122908e-14 √Ö\n",
      "     ‚úì Alignment verified: grids are centered on atom COM\n",
      "\n",
      "     ‚ö†Ô∏è  Large offset detected: 5.564 √Ö\n",
      "        This suggests ESP grids and atoms were in different reference frames.\n",
      "\n",
      "Aligning validation data...\n",
      "‚úÖ Aligned ESP grids to molecular reference frames\n",
      "   Number of samples: 1000\n",
      "\n",
      "   Sample 0 details:\n",
      "     Atom COM:        [0.         0.25326187 0.02194556]\n",
      "     Grid COM before: [[3.22872937 3.4025402  3.33670261]\n",
      " [3.15376263 3.21823402 3.28853512]\n",
      " [3.29284798 3.23636282 3.32147785]\n",
      " ...\n",
      " [3.30034465 3.5232823  3.59271659]\n",
      " [3.23821046 3.44180257 3.51664558]\n",
      " [3.27238647 3.57924288 3.50544553]]\n",
      "     Grid COM after:  [2.56683563e-15 2.53261870e-01 2.19455598e-02]\n",
      "     Offset corrected: [3.22872937 3.14927833 3.31475705] √Ö\n",
      "\n",
      "   Sense check:\n",
      "     Alignment error: 1.205896e-14 √Ö\n",
      "     ‚úì Alignment verified: grids are centered on atom COM\n",
      "\n",
      "     ‚ö†Ô∏è  Large offset detected: 5.597 √Ö\n",
      "        This suggests ESP grids and atoms were in different reference frames.\n",
      "\n",
      "======================================================================\n",
      "Sense Check\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Sense Check for Sample 0\n",
      "======================================================================\n",
      "\n",
      "Atom positions (first 3 atoms):\n",
      "  Atom 0: [0. 0. 0.]\n",
      "  Atom 1: [0.    0.    1.417]\n",
      "  Atom 2: [ 0.          0.43576133 -1.07288213]\n",
      "\n",
      "Atom COM: [0.         0.14525378 0.11470596]\n",
      "Grid COM:  [2.56091444e-16 1.45253775e-01 1.14705956e-01]\n",
      "Offset:    [2.56091444e-16 1.03805853e-14 4.27435864e-15]\n",
      "\n",
      "Alignment error: 1.122908e-14 √Ö\n",
      "Offset magnitude: 0.000 √Ö\n",
      "\n",
      "‚úÖ PASS: Grids are properly aligned\n",
      "\n",
      "======================================================================\n",
      "Sense Check for Sample 0\n",
      "======================================================================\n",
      "\n",
      "Atom positions (first 3 atoms):\n",
      "  Atom 0: [0. 0. 0.]\n",
      "  Atom 1: [0.    0.    1.042]\n",
      "  Atom 2: [ 0.          0.75978561 -0.97616332]\n",
      "\n",
      "Atom COM: [0.         0.25326187 0.02194556]\n",
      "Grid COM:  [2.56683563e-15 2.53261870e-01 2.19455598e-02]\n",
      "Offset:    [2.56683563e-15 1.17128529e-14 1.28022593e-15]\n",
      "\n",
      "Alignment error: 1.205896e-14 √Ö\n",
      "Offset magnitude: 0.000 √Ö\n",
      "\n",
      "‚úÖ PASS: Grids are properly aligned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'atom_com': array([0.        , 0.25326187, 0.02194556]),\n",
       " 'grid_com': array([2.56683563e-15, 2.53261870e-01, 2.19455598e-02]),\n",
       " 'alignment_error': np.float64(1.2058961268398482e-14),\n",
       " 'offset': array([2.56683563e-15, 1.17128529e-14, 1.28022593e-15]),\n",
       " 'offset_magnitude': np.float64(1.2058961268398482e-14),\n",
       " 'is_aligned': np.True_}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from align_esp_grids import align_esp_grids, sense_check_alignment\n",
    "\n",
    "# Apply alignment to training and validation data\n",
    "print(\"=\"*70)\n",
    "print(\"Aligning ESP Grids\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nAligning training data...\")\n",
    "train_data = align_esp_grids(train_data, verbose=args.verbose)\n",
    "\n",
    "print(\"\\nAligning validation data...\")\n",
    "valid_data = align_esp_grids(valid_data, verbose=args.verbose)\n",
    "\n",
    "# Sense check\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Sense Check\")\n",
    "print(\"=\"*70)\n",
    "sense_check_alignment(train_data, sample_idx=0, verbose=True)\n",
    "sense_check_alignment(valid_data, sample_idx=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "010a279a-2709-499d-800a-b4a146124ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m mono_imputation_fn(batch: Dict) -> jax.Array\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Impute monopoles for a batch.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "batch : dict\n",
       "    Batch dictionary containing 'Z', 'R', 'dst_idx', 'src_idx', 'batch_segments'\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "jnp.ndarray\n",
       "    Atomic monopoles with shape (batch_size * num_atoms,)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/examples/co2/dcmnet_train/train_charge_predictor_usage.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mono_imputation_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d966dad-dce0-4e88-8ebb-a592bd76d276",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STARTING TRAINING\n",
      "======================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DATA STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Training Data:\n",
      "  Samples: 8000\n",
      "  Atoms per sample: 60\n",
      "  Grid points per sample: mean=3000, min=3000, max=3000\n",
      "  Total ESP grid points: 24,000,000\n",
      "  Monopoles:\n",
      "    Shape: (0,)\n",
      "    Mean: 0.000000 e\n",
      "    Std: 0.000000 e\n",
      "    Range: [0.000000, 0.000000] e\n",
      "    Sum(abs): 0.000000 e\n",
      "    Non-zero count: 0.0 / 0\n",
      "  ESP:\n",
      "    Mean: 0.014748 Ha/e (9.254 kcal/mol/e)\n",
      "    Std: 0.067087 Ha/e (42.097 kcal/mol/e)\n",
      "    Range: [-0.058102, 0.859140] Ha/e\n",
      "    Range: [-36.459, 539.110] kcal/mol/e\n",
      "    Median: 0.002183 Ha/e (1.370 kcal/mol/e)\n",
      "    Q25-Q75: [-0.005583, 0.011786] Ha/e\n",
      "    NaN count: 0.0, Inf count: 0.0\n",
      "  VDW Surface (first sample):\n",
      "    Shape: (3000, 3)\n",
      "    Position range: [-3.2534, 3.3840] √Ö\n",
      "    Position mean: 0.0867 √Ö, std: 1.9270 √Ö\n",
      "\n",
      "Validation Data:\n",
      "  Samples: 1000\n",
      "  Atoms per sample: 60\n",
      "  Grid points per sample: mean=3000, min=3000, max=3000\n",
      "  Total ESP grid points: 3,000,000\n",
      "  Monopoles:\n",
      "    Shape: (0,)\n",
      "    Mean: 0.000000 e\n",
      "    Std: 0.000000 e\n",
      "    Range: [0.000000, 0.000000] e\n",
      "    Sum(abs): 0.000000 e\n",
      "    Non-zero count: 0.0 / 0\n",
      "  ESP:\n",
      "    Mean: 0.014783 Ha/e (9.277 kcal/mol/e)\n",
      "    Std: 0.067306 Ha/e (42.234 kcal/mol/e)\n",
      "    Range: [-0.058142, 0.862270] Ha/e\n",
      "    Range: [-36.484, 541.074] kcal/mol/e\n",
      "    Median: 0.002217 Ha/e (1.391 kcal/mol/e)\n",
      "    Q25-Q75: [-0.005635, 0.011821] Ha/e\n",
      "    NaN count: 0.0, Inf count: 0.0\n",
      "  VDW Surface (first sample):\n",
      "    Shape: (3000, 3)\n",
      "    Position range: [-3.2818, 3.4880] √Ö\n",
      "    Position mean: 0.0917 √Ö, std: 1.9169 √Ö\n",
      "\n",
      "Training Configuration:\n",
      "  Batch size: 1000\n",
      "  Steps per epoch: 8\n",
      "  ESP weight: 10000\n",
      "  Charge weight: 0.001\n",
      "  Charge conservation weight: 0.01\n",
      "  Distance weighting: False\n",
      "    Distance scale: 2.0 √Ö\n",
      "    Distance min: 0.5 √Ö\n",
      "  ESP magnitude weighting: False\n",
      "  ESP grid units: angstrom\n",
      "  Radii cutoff multiplier: 4.0\n",
      "  Use atomic radii mask: True\n",
      "  Learning rate: 0.001\n",
      "  Number of DCM per atom: 6\n",
      "  Total parameters: 1,045,614\n",
      "================================================================================\n",
      "\n",
      "Preparing batches\n",
      "..................\n",
      "\n",
      "Preprocessing monopoles...\n",
      "  Imputing monopoles for 8000 samples...\n",
      "  Using padded_size=60 (from data shape), actual_atoms=3 per molecule, batch_size=1000\n",
      "  ‚úì Monopole imputation complete. Mean_abs=0.038398 e, Std=0.184355 e\n",
      "  Imputing monopoles for 1000 samples...\n",
      "  Using padded_size=60 (from data shape), actual_atoms=3 per molecule, batch_size=1000\n",
      "  ‚úì Monopole imputation complete. Mean_abs=0.038579 e, Std=0.185109 e\n",
      "\n",
      "Post-imputation Statistics:\n",
      "  Training monopoles after imputation:\n",
      "    Mean: 0.000090 e\n",
      "    Std: 0.184355 e\n",
      "    Range: [-0.718163, 1.395041] e\n",
      "    Sum(abs): 18431.113281 e\n",
      "    Non-zero: 24,000.0 / 480,000\n",
      "  Validation monopoles after imputation:\n",
      "    Mean: 0.000073 e\n",
      "    Std: 0.185109 e\n",
      "    Range: [-0.717490, 1.365771] e\n",
      "    Sum(abs): 2314.720703 e\n",
      "    Non-zero: 3,000.0 / 60,000\n",
      "\n",
      "================================================================================\n",
      "ESP Grid Verification\n",
      "================================================================================\n",
      "Checking ESP grid alignment and masking...\n",
      "  ‚úì  Training: ESP grids aligned (avg error: 0.0000 √Ö)\n",
      "      Sample 0: 223/3000 points too close\n",
      "      Radii: [0.76 0.66 0.66]\n",
      "      Cutoffs per atom: [1.52 1.32 1.32]\n",
      "      Min distances range: [0.4602, 5.0762] √Ö\n",
      "  ‚ö†Ô∏è  Training: 5/5 samples have ESP points too close to atoms\n",
      "      (These should be masked by atomic_radii_mask)\n",
      "  ‚úì  Validation: ESP grids aligned (avg error: 0.0000 √Ö)\n",
      "      Sample 0: 208/3000 points too close\n",
      "      Radii: [0.76 0.66 0.66]\n",
      "      Cutoffs per atom: [1.52 1.32 1.32]\n",
      "      Min distances range: [0.5234, 5.4225] √Ö\n",
      "  ‚ö†Ô∏è  Validation: 5/5 samples have ESP points too close to atoms\n",
      "      (These should be masked by atomic_radii_mask)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Preparing validation batches (batch_size=1000, num_atoms=3)...\n",
      "  Created 1 validation batches\n",
      "  First validation batch shapes:\n",
      "    Dxyz: (1000, 3) (dtype=float32)\n",
      "    N: (1000,) (dtype=int32)\n",
      "    R: (60000, 3) (dtype=float32)\n",
      "    Z: (60000,) (dtype=int32)\n",
      "    atom_mask: (1000, 3) (dtype=float32)\n",
      "    batch_segments: (3000,) (dtype=int32)\n",
      "    dst_idx: (6000,) (dtype=int32)\n",
      "    esp: (1000, 3000) (dtype=float32)\n",
      "    mono: (60000,) (dtype=float32)\n",
      "    n_grid: (1000,) (dtype=int32)\n",
      "    src_idx: (6000,) (dtype=int32)\n",
      "    vdw_surface: (1000, 3000, 3) (dtype=float32)\n",
      "\n",
      "================================================================================\n",
      "ESP Sense Check (Monopoles)\n",
      "================================================================================\n",
      "Computing ESP from reference monopoles on validation set...\n",
      "\n",
      "ESP from Reference Monopoles (Validation Set):\n",
      "  Total samples: 1000\n",
      "  Total grid points: 3,000,000\n",
      "  Valid grid points (masked): 1,554,472 / 3,000,000 (51.82%)\n",
      "\n",
      "  Unmasked Statistics:\n",
      "    MAE: 0.019526 Ha/e (12.252 kcal/mol/e)\n",
      "    RMSE: 0.064999 Ha/e (40.787 kcal/mol/e)\n",
      "    R¬≤: 0.067382\n",
      "    Per-sample RMSE: mean=0.064649, median=0.064667, max=0.087556 Ha/e\n",
      "\n",
      "  Masked Statistics:\n",
      "    MAE: 0.006234 Ha/e (3.912 kcal/mol/e)\n",
      "    RMSE: 0.008019 Ha/e (5.032 kcal/mol/e)\n",
      "    R¬≤: -0.053570\n",
      "\n",
      "  Worst 5 samples (by RMSE):\n",
      "    1. Sample 465: RMSE=0.087556 Ha/e (54.941 kcal/mol/e), MAE=0.025730 Ha/e (16.145 kcal/mol/e)\n",
      "    2. Sample 931: RMSE=0.084972 Ha/e (53.320 kcal/mol/e), MAE=0.023630 Ha/e (14.828 kcal/mol/e)\n",
      "    3. Sample 689: RMSE=0.083557 Ha/e (52.432 kcal/mol/e), MAE=0.022273 Ha/e (13.976 kcal/mol/e)\n",
      "    4. Sample 27: RMSE=0.083485 Ha/e (52.387 kcal/mol/e), MAE=0.025865 Ha/e (16.231 kcal/mol/e)\n",
      "    5. Sample 535: RMSE=0.082693 Ha/e (51.890 kcal/mol/e), MAE=0.020462 Ha/e (12.840 kcal/mol/e)\n",
      "\n",
      "  Error Distribution:\n",
      "    Errors > 0.100 Ha/e (62.8 kcal/mol/e): 88,479 / 3,000,000 (2.95%)\n",
      "    Error percentiles:\n",
      "      50th: 0.007452 Ha/e (4.676 kcal/mol/e)\n",
      "      75th: 0.014450 Ha/e (9.068 kcal/mol/e)\n",
      "      90th: 0.029237 Ha/e (18.346 kcal/mol/e)\n",
      "      95th: 0.053538 Ha/e (33.595 kcal/mol/e)\n",
      "      99th: 0.304448 Ha/e (191.041 kcal/mol/e)\n",
      "\n",
      "  ‚ö†Ô∏è  ESP calculation has moderate errors (RMSE < 0.1 Ha/e)\n",
      "      Note: Monopoles alone may not reproduce full ESP if higher-order\n",
      "      multipoles (dipoles, quadrupoles) contribute significantly.\n",
      "\n",
      "  ‚ö†Ô∏è  Low R¬≤ (0.0674) suggests monopoles alone cannot\n",
      "      accurately reproduce the target ESP. This is expected if:\n",
      "      - Target ESP includes higher-order multipole contributions\n",
      "      - Target ESP is from quantum mechanical calculations\n",
      "      - Distributed multipoles (DCM) are needed for accuracy\n",
      "\n",
      "  Unit and Masking Diagnostics:\n",
      "    ESP grid units: angstrom\n",
      "    Radii cutoff multiplier: 4.0\n",
      "    Use atomic radii mask: True (always enabled in sense check)\n",
      "    First sample grid range (Angstrom): [-3.3254, 3.4595]\n",
      "    First sample atom positions range (Angstrom): [-1.2269, 1.0620]\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Training\n",
      "..................\n",
      "\n",
      "  Created 8 training batches\n",
      "  First training batch shapes:\n",
      "    Dxyz: (1000, 3) (dtype=float32)\n",
      "    N: (1000,) (dtype=int32)\n",
      "    R: (60000, 3) (dtype=float32)\n",
      "    Z: (60000,) (dtype=int32)\n",
      "    atom_mask: (1000, 3) (dtype=float32)\n",
      "    batch_segments: (3000,) (dtype=int32)\n",
      "    dst_idx: (6000,) (dtype=int32)\n",
      "    esp: (1000, 3000) (dtype=float32)\n",
      "    mono: (60000,) (dtype=float32)\n",
      "    n_grid: (1000,) (dtype=int32)\n",
      "    src_idx: (6000,) (dtype=int32)\n",
      "    vdw_surface: (1000, 3000, 3) (dtype=float32)\n",
      "    ESP shape: (1000, 3000)\n",
      "    VDW surface shape: (1000, 3000, 3)\n",
      "    n_grid: Array[1000] i32 3.9Kb x‚àà[3000, 3000] Œº=3.000e+03 œÉ=0.000 gpu:0\n",
      "    atom_mask shape: (1000, 3), sum: 3000.0\n",
      "\n",
      "  First batch (epoch 1, batch 0) statistics:\n",
      "    Loss: 1.067704e+01\n",
      "    Loss components: {'charge_conservation_loss': Array gpu:0 0.112, 'charge_conservation_loss_weighted': Array gpu:0 0.001, 'esp_loss': Array gpu:0 0.001, 'esp_loss_weighted': Array gpu:0 10.676, 'mono_loss': Array gpu:0 0.337, 'mono_loss_weighted': Array gpu:0 0.000}\n",
      "    ESP mask shape: (1000, 3000)\n",
      "    ESP mask dtype: float32\n",
      "    ESP mask min: 0.000000, max: 1.000000\n",
      "    ESP mask mean: 0.518210\n",
      "    ESP mask sum: 1554629.000000\n",
      "    ESP mask size: 3000000\n",
      "    ESP mask valid count (>0.5): 1554629.0\n",
      "    ESP mask valid fraction: 0.518210\n",
      "    ESP pred shape: (1000, 3000), mean: 0.061389, std: 0.026037\n",
      "    ESP target shape: (1000, 3000), mean: 0.014648, std: 0.066925\n",
      "    ESP error shape: (1000, 3000), mean: 0.046741, std: 0.051064\n",
      "    ESP error MAE: 0.057242 Ha/e\n",
      "    ESP error RMSE: 0.069225 Ha/e\n",
      "    ESP mask first 20 values: Array[20] x‚àà[0., 1.000] Œº=0.600 œÉ=0.490 gpu:0\n",
      "    Batch keys: ['Dxyz', 'N', 'R', 'Z', 'atom_mask', 'batch_segments', 'dst_idx', 'esp', 'mono', 'n_grid', 'src_idx', 'vdw_surface']\n",
      "    Batch R shape: (60000, 3)\n",
      "    Batch Z shape: (60000,), unique values: Array[3] i32 x‚àà[0, 8] Œº=4.667 œÉ=3.399 gpu:0 [0, 6, 8]\n",
      "    Batch atom_mask shape: (1000, 3), sum: 3000.0\n",
      "    Batch vdw_surface shape: (1000, 3000, 3)\n",
      "    Batch vdw_surface first 9 values (x,y,z of first 3 points): Array[9] x‚àà[-2.809, 2.329] Œº=-0.109 œÉ=2.140 gpu:0 [1.160, 1.874, 1.270, 2.218, -2.360, 2.329, -2.809, -2.624, -2.037]\n",
      "  DEBUG: train_esp_masks: size=24000000.0, sum=12422668.0, mean=0.517611, min=0.000000, max=1.000000\n",
      "  DEBUG: train_esp_masks: n_valid=12422668.0, n_total=24000000.0, fraction=0.517611\n",
      "  DEBUG: first_mask shape=(1000, 3000), first_mask[:10]=Array[10] x‚àà[0., 1.000] Œº=0.600 œÉ=0.490 gpu:0 [0., 1.000, 1.000, 0., 1.000, 0., 0., 1.000, 1.000, 1.000]\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "  DEBUG: valid_esp_masks: size=3000000.0, sum=1554472.0, mean=0.518157, min=0.000000, max=1.000000\n",
      "  DEBUG: valid_esp_masks: n_valid=1554472.0, n_total=3000000.0, fraction=0.518157\n",
      "  DEBUG: first_mask shape=(1000, 3000), first_mask[:10]=Array[10] x‚àà[0., 1.000] Œº=0.500 œÉ=0.500 gpu:0 [0., 1.000, 1.000, 0., 0., 1.000, 0., 1.000, 1.000, 0.]\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch   1 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    1.885452e+02    1.054568e+01   -1.779995e+02\n",
      "esp_loss                1.885255e-02    1.054424e-03   -1.779812e-02\n",
      "mono_loss               3.414592e-01    3.376906e-01   -3.768653e-03\n",
      "charge_conservation_loss    1.932807e+00    1.105689e-01   -1.822238e+00\n",
      "esp_loss_weighted       1.885255e+02    1.054424e+01   -1.779812e+02\n",
      "mono_loss_weighted      3.414592e-04    3.376906e-04   -3.768655e-06\n",
      "charge_conservation_loss_weighted    1.932807e-02    1.105689e-03   -1.822238e-02\n",
      "mono_mae                5.508552e-02    4.379262e-02   -1.129289e-02\n",
      "mono_rmse               1.847861e-01    1.837636e-01   -1.022562e-03\n",
      "mono_mean              -1.996922e-03    5.537769e-03    7.534691e-03\n",
      "mono_std                2.357387e-02    1.858826e-03   -2.171504e-02\n",
      "esp_mae                 1.944718e-01    5.694328e-02   -1.375286e-01\n",
      "esp_mae_kcal              122.031077       35.731905      -86.299172 (kcal/mol/e)\n",
      "esp_rmse                2.895534e-01    6.918026e-02   -2.203731e-01\n",
      "esp_rmse_kcal             181.694761       43.410612     -138.284149 (kcal/mol/e)\n",
      "esp_r2_unmasked        -1.000000e+01   -5.647671e-02    9.943523e+00\n",
      "esp_r2_masked          -1.000000e+01   -1.000000e+01    0.000000e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean          -2.209988e-02    6.103629e-02    8.313617e-02\n",
      "esp_pred_std            2.775629e-01    2.592876e-02   -2.516341e-01\n",
      "esp_error_mean         -3.684806e-02    4.625292e-02    8.310098e-02\n",
      "esp_error_std           2.871992e-01    5.144488e-02   -2.357543e-01\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=-1.996922e-03, std=2.357387e-02, min=-5.464646e-02, max=2.981259e-02\n",
      "  Valid: mean=5.537769e-03, std=1.858826e-03, min=-4.365876e-03, max=9.922035e-03\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-10.0000) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.0565) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Training masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch   2 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    1.123082e+02    1.181385e+01   -1.004943e+02\n",
      "esp_loss                1.122964e-02    1.181228e-03   -1.004841e-02\n",
      "mono_loss               3.385718e-01    3.377317e-01   -8.400083e-04\n",
      "charge_conservation_loss    1.151022e+00    1.239131e-01   -1.027109e+00\n",
      "esp_loss_weighted       1.122964e+02    1.181228e+01   -1.004841e+02\n",
      "mono_loss_weighted      3.385718e-04    3.377318e-04   -8.400239e-07\n",
      "charge_conservation_loss_weighted    1.151022e-02    1.239131e-03   -1.027109e-02\n",
      "mono_mae                5.311137e-02    4.411570e-02   -8.995675e-03\n",
      "mono_rmse               1.840032e-01    1.837748e-01   -2.284050e-04\n",
      "mono_mean              -2.815312e-04    5.862858e-03    6.144389e-03\n",
      "mono_std                1.834927e-02    1.895597e-03   -1.645368e-02\n",
      "esp_mae                 1.675669e-01    5.997976e-02   -1.075872e-01\n",
      "esp_mae_kcal              105.148255       37.637299      -67.510956 (kcal/mol/e)\n",
      "esp_rmse                2.264660e-01    7.112987e-02   -1.553362e-01\n",
      "esp_rmse_kcal             142.107443       44.633991      -97.473452 (kcal/mol/e)\n",
      "esp_r2_unmasked        -1.000000e+01   -1.168619e-01    9.883138e+00\n",
      "esp_r2_masked          -1.000000e+01   -1.000000e+01    0.000000e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean          -3.329466e-03    6.462726e-02    6.795673e-02\n",
      "esp_pred_std            2.149896e-01    2.746051e-02   -1.875291e-01\n",
      "esp_error_mean         -1.807765e-02    4.984389e-02    6.792153e-02\n",
      "esp_error_std           2.257434e-01    5.074490e-02   -1.749985e-01\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=-2.815312e-04, std=1.834927e-02, min=-3.385213e-02, max=2.779027e-02\n",
      "  Valid: mean=5.862858e-03, std=1.895597e-03, min=-4.301863e-03, max=9.981196e-03\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-10.0000) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.1169) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Training masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch   3 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    2.091423e+01    1.330210e+01   -7.612137e+00\n",
      "esp_loss                2.091178e-03    1.330036e-03   -7.611418e-04\n",
      "mono_loss               3.364570e-01    3.377831e-01    1.326114e-03\n",
      "charge_conservation_loss    2.116241e-01    1.395504e-01   -7.207370e-02\n",
      "esp_loss_weighted       2.091178e+01    1.330036e+01   -7.611417e+00\n",
      "mono_loss_weighted      3.364570e-04    3.377831e-04    1.326087e-06\n",
      "charge_conservation_loss_weighted    2.116241e-03    1.395505e-03   -7.207369e-04\n",
      "mono_mae                4.469445e-02    4.447177e-02   -2.226830e-04\n",
      "mono_rmse               1.834276e-01    1.837888e-01    3.611296e-04\n",
      "mono_mean              -1.531368e-04    6.222358e-03    6.375495e-03\n",
      "mono_std                8.075167e-03    1.930122e-03   -6.145046e-03\n",
      "esp_mae                 7.755391e-02    6.337246e-02   -1.418146e-02\n",
      "esp_mae_kcal               48.665080       39.766216       -8.898865 (kcal/mol/e)\n",
      "esp_rmse                1.161048e-01    7.346725e-02   -4.263752e-02\n",
      "esp_rmse_kcal              72.855741       46.100698      -26.755044 (kcal/mol/e)\n",
      "esp_r2_unmasked        -1.995181e+00   -1.914699e-01    1.803711e+00\n",
      "esp_r2_masked          -1.000000e+01   -1.000000e+01    0.000000e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean          -1.937861e-03    6.859777e-02    7.053563e-02\n",
      "esp_pred_std            9.218121e-02    2.914954e-02   -6.303166e-02\n",
      "esp_error_mean         -1.668605e-02    5.381440e-02    7.050045e-02\n",
      "esp_error_std           1.148995e-01    5.001446e-02   -6.488503e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=-1.531368e-04, std=8.075167e-03, min=-1.321998e-02, max=1.540936e-02\n",
      "  Valid: mean=6.222358e-03, std=1.930122e-03, min=-4.172445e-03, max=1.008818e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-1.9952) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.1915) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Training masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch   4 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    8.260076e+00    1.473117e+01    6.471097e+00\n",
      "esp_loss                8.258928e-04    1.472929e-03    6.470361e-04\n",
      "mono_loss               3.365075e-01    3.378364e-01    1.328886e-03\n",
      "charge_conservation_loss    8.109621e-02    1.545473e-01    7.345106e-02\n",
      "esp_loss_weighted       8.258928e+00    1.472929e+01    6.470361e+00\n",
      "mono_loss_weighted      3.365075e-04    3.378364e-04    1.328881e-06\n",
      "charge_conservation_loss_weighted    8.109621e-04    1.545473e-03    7.345107e-04\n",
      "mono_mae                4.267891e-02    4.479470e-02    2.115786e-03\n",
      "mono_rmse               1.834414e-01    1.838033e-01    3.618449e-04\n",
      "mono_mean              -7.101471e-04    6.548626e-03    7.258773e-03\n",
      "mono_std                5.262523e-03    1.959179e-03   -3.303344e-03\n",
      "esp_mae                 5.686323e-02    6.648026e-02    9.617027e-03\n",
      "esp_mae_kcal               35.681677       41.716361        6.034684 (kcal/mol/e)\n",
      "esp_rmse                9.313609e-02    7.573964e-02   -1.739644e-02\n",
      "esp_rmse_kcal              58.442895       47.526627      -10.916268 (kcal/mol/e)\n",
      "esp_r2_unmasked        -9.273422e-01   -2.663158e-01    6.610264e-01\n",
      "esp_r2_masked          -1.000000e+01   -1.000000e+01    0.000000e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean          -8.087979e-03    7.220104e-02    8.028902e-02\n",
      "esp_pred_std            5.659408e-02    3.068229e-02   -2.591180e-02\n",
      "esp_error_mean         -2.283616e-02    5.741766e-02    8.025383e-02\n",
      "esp_error_std           9.029308e-02    4.939337e-02   -4.089971e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=-7.101471e-04, std=5.262523e-03, min=-7.685186e-03, max=1.518465e-02\n",
      "  Valid: mean=6.548626e-03, std=1.959179e-03, min=-4.039442e-03, max=1.020113e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Overfitting detected: validation loss (1.47e+01) is 1.8x higher than training loss (8.26e+00)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.9273) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.2663) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Training masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch   5 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    2.351972e+00    1.605822e+01    1.370625e+01\n",
      "esp_loss                2.351436e-04    1.605620e-03    1.370477e-03\n",
      "mono_loss               3.365393e-01    3.378874e-01    1.348108e-03\n",
      "charge_conservation_loss    1.997864e-02    1.684590e-01    1.484803e-01\n",
      "esp_loss_weighted       2.351436e+00    1.605620e+01    1.370477e+01\n",
      "mono_loss_weighted      3.365393e-04    3.378874e-04    1.348119e-06\n",
      "charge_conservation_loss_weighted    1.997864e-04    1.684590e-03    1.484803e-03\n",
      "mono_mae                4.051651e-02    4.507971e-02    4.563197e-03\n",
      "mono_rmse               1.834501e-01    1.838171e-01    3.670752e-04\n",
      "mono_mean              -1.112502e-03    6.837313e-03    7.949815e-03\n",
      "mono_std                3.091400e-03    1.981236e-03   -1.110164e-03\n",
      "esp_mae                 3.713146e-02    6.925161e-02    3.212015e-02\n",
      "esp_mae_kcal               23.299993       43.455386       20.155394 (kcal/mol/e)\n",
      "esp_rmse                8.097082e-02    7.786086e-02   -3.109954e-03\n",
      "esp_rmse_kcal              50.809187       48.857691       -1.951496 (kcal/mol/e)\n",
      "esp_r2_unmasked        -4.567327e-01   -3.382400e-01    1.184927e-01\n",
      "esp_r2_masked          -6.810879e+00   -1.000000e+01   -3.189121e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean          -1.253381e-02    7.538883e-02    8.792263e-02\n",
      "esp_pred_std            2.576883e-02    3.203932e-02    6.270494e-03\n",
      "esp_error_mean         -2.728199e-02    6.060546e-02    8.788745e-02\n",
      "esp_error_std           7.623625e-02    4.888040e-02   -2.735585e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=-1.112502e-03, std=3.091400e-03, min=-4.080708e-03, max=1.482668e-02\n",
      "  Valid: mean=6.837313e-03, std=1.981236e-03, min=-3.888577e-03, max=1.029617e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (1.61e+01) is 6.8x higher than training loss (2.35e+00)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.4567) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.3382) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Training masked ESP R¬≤ is very negative (-6.8109) - check masking logic\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch   6 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    1.352059e+00    1.731127e+01    1.595921e+01\n",
      "esp_loss                1.351605e-04    1.730912e-03    1.595751e-03\n",
      "mono_loss               3.365536e-01    3.379377e-01    1.384079e-03\n",
      "charge_conservation_loss    1.175957e-02    1.815836e-01    1.698241e-01\n",
      "esp_loss_weighted       1.351605e+00    1.730912e+01    1.595751e+01\n",
      "mono_loss_weighted      3.365536e-04    3.379377e-04    1.384062e-06\n",
      "charge_conservation_loss_weighted    1.175957e-04    1.815836e-03    1.698241e-03\n",
      "mono_mae                3.976690e-02    4.533776e-02    5.570859e-03\n",
      "mono_rmse               1.834540e-01    1.838308e-01    3.768504e-04\n",
      "mono_mean               1.085077e-03    7.099018e-03    6.013940e-03\n",
      "mono_std                2.403546e-03    1.998432e-03   -4.051139e-04\n",
      "esp_mae                 2.806576e-02    7.178051e-02    4.371475e-02\n",
      "esp_mae_kcal               17.611264       45.042270       27.431006 (kcal/mol/e)\n",
      "esp_rmse                6.667345e-02    7.986417e-02    1.319072e-02\n",
      "esp_rmse_kcal              41.837590       50.114769        8.277179 (kcal/mol/e)\n",
      "esp_r2_unmasked         1.229161e-02   -4.079900e-01   -4.202816e-01\n",
      "esp_r2_masked          -3.489904e+00   -1.000000e+01   -6.510096e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean           1.173947e-02    7.827852e-02    6.653905e-02\n",
      "esp_pred_std            1.795075e-02    3.326607e-02    1.531532e-02\n",
      "esp_error_mean         -3.008716e-03    6.349514e-02    6.650386e-02\n",
      "esp_error_std           6.660553e-02    4.844226e-02   -1.816327e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=1.085077e-03, std=2.403546e-03, min=-1.926341e-03, max=1.473932e-02\n",
      "  Valid: mean=7.099018e-03, std=1.998432e-03, min=-3.738504e-03, max=1.040219e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (1.73e+01) is 12.8x higher than training loss (1.35e+00)\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.4080) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch   7 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    8.194405e-01    1.848438e+01    1.766494e+01\n",
      "esp_loss                8.190513e-05    1.848211e-03    1.766306e-03\n",
      "mono_loss               3.365628e-01    3.379913e-01    1.428515e-03\n",
      "charge_conservation_loss    5.257756e-03    1.938626e-01    1.886049e-01\n",
      "esp_loss_weighted       8.190514e-01    1.848211e+01    1.766306e+01\n",
      "mono_loss_weighted      3.365628e-04    3.379913e-04    1.428503e-06\n",
      "charge_conservation_loss_weighted    5.257756e-05    1.938626e-03    1.886049e-03\n",
      "mono_mae                3.943080e-02    4.557126e-02    6.140452e-03\n",
      "mono_rmse               1.834565e-01    1.838454e-01    3.889203e-04\n",
      "mono_mean               5.817048e-06    7.335301e-03    7.329484e-03\n",
      "mono_std                2.391447e-03    2.013706e-03   -3.777409e-04\n",
      "esp_mae                 2.687470e-02    7.407667e-02    4.720198e-02\n",
      "esp_mae_kcal               16.863873       46.483113       29.619240 (kcal/mol/e)\n",
      "esp_rmse                7.112999e-02    8.173590e-02    1.060591e-02\n",
      "esp_rmse_kcal              44.634070       51.289278        6.655208 (kcal/mol/e)\n",
      "esp_r2_unmasked        -1.241606e-01   -4.747597e-01   -3.505991e-01\n",
      "esp_r2_masked          -1.720054e+00   -1.000000e+01   -8.279946e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean          -1.814121e-04    8.088739e-02    8.106880e-02\n",
      "esp_pred_std            1.465524e-02    3.437692e-02    1.972167e-02\n",
      "esp_error_mean         -1.492960e-02    6.610402e-02    8.103361e-02\n",
      "esp_error_std           6.954554e-02    4.807303e-02   -2.147251e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=5.817048e-06, std=2.391447e-03, min=-2.208180e-03, max=1.431641e-02\n",
      "  Valid: mean=7.335301e-03, std=2.013706e-03, min=-3.603281e-03, max=1.049822e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (1.85e+01) is 22.6x higher than training loss (8.19e-01)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.1242) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.4748) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch   8 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    4.732612e-01    1.961500e+01    1.914174e+01\n",
      "esp_loss                4.729091e-05    1.961261e-03    1.913970e-03\n",
      "mono_loss               3.365259e-01    3.380277e-01    1.501709e-03\n",
      "charge_conservation_loss    1.554479e-03    2.056897e-01    2.041352e-01\n",
      "esp_loss_weighted       4.729091e-01    1.961261e+01    1.913970e+01\n",
      "mono_loss_weighted      3.365259e-04    3.380277e-04    1.501729e-06\n",
      "charge_conservation_loss_weighted    1.554479e-05    2.056897e-03    2.041352e-03\n",
      "mono_mae                3.909694e-02    4.578810e-02    6.691165e-03\n",
      "mono_rmse               1.834464e-01    1.838553e-01    4.088432e-04\n",
      "mono_mean              -1.602390e-04    7.556091e-03    7.716330e-03\n",
      "mono_std                2.155738e-03    2.028031e-03   -1.277069e-04\n",
      "esp_mae                 2.480603e-02    7.623227e-02    5.142624e-02\n",
      "esp_mae_kcal               15.565785       47.835749       32.269964 (kcal/mol/e)\n",
      "esp_rmse                7.100704e-02    8.353178e-02    1.252475e-02\n",
      "esp_rmse_kcal              44.556915       52.416193        7.859278 (kcal/mol/e)\n",
      "esp_r2_unmasked        -1.202774e-01   -5.402777e-01   -4.200003e-01\n",
      "esp_r2_masked          -5.708466e-01   -1.000000e+01   -9.429153e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean          -2.012646e-03    8.332513e-02    8.533778e-02\n",
      "esp_pred_std            8.012642e-03    3.540920e-02    2.739656e-02\n",
      "esp_error_mean         -1.676083e-02    6.854176e-02    8.530259e-02\n",
      "esp_error_std           6.900053e-02    4.774502e-02   -2.125552e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=-1.602390e-04, std=2.155738e-03, min=-1.262869e-03, max=1.420678e-02\n",
      "  Valid: mean=7.556091e-03, std=2.028031e-03, min=-3.462472e-03, max=1.060491e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (1.96e+01) is 41.4x higher than training loss (4.73e-01)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.1203) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.5403) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch   9 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    3.668380e-01    2.066208e+01    2.029524e+01\n",
      "esp_loss                3.664913e-05    2.065957e-03    2.029308e-03\n",
      "mono_loss               3.364698e-01    3.380705e-01    1.600653e-03\n",
      "charge_conservation_loss    1.023819e-03    2.166369e-01    2.156131e-01\n",
      "esp_loss_weighted       3.664913e-01    2.065957e+01    2.029308e+01\n",
      "mono_loss_weighted      3.364698e-04    3.380705e-04    1.600652e-06\n",
      "charge_conservation_loss_weighted    1.023819e-05    2.166369e-03    2.156131e-03\n",
      "mono_mae                3.860341e-02    4.598340e-02    7.379986e-03\n",
      "mono_rmse               1.834311e-01    1.838669e-01    4.357696e-04\n",
      "mono_mean               4.383834e-04    7.754720e-03    7.316337e-03\n",
      "mono_std                1.981547e-03    2.038144e-03    5.659764e-05\n",
      "esp_mae                 2.267303e-02    7.817972e-02    5.550669e-02\n",
      "esp_mae_kcal               14.227326       49.057772       34.830446 (kcal/mol/e)\n",
      "esp_rmse                6.734471e-02    8.518738e-02    1.784267e-02\n",
      "esp_rmse_kcal              42.258806       53.455078       11.196272 (kcal/mol/e)\n",
      "esp_r2_unmasked        -7.696629e-03   -6.019392e-01   -5.942426e-01\n",
      "esp_r2_masked          -2.172649e-01   -1.000000e+01   -9.782735e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean           4.601147e-03    8.551808e-02    8.091694e-02\n",
      "esp_pred_std            4.175091e-03    3.634182e-02    3.216673e-02\n",
      "esp_error_mean         -1.014704e-02    7.073472e-02    8.088175e-02\n",
      "esp_error_std           6.657588e-02    4.747094e-02   -1.910494e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=4.383834e-04, std=1.981547e-03, min=-4.856944e-04, max=1.405706e-02\n",
      "  Valid: mean=7.754720e-03, std=2.038144e-03, min=-3.332040e-03, max=1.069372e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (2.07e+01) is 56.3x higher than training loss (3.67e-01)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.0077) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.6019) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch  10 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    3.428869e-01    2.163634e+01    2.129345e+01\n",
      "esp_loss                3.425467e-05    2.163374e-03    2.129119e-03\n",
      "mono_loss               3.364229e-01    3.381114e-01    1.688451e-03\n",
      "charge_conservation_loss    3.776188e-04    2.268187e-01    2.264410e-01\n",
      "esp_loss_weighted       3.425467e-01    2.163374e+01    2.129119e+01\n",
      "mono_loss_weighted      3.364230e-04    3.381114e-04    1.688430e-06\n",
      "charge_conservation_loss_weighted    3.776188e-06    2.268187e-03    2.264410e-03\n",
      "mono_mae                3.872879e-02    4.616074e-02    7.431950e-03\n",
      "mono_rmse               1.834183e-01    1.838780e-01    4.597008e-04\n",
      "mono_mean               1.267579e-05    7.934993e-03    7.922317e-03\n",
      "mono_std                2.027826e-03    2.047294e-03    1.946790e-05\n",
      "esp_mae                 2.344122e-02    7.995344e-02    5.651222e-02\n",
      "esp_mae_kcal               14.709368       50.170783       35.461416 (kcal/mol/e)\n",
      "esp_rmse                6.966107e-02    8.671937e-02    1.705830e-02\n",
      "esp_rmse_kcal              43.712324       54.416406       10.704082 (kcal/mol/e)\n",
      "esp_r2_unmasked        -7.820952e-02   -6.600754e-01   -5.818659e-01\n",
      "esp_r2_masked          -1.377658e-01   -1.000000e+01   -9.862234e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean          -9.884660e-05    8.750834e-02    8.760719e-02\n",
      "esp_pred_std            4.306696e-03    3.718828e-02    3.288158e-02\n",
      "esp_error_mean         -1.484703e-02    7.272498e-02    8.757201e-02\n",
      "esp_error_std           6.806049e-02    4.723694e-02   -2.082355e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=1.267579e-05, std=2.027826e-03, min=-7.948875e-04, max=1.389111e-02\n",
      "  Valid: mean=7.934993e-03, std=2.047294e-03, min=-3.200110e-03, max=1.078453e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (2.16e+01) is 63.1x higher than training loss (3.43e-01)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.0782) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.6601) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch  11 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    3.173119e-01    2.252176e+01    2.220445e+01\n",
      "esp_loss                3.169737e-05    2.251906e-03    2.220208e-03\n",
      "mono_loss               3.363589e-01    3.381454e-01    1.786500e-03\n",
      "charge_conservation_loss    1.854733e-04    2.360668e-01    2.358813e-01\n",
      "esp_loss_weighted       3.169737e-01    2.251906e+01    2.220208e+01\n",
      "mono_loss_weighted      3.363589e-04    3.381454e-04    1.786480e-06\n",
      "charge_conservation_loss_weighted    1.854733e-06    2.360668e-03    2.358813e-03\n",
      "mono_mae                3.863453e-02    4.631747e-02    7.682938e-03\n",
      "mono_rmse               1.834009e-01    1.838873e-01    4.863888e-04\n",
      "mono_mean               8.484847e-05    8.095372e-03    8.010524e-03\n",
      "mono_std                1.988558e-03    2.051155e-03    6.259698e-05\n",
      "esp_mae                 2.307153e-02    8.153624e-02    5.846471e-02\n",
      "esp_mae_kcal               14.477386       51.163991       36.686605 (kcal/mol/e)\n",
      "esp_rmse                6.917915e-02    8.810352e-02    1.892437e-02\n",
      "esp_rmse_kcal              43.409915       55.284957       11.875042 (kcal/mol/e)\n",
      "esp_r2_unmasked        -6.334281e-02   -7.134918e-01   -6.501490e-01\n",
      "esp_r2_masked          -5.281329e-02   -1.000000e+01   -9.947187e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean           7.000469e-04    8.927844e-02    8.857839e-02\n",
      "esp_pred_std            3.046941e-03    3.793592e-02    3.488897e-02\n",
      "esp_error_mean         -1.404814e-02    7.449506e-02    8.854320e-02\n",
      "esp_error_std           6.773776e-02    4.703951e-02   -2.069825e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=8.484847e-05, std=1.988558e-03, min=-5.477438e-04, max=1.390603e-02\n",
      "  Valid: mean=8.095372e-03, std=2.051155e-03, min=-3.067732e-03, max=1.089458e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (2.25e+01) is 71.0x higher than training loss (3.17e-01)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.0633) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.7135) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch  12 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    3.062769e-01    2.344650e+01    2.314022e+01\n",
      "esp_loss                3.059387e-05    2.344370e-03    2.313776e-03\n",
      "mono_loss               3.362884e-01    3.381916e-01    1.903206e-03\n",
      "charge_conservation_loss    1.860886e-04    2.457239e-01    2.455378e-01\n",
      "esp_loss_weighted       3.059387e-01    2.344370e+01    2.313776e+01\n",
      "mono_loss_weighted      3.362884e-04    3.381916e-04    1.903216e-06\n",
      "charge_conservation_loss_weighted    1.860886e-06    2.457239e-03    2.455378e-03\n",
      "mono_mae                3.848653e-02    4.647918e-02    7.992651e-03\n",
      "mono_rmse               1.833817e-01    1.838998e-01    5.181879e-04\n",
      "mono_mean               2.051280e-04    8.259455e-03    8.054327e-03\n",
      "mono_std                1.949769e-03    2.057095e-03    1.073265e-04\n",
      "esp_mae                 2.272199e-02    8.316052e-02    6.043853e-02\n",
      "esp_mae_kcal               14.258050       52.183226       37.925176 (kcal/mol/e)\n",
      "esp_rmse                6.845792e-02    8.954073e-02    2.108282e-02\n",
      "esp_rmse_kcal              42.957343       56.186811       13.229469 (kcal/mol/e)\n",
      "esp_r2_unmasked        -4.128635e-02   -7.698516e-01   -7.285652e-01\n",
      "esp_r2_masked          -1.616633e-02   -1.000000e+01   -9.983834e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean           2.031279e-03    9.109014e-02    8.905886e-02\n",
      "esp_pred_std            1.996326e-03    3.870564e-02    3.670931e-02\n",
      "esp_error_mean         -1.271691e-02    7.630676e-02    8.902367e-02\n",
      "esp_error_std           6.726638e-02    4.684892e-02   -2.041746e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=2.051280e-04, std=1.949769e-03, min=-3.496367e-04, max=1.389110e-02\n",
      "  Valid: mean=8.259455e-03, std=2.057095e-03, min=-2.939530e-03, max=1.096260e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (2.34e+01) is 76.6x higher than training loss (3.06e-01)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.0413) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.7699) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch  13 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    3.046657e-01    2.419350e+01    2.388883e+01\n",
      "esp_loss                3.043286e-05    2.419063e-03    2.388630e-03\n",
      "mono_loss               3.362182e-01    3.382241e-01    2.005935e-03\n",
      "charge_conservation_loss    8.860597e-05    2.535218e-01    2.534332e-01\n",
      "esp_loss_weighted       3.043286e-01    2.419063e+01    2.388630e+01\n",
      "mono_loss_weighted      3.362182e-04    3.382241e-04    2.005923e-06\n",
      "charge_conservation_loss_weighted    8.860598e-07    2.535218e-03    2.534332e-03\n",
      "mono_mae                3.855876e-02    4.660665e-02    8.047890e-03\n",
      "mono_rmse               1.833625e-01    1.839087e-01    5.461723e-04\n",
      "mono_mean               1.185939e-04    8.389601e-03    8.271007e-03\n",
      "mono_std                1.949015e-03    2.059943e-03    1.109282e-04\n",
      "esp_mae                 2.290148e-02    8.445214e-02    6.155066e-02\n",
      "esp_mae_kcal               14.370679       52.993716       38.623037 (kcal/mol/e)\n",
      "esp_rmse                6.892873e-02    9.069514e-02    2.176642e-02\n",
      "esp_rmse_kcal              43.252776       56.911202       13.658426 (kcal/mol/e)\n",
      "esp_r2_unmasked        -5.565822e-02   -8.157817e-01   -7.601235e-01\n",
      "esp_r2_masked          -1.081645e-02   -1.000000e+01   -9.989184e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean           1.077847e-03    9.252662e-02    9.144877e-02\n",
      "esp_pred_std            2.041321e-03    3.931456e-02    3.727324e-02\n",
      "esp_error_mean         -1.367034e-02    7.774325e-02    9.141358e-02\n",
      "esp_error_std           6.755954e-02    4.670757e-02   -2.085197e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=1.185939e-04, std=1.949015e-03, min=-4.041863e-04, max=1.383113e-02\n",
      "  Valid: mean=8.389601e-03, std=2.059943e-03, min=-2.829717e-03, max=1.104143e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (2.42e+01) is 79.4x higher than training loss (3.05e-01)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.0557) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.8158) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch  14 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    3.018473e-01    2.492505e+01    2.462321e+01\n",
      "esp_loss                3.015107e-05    2.492210e-03    2.462059e-03\n",
      "mono_loss               3.361466e-01    3.382478e-01    2.101243e-03\n",
      "charge_conservation_loss    4.775039e-05    2.611563e-01    2.611086e-01\n",
      "esp_loss_weighted       3.015107e-01    2.492210e+01    2.462059e+01\n",
      "mono_loss_weighted      3.361466e-04    3.382478e-04    2.101267e-06\n",
      "charge_conservation_loss_weighted    4.775039e-07    2.611563e-03    2.611086e-03\n",
      "mono_mae                3.856013e-02    4.672899e-02    8.168854e-03\n",
      "mono_rmse               1.833430e-01    1.839151e-01    5.721301e-04\n",
      "mono_mean               1.046157e-04    8.515120e-03    8.410505e-03\n",
      "mono_std                1.934916e-03    2.063477e-03    1.285607e-04\n",
      "esp_mae                 2.290643e-02    8.570056e-02    6.279413e-02\n",
      "esp_mae_kcal               14.373786       53.777104       39.403318 (kcal/mol/e)\n",
      "esp_rmse                6.898941e-02    9.181959e-02    2.283018e-02\n",
      "esp_rmse_kcal              43.290855       57.616794       14.325938 (kcal/mol/e)\n",
      "esp_r2_unmasked        -5.751801e-02   -8.610852e-01   -8.035672e-01\n",
      "esp_r2_masked          -1.453042e-03   -1.000000e+01   -9.998547e+00\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean           9.255840e-04    9.391200e-02    9.298641e-02\n",
      "esp_pred_std            1.721328e-03    3.990095e-02    3.817962e-02\n",
      "esp_error_mean         -1.382260e-02    7.912864e-02    9.295124e-02\n",
      "esp_error_std           6.759049e-02    4.657786e-02   -2.101263e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=1.046157e-04, std=1.934916e-03, min=-3.319087e-04, max=1.384381e-02\n",
      "  Valid: mean=8.515120e-03, std=2.063477e-03, min=-2.718985e-03, max=1.113515e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (2.49e+01) is 82.6x higher than training loss (3.02e-01)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.0575) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.8611) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "‚úì  Training monopoles OK (mean_abs=0.038398 e)\n",
      "‚úì  Validation monopoles OK (mean_abs=0.038579 e)\n",
      "\n",
      "================================================================================\n",
      "Epoch  15 Statistics\n",
      "================================================================================\n",
      "Metric                         Train           Valid      Difference\n",
      "--------------------------------------------------------------------------------\n",
      "loss                    3.013424e-01    2.559833e+01    2.529699e+01\n",
      "esp_loss                3.010055e-05    2.559531e-03    2.529431e-03\n",
      "mono_loss               3.360713e-01    3.382832e-01    2.211899e-03\n",
      "charge_conservation_loss    8.064436e-05    2.681805e-01    2.680999e-01\n",
      "esp_loss_weighted       3.010055e-01    2.559531e+01    2.529431e+01\n",
      "mono_loss_weighted      3.360713e-04    3.382832e-04    2.211862e-06\n",
      "charge_conservation_loss_weighted    8.064437e-07    2.681806e-03    2.680999e-03\n",
      "mono_mae                3.851002e-02    4.684063e-02    8.330610e-03\n",
      "mono_rmse               1.833225e-01    1.839248e-01    6.022900e-04\n",
      "mono_mean               1.428245e-04    8.628986e-03    8.486161e-03\n",
      "mono_std                1.916561e-03    2.063495e-03    1.469336e-04\n",
      "esp_mae                 2.281375e-02    8.683535e-02    6.402160e-02\n",
      "esp_mae_kcal               14.315628       54.489180       40.173552 (kcal/mol/e)\n",
      "esp_rmse                6.876230e-02    9.284917e-02    2.408686e-02\n",
      "esp_rmse_kcal              43.148345       58.262851       15.114506 (kcal/mol/e)\n",
      "esp_r2_unmasked        -5.056691e-02   -9.030559e-01   -8.524890e-01\n",
      "esp_r2_masked           2.173781e-04   -1.000000e+01   -1.000022e+01\n",
      "esp_mask_fraction       5.176112e-01    5.181573e-01    5.461667e-04\n",
      "esp_pred_mean           1.350136e-03    9.516856e-02    9.381842e-02\n",
      "esp_pred_std            1.660455e-03    4.043225e-02    3.877180e-02\n",
      "esp_error_mean         -1.339805e-02    8.038519e-02    9.378324e-02\n",
      "esp_error_std           6.744440e-02    4.646707e-02   -2.097733e-02\n",
      "--------------------------------------------------------------------------------\n",
      "Monopole Prediction Statistics:\n",
      "  Train: mean=1.428245e-04, std=1.916561e-03, min=-2.852312e-04, max=1.381872e-02\n",
      "  Valid: mean=8.628986e-03, std=2.063495e-03, min=-2.605627e-03, max=1.120683e-02\n",
      "\n",
      "================================================================================\n",
      "WARNINGS:\n",
      "  ‚ö†Ô∏è  Severe overfitting: validation loss (2.56e+01) is 84.9x higher than training loss (3.01e-01)\n",
      "  ‚ö†Ô∏è  Training ESP R¬≤ is negative (-0.0506) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation ESP R¬≤ is negative (-0.9031) - model performs worse than predicting the mean\n",
      "  ‚ö†Ô∏è  Validation masked ESP R¬≤ is very negative (-10.0000) - check masking logic\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Start training\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STARTING TRAINING\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "try:\n",
    "    final_params = train_model(\n",
    "        key=key,\n",
    "        model=model,\n",
    "        train_data=train_data,\n",
    "        valid_data=valid_data,\n",
    "        num_epochs=100,\n",
    "        learning_rate=0.001,\n",
    "        batch_size=1000,\n",
    "        esp_w=10000,\n",
    "        restart_params=pd.read_pickle(\"best_100000_params.pkl\"),\n",
    "        writer=None,\n",
    "        chg_w=0.001,\n",
    "        ndcm=args.n_dcm,\n",
    "        mono_imputation_fn=mono_imputation_fn,\n",
    "        num_atoms = 3,\n",
    "        use_grad_clip=False,\n",
    "        grad_clip_norm=100,\n",
    "        distance_weighting=False,\n",
    "        esp_magnitude_weighting=False,\n",
    "        charge_conservation_w=0.01,\n",
    "        # esp_grid_units=\"bohr\",  # Specify that grid is in Bohr\n",
    "        radii_cutoff_multiplier=4.0,\n",
    "        # tag=args.name,\n",
    "        # output_dir=args.output_dir,\n",
    "        # print_freq=args.print_freq,\n",
    "    )\n",
    "    \n",
    "    # Save final model\n",
    "    final_path = args.output_dir / f\"{args.name}_final.pkl\"\n",
    "    with open(final_path, 'wb') as f:\n",
    "        pickle.dump(final_params, f)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nFinal parameters saved to: {final_path}\")\n",
    "    print(f\"\\nTo use the trained model:\")\n",
    "    print(f\"  from mmml.dcmnet.dcmnet.modules import MessagePassingModel\")\n",
    "    print(f\"  import pickle\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Load parameters\")\n",
    "    print(f\"  with open('{final_path}', 'rb') as f:\")\n",
    "    print(f\"      params = pickle.load(f)\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Create model and predict\")\n",
    "    print(f\"  model = MessagePassingModel(...)\")\n",
    "    print(f\"  mono, dipo = model.apply(params, Z, R, dst_idx, src_idx)\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Calculate ESP\")\n",
    "    print(f\"  from mmml.dcmnet.dcmnet.electrostatics import calc_esp\")\n",
    "    print(f\"  esp_pred = calc_esp(mono, dipo, R, vdw_surface)\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n\\n‚ö†Ô∏è  Training interrupted by user\")\n",
    "    print(f\"Checkpoints saved to: {args.output_dir}\")\n",
    "    sys.exit(0)\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\n‚ùå Training failed with error:\")\n",
    "    print(f\"  {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5ca54-29d1-4323-9be8-66d8db33e4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12507cc-6ba2-4b45-8067-b6b02db1bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495dd84-69be-432c-9f7a-59075f389871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c80cfe-9c3b-4e9a-8cd4-6a57fcd5919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data[\"R\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91356807-f3f6-40ae-bc91-947efdb5aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmml.dcmnet.dcmnet.modules import MessagePassingModel\n",
    "import pickle\n",
    "import e3x\n",
    "# Load parameters\n",
    "with open('output/co2_dcmnet_final.pkl', 'rb') as f:\n",
    "  params = pickle.load(f)\n",
    "with open('best_10000_params.pkl', 'rb') as f:\n",
    "  params = pickle.load(f)\n",
    "# # Create model and predict\n",
    "# model = MessagePassingModel()\n",
    "dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(3)\n",
    "mono, dipo = model.apply(params, valid_data[\"Z\"][0], valid_data[\"R\"][0], dst_idx, src_idx)\n",
    "\n",
    "mono, dipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966698e1-e419-4627-92e2-a1a2832df5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mono[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57526152-73eb-4b1f-aac0-3c1862bd7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(valid_data[\"R\"][0])[:3,np.newaxis,:] - np.array(dipo[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb0ca3-cbe4-4bd5-a91b-1425b76692db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mono[:3]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df8ca4-021d-45bd-8a7d-6acd0adebee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mono[:3]), np.array(dipo[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8af8c1-554e-483f-a97d-782be97c8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dcm = model.n_dcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaec1ed-b0ea-42e6-99ea-da57e86445ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = jnp.moveaxis(dipo, -1, -2).reshape(1, 60 * n_dcm, 3)\n",
    "m = mono.reshape(1, 60 * n_dcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c8f9b-e5cc-4043-abec-ed1fc47a557b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66eb97-df6e-4f70-8938-74f4f7dd7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_esp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b1937d-7e07-4998-a9ed-33bc90583cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mmml.dcmnet.dcmnet.electrostatics import calc_esp\n",
    "esp_pred = calc_esp(d[:9], m[:9], valid_data[\"vdw_surface\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91457d2-53a2-4849-bf2b-80d1db71f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(esp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f93c6a-e048-48df-ac7b-5b42d702bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data[\"esp\"][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cd89a-45f7-4244-a6fa-2a1dab01ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(esp_pred), valid_data[\"esp\"][0] )\n",
    "# plt.xlim(-0.1, 0.1)\n",
    "# plt.ylim(-0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efcaa8-f90a-4f81-b737-61c4cd3fd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(esp_pred))\n",
    "plt.plot(valid_data[\"esp\"][0], alpha=0.1)\n",
    "plt.ylim(-0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d3fdc-8f9c-40f8-8375-488455d40646",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(esp_pred) - valid_data[\"esp\"][0], \"-o\", alpha=0.1)\n",
    "plt.ylim(-0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ecd4f-5ed1-4b52-b270-b5c0a56c20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "esp = valid_data[\"esp\"][0]         # (N,)\n",
    "grid = valid_data[\"vdw_surface\"][0]     # (N, 3) in Angstrom\n",
    "R =  valid_data[\"R\"][0]          # (M, 3)\n",
    "Z = valid_data[\"Z\"][0]               # (M,)\n",
    "\n",
    "# Define a cube (rectilinear) grid around the molecule\n",
    "pad = 4.0  # Angstrom padding\n",
    "mins = np.min(R, axis=0) - pad\n",
    "maxs = np.max(R, axis=0) + pad\n",
    "nx, ny, nz = 40, 40, 40\n",
    "xs = np.linspace(mins[0], maxs[0], nx)\n",
    "ys = np.linspace(mins[1], maxs[1], ny)\n",
    "zs = np.linspace(mins[2], maxs[2], nz)\n",
    "X, Y, Zz = np.meshgrid(xs, ys, zs, indexing=\"ij\")\n",
    "cube_points = np.stack([X, Y, Zz], axis=-1).reshape(-1, 3)\n",
    "\n",
    "# Interpolate scattered ESP onto the rectilinear grid (nearest-neighbor)\n",
    "from scipy.spatial import cKDTree\n",
    "tree = cKDTree(grid)\n",
    "_, idx = tree.query(cube_points, k=1)\n",
    "cube_values = esp[idx].reshape(nx, ny, nz)\n",
    "\n",
    "def write_cube(path, atoms_Z, atoms_R, origin, axes, values):\n",
    "    # values must be shaped (nx, ny, nz)\n",
    "    nx, ny, nz = values.shape\n",
    "    ax, ay, az = axes  # each is (3,) box vector in Angstrom / count\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(\"ESP cube generated by mmml\\n\")\n",
    "        f.write(\"ESP on a rectilinear grid\\n\")\n",
    "        f.write(f\"{len(atoms_Z):4d} {origin[0]:12.6f} {origin[1]:12.6f} {origin[2]:12.6f}\\n\")\n",
    "        f.write(f\"{nx:4d} {ax[0]:12.6f} {ax[1]:12.6f} {ax[2]:12.6f}\\n\")\n",
    "        f.write(f\"{ny:4d} {ay[0]:12.6f} {ay[1]:12.6f} {ay[2]:12.6f}\\n\")\n",
    "        f.write(f\"{nz:4d} {az[0]:12.6f} {az[1]:12.6f} {az[2]:12.6f}\\n\")\n",
    "        for Zq, Rq in zip(atoms_Z, atoms_R):\n",
    "            f.write(f\"{int(Zq):4d} {float(Zq):12.6f} {Rq[0]:12.6f} {Rq[1]:12.6f} {Rq[2]:12.6f}\\n\")\n",
    "        # Write voxel data, 6 values per line\n",
    "        count = 0\n",
    "        for i in range(nx):\n",
    "            for j in range(ny):\n",
    "                line_vals = []\n",
    "                for k in range(nz):\n",
    "                    line_vals.append(f\"{values[i, j, k]:13.5e}\")\n",
    "                    count += 1\n",
    "                    if len(line_vals) == 6:\n",
    "                        f.write(\" \".join(line_vals) + \"\\n\")\n",
    "                        line_vals = []\n",
    "                if line_vals:\n",
    "                    f.write(\" \".join(line_vals) + \"\\n\")\n",
    "\n",
    "# Build cube axes from box lengths\n",
    "ax = np.array([xs[1]-xs[0], 0.0, 0.0])\n",
    "ay = np.array([0.0, ys[1]-ys[0], 0.0])\n",
    "az = np.array([0.0, 0.0, zs[1]-zs[0]])\n",
    "write_cube(\n",
    "    \"esp.cube\",\n",
    "    atoms_Z=Z,\n",
    "    atoms_R=R,\n",
    "    origin=np.array([xs[0], ys[0], zs[0]]),\n",
    "    axes=(ax, ay, az),\n",
    "    values=cube_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43337d8-436e-49c5-8235-582c5abeeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = abs(valid_data[\"esp\"][0]) < 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5366738-a27a-42a9-970c-b74c1decc975",
   "metadata": {},
   "outputs": [],
   "source": [
    "VMAX = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8df62-8704-4a34-b17a-80b525d6af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a738d-3b2b-4f92-a8fc-b2dabd18fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "VDW = valid_data[\"vdw_surface\"][0]\n",
    "X,Y,Z = VDW.T\n",
    "plt.scatter(X[indices],Y[indices], c=esp_pred[indices], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
    "plt.scatter(X[indices],Z[indices], c=esp_pred[indices], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
    "plt.scatter(Y[indices],Z[indices], c=esp_pred[indices], vmin=-VMAX, vmax=VMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87b321-67b1-4243-a3ab-c11cb883c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VDW = valid_data[\"vdw_surface\"][0]\n",
    "X,Y,Z = VDW.T\n",
    "plt.scatter(X,Y, c= valid_data[\"esp\"][0], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
    "plt.scatter(X,Z, c= valid_data[\"esp\"][0], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
    "plt.scatter(Y,Z, c= valid_data[\"esp\"][0], vmin=-VMAX, vmax=VMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c078e-68ef-497e-9a81-c2f9ecee2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc04275-0b19-4545-a155-437d60716a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad057882-c5ef-4de1-8b58-08b7867b3839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86821789-c8b0-42ab-a9be-2c492e034e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
