{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce1a70c-eea0-43eb-a14b-e0433adb80e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovely_jax enabled for enhanced array visualization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CudaDevice(id=0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import *\n",
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3e1440-6d11-48d1-a104-299ce80d8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookArgs:\n",
    "    \"\"\"\n",
    "    Helper class to mimic argparse.Namespace for Jupyter notebooks.\n",
    "    Example:\n",
    "        args = NotebookArgs(\n",
    "            train_efd=\"../preclassified_data/energies_forces_dipoles_train.npz\",\n",
    "            train_grid=\"../preclassified_data/grids_esp_train.npz\",\n",
    "            valid_efd=\"../preclassified_data/energies_forces_dipoles_valid.npz\",\n",
    "            valid_grid=\"../preclassified_data/grids_esp_valid.npz\",\n",
    "            batch_size=16,\n",
    "            epochs=500,\n",
    "            n_dcm=3,\n",
    "            verbose=True,\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # Default values ‚Äî should match argparse defaults\n",
    "        defaults = dict(\n",
    "            train_efd=None,\n",
    "            train_grid=None,\n",
    "            valid_efd=None,\n",
    "            valid_grid=None,\n",
    "            features=32,\n",
    "            max_degree=2,\n",
    "            num_iterations=2,\n",
    "            num_basis_functions=32,\n",
    "            cutoff=10.0,\n",
    "            n_dcm=3,\n",
    "            include_pseudotensors=False,\n",
    "            batch_size=32,\n",
    "            epochs=100,\n",
    "            learning_rate=0.001,\n",
    "            esp_weight=10000.0,\n",
    "            seed=42,\n",
    "            restart=None,\n",
    "            name='co2_dcmnet',\n",
    "            output_dir='./checkpoints',\n",
    "            print_freq=10,\n",
    "            save_freq=5,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # Update defaults with user-specified values\n",
    "        defaults.update(kwargs)\n",
    "\n",
    "        # Assign all attributes\n",
    "        for key, val in defaults.items():\n",
    "            setattr(self, key, val)\n",
    "\n",
    "    def as_dict(self):\n",
    "        \"\"\"Return arguments as a plain dict (useful for logging).\"\"\"\n",
    "        return vars(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f86473-7bf8-4fa8-8739-f3f5e02d052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import main, load_co2_data\n",
    "\n",
    "\n",
    "args = NotebookArgs(\n",
    "    train_efd=Path(\"../preclassified_data/energies_forces_dipoles_train.npz\"),\n",
    "    train_grid=Path(\"../preclassified_data/grids_esp_train.npz\"),\n",
    "    valid_efd=Path(\"../preclassified_data/energies_forces_dipoles_valid.npz\"),\n",
    "    valid_grid=Path(\"../preclassified_data/grids_esp_valid.npz\"),\n",
    "    output_dir=Path(\"./output\"),\n",
    "    batch_size=1000,\n",
    "    epochs=5,\n",
    "    learning_rate=5e-4,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0be27f-d4ce-4eba-a2fb-1a2484038baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can call your functions directly\n",
    "train_data = load_co2_data(args.train_efd, args.train_grid)\n",
    "valid_data = load_co2_data(args.valid_efd, args.valid_grid)\n",
    "\n",
    "# Or if your `main()` function expects args like from argparse:\n",
    "# \n",
    "\n",
    "len(valid_data[\"R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34194dd0-de56-4c42-8bcf-5131b122eda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "train_model(\n",
       "    key,\n",
       "    model,\n",
       "    train_data,\n",
       "    valid_data,\n",
       "    num_epochs,\n",
       "    learning_rate,\n",
       "    batch_size,\n",
       "    writer,\n",
       "    ndcm,\n",
       "    esp_w=\u001b[32m1.0\u001b[39m,\n",
       "    chg_w=\u001b[32m0.01\u001b[39m,\n",
       "    restart_params=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    ema_decay=\u001b[32m0.999\u001b[39m,\n",
       "    num_atoms=\u001b[32m60\u001b[39m,\n",
       "    use_grad_clip=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    grad_clip_norm=\u001b[32m2.0\u001b[39m,\n",
       "    mono_imputation_fn=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Train DCMNet model with ESP and monopole losses.\n",
       "\n",
       "Performs full training loop with validation, logging, and checkpointing.\n",
       "Uses exponential moving average (EMA) for parameter smoothing and saves\n",
       "best parameters based on validation loss.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "key : jax.random.PRNGKey\n",
       "    Random key for training\n",
       "model : MessagePassingModel\n",
       "    DCMNet model instance\n",
       "train_data : dict\n",
       "    Training dataset dictionary\n",
       "valid_data : dict\n",
       "    Validation dataset dictionary\n",
       "num_epochs : int\n",
       "    Number of training epochs\n",
       "learning_rate : float\n",
       "    Learning rate for optimization\n",
       "batch_size : int\n",
       "    Batch size for training\n",
       "writer : SummaryWriter\n",
       "    TensorBoard writer for logging\n",
       "ndcm : int\n",
       "    Number of distributed multipoles per atom\n",
       "esp_w : float, optional\n",
       "    Weight for ESP loss term, by default 1.0\n",
       "chg_w : float, optional\n",
       "    Weight for charge/monopole loss term, by default 0.01\n",
       "restart_params : Any, optional\n",
       "    Parameters to restart from, by default None\n",
       "ema_decay : float, optional\n",
       "    Exponential moving average decay rate, by default 0.999\n",
       "num_atoms : int, optional\n",
       "    Maximum number of atoms for batching, by default 60\n",
       "use_grad_clip : bool, optional\n",
       "    Whether to use gradient clipping, by default False\n",
       "grad_clip_norm : float, optional\n",
       "    Maximum gradient norm for clipping, by default 2.0\n",
       "mono_imputation_fn : callable, optional\n",
       "    Function to impute monopoles if missing from batches. Should take a batch dict\n",
       "    and return monopoles with shape (batch_size * num_atoms,). By default None\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "tuple\n",
       "    (final_params, final_valid_loss)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/mmml/dcmnet/dcmnet/training.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?prepare_datasets\n",
    "?train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8c7e7b-b633-4124-9e0c-1186c963533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_charge_predictor import load_charge_data\n",
    "\n",
    "# # Use only HF level\n",
    "# R, Z, mono = load_charge_data(csv_file, scheme='Hirshfeld', level='hf')\n",
    "\n",
    "# # Use only MP2 level\n",
    "# R, Z, mono = load_charge_data(csv_file, scheme='Hirshfeld', level='mp2')\n",
    "\n",
    "# # Use all levels (default)\n",
    "# R, Z, mono = load_charge_data(csv_file, scheme='Hirshfeld', level=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d56ade3-5d28-4693-81c5-23e5d645abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CO2 Charge Predictor Training Example\n",
      "======================================================================\n",
      "\n",
      "Loading data...\n",
      "Loaded 27540 rows from ../detailed_charges/df_charges_long.csv\n",
      "Available schemes: ['Hirshfeld' 'VDD' 'Becke' 'ADCH' 'CHELPG' 'MK' 'CM5' 'MBIS' 'MBIS_raw']\n",
      "Available levels: ['hf' 'mp2']\n",
      "Using level: mp2, 13770 rows\n",
      "Using scheme: MBIS_raw, 1530 rows\n",
      "Found 510 unique geometry+level combinations\n",
      "\n",
      "Prepared data:\n",
      "  R shape: (510, 3, 3)\n",
      "  Z shape: (510, 3)\n",
      "  mono shape: (510, 3)\n",
      "\n",
      "Training models...\n",
      "\n",
      "======================================================================\n",
      "Training Gradient Boosting Charge Predictors\n",
      "======================================================================\n",
      "\n",
      "Computing molecular features...\n",
      "Feature matrix shape: (510, 12)\n",
      "\n",
      "======================================================================\n",
      "Training model for atom 0 (Z=6)\n",
      "======================================================================\n",
      "  Train samples: 408\n",
      "  Test samples: 102\n",
      "  Charge range: [0.7880, 1.4690]\n",
      "  Charge mean: 1.1948, std: 0.1349\n",
      "\n",
      "  Training...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0149           0.0029            0.17s\n",
      "         2           0.0114          -0.0006            0.15s\n",
      "         3           0.0096           0.0039            0.15s\n",
      "         4           0.0080           0.0027            0.14s\n",
      "         5           0.0063           0.0007            0.14s\n",
      "         6           0.0054           0.0023            0.14s\n",
      "         7           0.0045           0.0012            0.13s\n",
      "         8           0.0033          -0.0006            0.13s\n",
      "         9           0.0029           0.0015            0.13s\n",
      "        10           0.0023           0.0005            0.13s\n",
      "        20           0.0003           0.0001            0.11s\n",
      "        30           0.0000           0.0000            0.09s\n",
      "        40           0.0000           0.0000            0.08s\n",
      "        50           0.0000           0.0000            0.07s\n",
      "        60           0.0000          -0.0000            0.05s\n",
      "        70           0.0000          -0.0000            0.04s\n",
      "        80           0.0000          -0.0000            0.03s\n",
      "        90           0.0000          -0.0000            0.01s\n",
      "       100           0.0000          -0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000576\n",
      "    RMSE: 0.000735\n",
      "    R¬≤:   0.999970\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.006144\n",
      "    RMSE: 0.016929\n",
      "    R¬≤:   0.984799\n",
      "\n",
      "======================================================================\n",
      "Training model for atom 1 (Z=8)\n",
      "======================================================================\n",
      "  Train samples: 408\n",
      "  Test samples: 102\n",
      "  Charge range: [-0.7345, -0.2623]\n",
      "  Charge mean: -0.5146, std: 0.1162\n",
      "\n",
      "  Training...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0109           0.0024            0.14s\n",
      "         2           0.0086           0.0011            0.14s\n",
      "         3           0.0072           0.0026            0.13s\n",
      "         4           0.0060           0.0019            0.13s\n",
      "         5           0.0048           0.0007            0.13s\n",
      "         6           0.0039           0.0011            0.13s\n",
      "         7           0.0033           0.0012            0.13s\n",
      "         8           0.0025          -0.0003            0.12s\n",
      "         9           0.0021           0.0009            0.12s\n",
      "        10           0.0017           0.0004            0.12s\n",
      "        20           0.0002           0.0000            0.11s\n",
      "        30           0.0000           0.0000            0.09s\n",
      "        40           0.0000           0.0000            0.08s\n",
      "        50           0.0000           0.0000            0.07s\n",
      "        60           0.0000          -0.0000            0.05s\n",
      "        70           0.0000           0.0000            0.04s\n",
      "        80           0.0000          -0.0000            0.03s\n",
      "        90           0.0000           0.0000            0.01s\n",
      "       100           0.0000           0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000329\n",
      "    RMSE: 0.000414\n",
      "    R¬≤:   0.999987\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.002548\n",
      "    RMSE: 0.008003\n",
      "    R¬≤:   0.995176\n",
      "\n",
      "======================================================================\n",
      "Training model for atom 2 (Z=8)\n",
      "======================================================================\n",
      "  Train samples: 408\n",
      "  Test samples: 102\n",
      "  Charge range: [-0.7345, -0.4785]\n",
      "  Charge mean: -0.6802, std: 0.0374\n",
      "\n",
      "  Training...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.0012           0.0002            0.14s\n",
      "         2           0.0008          -0.0004            0.13s\n",
      "         3           0.0008           0.0005            0.13s\n",
      "         4           0.0006          -0.0002            0.13s\n",
      "         5           0.0005           0.0001            0.13s\n",
      "         6           0.0005           0.0005            0.13s\n",
      "         7           0.0004           0.0000            0.13s\n",
      "         8           0.0003          -0.0000            0.12s\n",
      "         9           0.0003           0.0001            0.12s\n",
      "        10           0.0002           0.0000            0.12s\n",
      "        20           0.0000           0.0000            0.11s\n",
      "        30           0.0000           0.0000            0.09s\n",
      "        40           0.0000          -0.0000            0.08s\n",
      "        50           0.0000           0.0000            0.07s\n",
      "        60           0.0000           0.0000            0.05s\n",
      "        70           0.0000           0.0000            0.04s\n",
      "        80           0.0000           0.0000            0.03s\n",
      "        90           0.0000           0.0000            0.01s\n",
      "       100           0.0000           0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000322\n",
      "    RMSE: 0.000406\n",
      "    R¬≤:   0.999876\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.003140\n",
      "    RMSE: 0.008604\n",
      "    R¬≤:   0.956313\n",
      "\n",
      "======================================================================\n",
      "Saving models to charge_predictor_MBIS_raw.pkl\n",
      "======================================================================\n",
      "Saved models and metadata\n",
      "\n",
      "======================================================================\n",
      "Training Complete!\n",
      "======================================================================\n",
      "\n",
      "Model saved to: charge_predictor_hirshfeld.pkl\n",
      "\n",
      "To use with DCMNet training:\n",
      "  from train_charge_predictor_usage import create_mono_imputation_fn_from_gb\n",
      "  mono_imputation_fn = create_mono_imputation_fn_from_gb('charge_predictor_hirshfeld.pkl')\n",
      "  train_model(..., mono_imputation_fn=mono_imputation_fn)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Quick example: Train charge predictor on CO2 data\n",
    "\n",
    "This script demonstrates how to train the gradient boosting charge predictor\n",
    "using the CO2 charge data.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from train_charge_predictor import load_charge_data, train_charge_predictor\n",
    "\n",
    "# Path to your data\n",
    "data_file = Path(\"../detailed_charges/df_charges_long.csv\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CO2 Charge Predictor Training Example\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load data - you can choose different schemes: Hirshfeld, VDD, Becke, etc.\n",
    "# and levels: hf, mp2\n",
    "print(\"\\nLoading data...\")\n",
    "R, Z, mono = load_charge_data(data_file, scheme='MBIS_raw', level='mp2')\n",
    "\n",
    "# Train models\n",
    "print(\"\\nTraining models...\")\n",
    "results = train_charge_predictor(\n",
    "    R=R,\n",
    "    Z=Z,\n",
    "    mono=mono,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    save_path=\"charge_predictor_MBIS_raw.pkl\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel saved to: charge_predictor_hirshfeld.pkl\")\n",
    "print(\"\\nTo use with DCMNet training:\")\n",
    "print(\"  from train_charge_predictor_usage import create_mono_imputation_fn_from_gb\")\n",
    "print(\"  mono_imputation_fn = create_mono_imputation_fn_from_gb('charge_predictor_hirshfeld.pkl')\")\n",
    "print(\"  train_model(..., mono_imputation_fn=mono_imputation_fn)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0eb290-1485-491f-bdb3-b5c0b9c8beb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m mono_imputation_fn(batch: Dict) -> jax.Array\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Impute monopoles for a batch.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "batch : dict\n",
       "    Batch dictionary containing 'Z', 'R', 'dst_idx', 'src_idx', 'batch_segments'\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "jnp.ndarray\n",
       "    Atomic monopoles with shape (batch_size * num_atoms,)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/examples/co2/dcmnet_train/train_charge_predictor_usage.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train_charge_predictor_usage import create_mono_imputation_fn_from_gb\n",
    "mono_imputation_fn = create_mono_imputation_fn_from_gb('charge_predictor_MBIS_raw.pkl')\n",
    "mono_imputation_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1131023a-d1ff-49c4-96de-891eb6014c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 3), (60, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"R\"][0].shape, train_data[\"R\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14acf1e9-ca77-4d24-b00a-c7fc70017fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['R', 'Z', 'N', 'esp', 'vdw_surface', 'Dxyz', 'E'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ceffbf2-ff6f-41db-a6c7-eb93e7a0f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize JAX random key\n",
    "key = jax.random.PRNGKey(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d03962-203a-4f0d-9e50-85bd9675565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Data Files:\n",
      "  Train EFD:  ../preclassified_data/energies_forces_dipoles_train.npz\n",
      "  Train Grid: ../preclassified_data/grids_esp_train.npz\n",
      "  Valid EFD:  ../preclassified_data/energies_forces_dipoles_valid.npz\n",
      "  Valid Grid: ../preclassified_data/grids_esp_valid.npz\n",
      "  Output: output/co2_dcmnet\n",
      "\n",
      "######################################################################\n",
      "# Loading Data\n",
      "######################################################################\n",
      "\n",
      "Loading training data...\n",
      "Loading validation data...\n",
      "\n",
      "‚úÖ Data loaded:\n",
      "  Training samples: 8000\n",
      "  Validation samples: 1000\n",
      "  Data keys: ['R', 'Z', 'N', 'esp', 'vdw_surface', 'Dxyz', 'E']\n",
      "\n",
      "Preparing datasets (computing edge lists, etc.)...\n",
      "‚úÖ Datasets prepared\n",
      "  Training batches: 7\n",
      "  Validation batches: 7\n",
      "\n",
      "######################################################################\n",
      "# Building Model\n",
      "######################################################################\n",
      "\n",
      "Model hyperparameters:\n",
      "  Features: 32\n",
      "  Max degree: 2\n",
      "  Message passing iterations: 2\n",
      "  Basis functions: 32\n",
      "  Cutoff: 10.0 √Ö\n",
      "  Distributed multipoles per atom: 3\n",
      "  Include pseudotensors: False\n",
      "\n",
      "‚úÖ Model created: DCMNet (n_dcm=3)\n",
      "\n",
      "######################################################################\n",
      "# Training Setup\n",
      "######################################################################\n",
      "\n",
      "Training hyperparameters:\n",
      "  Batch size: 1000\n",
      "  Epochs: 5\n",
      "  Learning rate: 0.0005\n",
      "  ESP weight: 10000.0\n",
      "  Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import Dict, Tuple, Optional, Any, Mapping\n",
    "\n",
    "# Add mmml to path\n",
    "# repo_root = Path(__file__).parent / \"../../..\"\n",
    "# sys.path.insert(0, str(repo_root.resolve()))\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from mmml.dcmnet.dcmnet.modules import MessagePassingModel\n",
    "from mmml.dcmnet.dcmnet.training import train_model\n",
    "# from mmml.dcmnet.dcmnet.data import prepare_datasets\n",
    "\n",
    "# Validate input files\n",
    "for fname, fpath in [\n",
    "    ('Train EFD', args.train_efd),\n",
    "    ('Train Grid', args.train_grid),\n",
    "    ('Valid EFD', args.valid_efd),\n",
    "    ('Valid Grid', args.valid_grid)\n",
    "]:\n",
    "    if not fpath.exists():\n",
    "        print(f\"‚ùå Error: {fname} file not found: {fpath}\")\n",
    "        raise FileNotFoundError(f\"{fname} file not found: {fpath}\")\n",
    "\n",
    "print(f\"\\nüìÅ Data Files:\")\n",
    "print(f\"  Train EFD:  {args.train_efd}\")\n",
    "print(f\"  Train Grid: {args.train_grid}\")\n",
    "print(f\"  Valid EFD:  {args.valid_efd}\")\n",
    "print(f\"  Valid Grid: {args.valid_grid}\")\n",
    "\n",
    "# Setup output directory\n",
    "args.output_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"  Output: {args.output_dir / args.name}\")\n",
    "\n",
    "# Load data\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Loading Data\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "if args.verbose:\n",
    "    print(f\"\\nLoading training data...\")\n",
    "train_data_raw = load_co2_data(args.train_efd, args.train_grid)\n",
    "\n",
    "if args.verbose:\n",
    "    print(f\"Loading validation data...\")\n",
    "valid_data_raw = load_co2_data(args.valid_efd, args.valid_grid)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded:\")\n",
    "print(f\"  Training samples: {len(train_data_raw['R'])}\")\n",
    "print(f\"  Validation samples: {len(valid_data_raw['R'])}\")\n",
    "print(f\"  Data keys: {list(train_data_raw.keys())}\")\n",
    "\n",
    "# Prepare datasets (convert to DCMnet format with edge lists, etc.)\n",
    "print(f\"\\nPreparing datasets (computing edge lists, etc.)...\")\n",
    "# train_data, valid_data = prepare_datasets(\n",
    "#     train_data_raw,\n",
    "#     valid_data_raw,\n",
    "#     num_valid = \n",
    "#     # cutoff=args.cutoff,\n",
    "#     # batch_size=args.batch_size,\n",
    "# )\n",
    "train_data = train_data_raw\n",
    "valid_data = valid_data_raw\n",
    "print(f\"‚úÖ Datasets prepared\")\n",
    "print(f\"  Training batches: {len(train_data)}\")\n",
    "print(f\"  Validation batches: {len(valid_data)}\")\n",
    "\n",
    "# Build model\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Building Model\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "print(f\"\\nModel hyperparameters:\")\n",
    "print(f\"  Features: {args.features}\")\n",
    "print(f\"  Max degree: {args.max_degree}\")\n",
    "print(f\"  Message passing iterations: {args.num_iterations}\")\n",
    "print(f\"  Basis functions: {args.num_basis_functions}\")\n",
    "print(f\"  Cutoff: {args.cutoff} √Ö\")\n",
    "print(f\"  Distributed multipoles per atom: {args.n_dcm}\")\n",
    "print(f\"  Include pseudotensors: {args.include_pseudotensors}\")\n",
    "\n",
    "model = MessagePassingModel(\n",
    "    features=args.features,\n",
    "    max_degree=args.max_degree,\n",
    "    num_iterations=args.num_iterations,\n",
    "    num_basis_functions=args.num_basis_functions,\n",
    "    cutoff=args.cutoff,\n",
    "    n_dcm=args.n_dcm,\n",
    "    include_pseudotensors=args.include_pseudotensors,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model created: DCMNet (n_dcm={args.n_dcm})\")\n",
    "\n",
    "# Training setup\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Training Setup\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "print(f\"\\nTraining hyperparameters:\")\n",
    "print(f\"  Batch size: {args.batch_size}\")\n",
    "print(f\"  Epochs: {args.epochs}\")\n",
    "print(f\"  Learning rate: {args.learning_rate}\")\n",
    "print(f\"  ESP weight: {args.esp_weight}\")\n",
    "print(f\"  Random seed: {args.seed}\")\n",
    "\n",
    "# Load restart parameters if provided\n",
    "restart_params = None\n",
    "if args.restart:\n",
    "    print(f\"\\nüìÇ Loading restart checkpoint: {args.restart}\")\n",
    "    with open(args.restart, 'rb') as f:\n",
    "        restart_params = pickle.load(f)\n",
    "    print(f\"‚úÖ Checkpoint loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b751cd86-5781-4308-b6e0-bbe3467035fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "prepare_datasets(\n",
       "    key,\n",
       "    num_train,\n",
       "    num_valid,\n",
       "    filename,\n",
       "    natoms=\u001b[32m60\u001b[39m,\n",
       "    clean=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    esp_mask=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    clip_esp=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Prepare datasets for training and validation.\n",
       "\n",
       "Wrapper function that calls prepare_multiple_datasets and then\n",
       "creates train/validation splits and dictionaries.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "key : jax.random.PRNGKey\n",
       "    Random key for dataset shuffling\n",
       "num_train : int\n",
       "    Number of training samples\n",
       "num_valid : int\n",
       "    Number of validation samples\n",
       "filename : str or list\n",
       "    Filename(s) to load datasets from\n",
       "clean : bool, optional\n",
       "    Whether to filter failed calculations, by default False\n",
       "esp_mask : bool, optional\n",
       "    Whether to create ESP masks, by default False\n",
       "clip_esp : bool, optional\n",
       "    Whether to clip ESP to first 1000 points, by default False\n",
       "natoms : int, optional\n",
       "    Maximum number of atoms per system, by default 60\n",
       "\n",
       "Returns\n",
       "-------\n",
       "tuple\n",
       "    A tuple containing train_data and valid_data dictionaries\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/mmml/dcmnet/dcmnet/data.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prepare_datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab49c8d7-f477-4f02-a29b-4eafcec321fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0052505,  0.0033848,  0.037617 , ...,  0.0093954, -0.023834 ,\n",
       "         0.0059184],\n",
       "       [ 0.0043249,  0.0058309, -0.0074244, ..., -0.017754 ,  0.013946 ,\n",
       "        -0.006544 ],\n",
       "       [ 0.018399 ,  0.011036 ,  0.0095978, ..., -0.011879 , -0.010322 ,\n",
       "         0.0057994],\n",
       "       ...,\n",
       "       [ 0.042213 ,  0.032696 , -0.011879 , ..., -0.0024751,  0.032268 ,\n",
       "         0.015244 ],\n",
       "       [-0.0083788,  0.0076804, -0.010421 , ..., -0.010508 ,  0.0033204,\n",
       "        -0.0011256],\n",
       "       [-0.031544 , -0.0094387, -0.0063055, ..., -0.014822 , -0.002533 ,\n",
       "        -0.0051037]], shape=(8000, 3000), dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"esp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d10d14-db80-4f1d-92f5-4673cee5b50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "train_model(\n",
       "    key,\n",
       "    model,\n",
       "    train_data,\n",
       "    valid_data,\n",
       "    num_epochs,\n",
       "    learning_rate,\n",
       "    batch_size,\n",
       "    writer,\n",
       "    ndcm,\n",
       "    esp_w=\u001b[32m1.0\u001b[39m,\n",
       "    chg_w=\u001b[32m0.01\u001b[39m,\n",
       "    restart_params=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    ema_decay=\u001b[32m0.999\u001b[39m,\n",
       "    num_atoms=\u001b[32m60\u001b[39m,\n",
       "    use_grad_clip=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    grad_clip_norm=\u001b[32m2.0\u001b[39m,\n",
       "    mono_imputation_fn=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Train DCMNet model with ESP and monopole losses.\n",
       "\n",
       "Performs full training loop with validation, logging, and checkpointing.\n",
       "Uses exponential moving average (EMA) for parameter smoothing and saves\n",
       "best parameters based on validation loss.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "key : jax.random.PRNGKey\n",
       "    Random key for training\n",
       "model : MessagePassingModel\n",
       "    DCMNet model instance\n",
       "train_data : dict\n",
       "    Training dataset dictionary\n",
       "valid_data : dict\n",
       "    Validation dataset dictionary\n",
       "num_epochs : int\n",
       "    Number of training epochs\n",
       "learning_rate : float\n",
       "    Learning rate for optimization\n",
       "batch_size : int\n",
       "    Batch size for training\n",
       "writer : SummaryWriter\n",
       "    TensorBoard writer for logging\n",
       "ndcm : int\n",
       "    Number of distributed multipoles per atom\n",
       "esp_w : float, optional\n",
       "    Weight for ESP loss term, by default 1.0\n",
       "chg_w : float, optional\n",
       "    Weight for charge/monopole loss term, by default 0.01\n",
       "restart_params : Any, optional\n",
       "    Parameters to restart from, by default None\n",
       "ema_decay : float, optional\n",
       "    Exponential moving average decay rate, by default 0.999\n",
       "num_atoms : int, optional\n",
       "    Maximum number of atoms for batching, by default 60\n",
       "use_grad_clip : bool, optional\n",
       "    Whether to use gradient clipping, by default False\n",
       "grad_clip_norm : float, optional\n",
       "    Maximum gradient norm for clipping, by default 2.0\n",
       "mono_imputation_fn : callable, optional\n",
       "    Function to impute monopoles if missing from batches. Should take a batch dict\n",
       "    and return monopoles with shape (batch_size * num_atoms,). By default None\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "tuple\n",
       "    (final_params, final_valid_loss)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/mmml/dcmnet/dcmnet/training.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d966dad-dce0-4e88-8ebb-a592bd76d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STARTING TRAINING\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start training\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STARTING TRAINING\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "try:\n",
    "    final_params = train_model(\n",
    "        key=key,\n",
    "        model=model,\n",
    "        train_data=train_data,\n",
    "        valid_data=valid_data,\n",
    "        num_epochs=args.epochs,\n",
    "        learning_rate=args.learning_rate,\n",
    "        batch_size=args.batch_size,\n",
    "        esp_w=args.esp_weight,\n",
    "        restart_params=restart_params,\n",
    "        writer=None,\n",
    "        ndcm=args.n_dcm,\n",
    "        mono_imputation_fn=mono_imputation_fn,\n",
    "        # num_atoms = 3,\n",
    "        # tag=args.name,\n",
    "        # output_dir=args.output_dir,\n",
    "        # print_freq=args.print_freq,\n",
    "        # save_freq=args.save_freq,\n",
    "    )\n",
    "    \n",
    "    # Save final model\n",
    "    final_path = args.output_dir / f\"{args.name}_final.pkl\"\n",
    "    with open(final_path, 'wb') as f:\n",
    "        pickle.dump(final_params, f)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nFinal parameters saved to: {final_path}\")\n",
    "    print(f\"\\nTo use the trained model:\")\n",
    "    print(f\"  from mmml.dcmnet.dcmnet.modules import MessagePassingModel\")\n",
    "    print(f\"  import pickle\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Load parameters\")\n",
    "    print(f\"  with open('{final_path}', 'rb') as f:\")\n",
    "    print(f\"      params = pickle.load(f)\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Create model and predict\")\n",
    "    print(f\"  model = MessagePassingModel(...)\")\n",
    "    print(f\"  mono, dipo = model.apply(params, Z, R, dst_idx, src_idx)\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Calculate ESP\")\n",
    "    print(f\"  from mmml.dcmnet.dcmnet.electrostatics import calc_esp\")\n",
    "    print(f\"  esp_pred = calc_esp(mono, dipo, R, vdw_surface)\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n\\n‚ö†Ô∏è  Training interrupted by user\")\n",
    "    print(f\"Checkpoints saved to: {args.output_dir}\")\n",
    "    sys.exit(0)\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\n‚ùå Training failed with error:\")\n",
    "    print(f\"  {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91356807-f3f6-40ae-bc91-947efdb5aaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c078e-68ef-497e-9a81-c2f9ecee2ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
