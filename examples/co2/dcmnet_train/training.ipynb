{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce1a70c-eea0-43eb-a14b-e0433adb80e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovely_jax enabled for enhanced array visualization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CudaDevice(id=0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import *\n",
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3e1440-6d11-48d1-a104-299ce80d8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookArgs:\n",
    "    \"\"\"\n",
    "    Helper class to mimic argparse.Namespace for Jupyter notebooks.\n",
    "    Example:\n",
    "        args = NotebookArgs(\n",
    "            train_efd=\"../preclassified_data/energies_forces_dipoles_train.npz\",\n",
    "            train_grid=\"../preclassified_data/grids_esp_train.npz\",\n",
    "            valid_efd=\"../preclassified_data/energies_forces_dipoles_valid.npz\",\n",
    "            valid_grid=\"../preclassified_data/grids_esp_valid.npz\",\n",
    "            batch_size=16,\n",
    "            epochs=500,\n",
    "            n_dcm=3,\n",
    "            verbose=True,\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # Default values ‚Äî should match argparse defaults\n",
    "        defaults = dict(\n",
    "            train_efd=None,\n",
    "            train_grid=None,\n",
    "            valid_efd=None,\n",
    "            valid_grid=None,\n",
<<<<<<< HEAD
    "            features=128,\n",
    "            max_degree=2,\n",
    "            num_iterations=2,\n",
    "            num_basis_functions=128,\n",
    "            cutoff=10.0,\n",
    "            n_dcm=4,\n",
=======
    "            features=256,\n",
    "            max_degree=2,\n",
    "            num_iterations=3,\n",
    "            num_basis_functions=256,\n",
    "            cutoff=10.0,\n",
    "            n_dcm=6,\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
    "            include_pseudotensors=False,\n",
    "            batch_size=1000,\n",
    "            epochs=100,\n",
    "            learning_rate=0.001,\n",
    "            esp_weight=10000.0,\n",
    "            seed=42,\n",
    "            restart=None,\n",
    "            name='co2_dcmnet',\n",
    "            output_dir='./checkpoints',\n",
    "            print_freq=10,\n",
    "            save_freq=5,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # Update defaults with user-specified values\n",
    "        defaults.update(kwargs)\n",
    "\n",
    "        # Assign all attributes\n",
    "        for key, val in defaults.items():\n",
    "            setattr(self, key, val)\n",
    "\n",
    "    def as_dict(self):\n",
    "        \"\"\"Return arguments as a plain dict (useful for logging).\"\"\"\n",
    "        return vars(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f86473-7bf8-4fa8-8739-f3f5e02d052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import main, load_co2_data\n",
    "\n",
    "\n",
    "args = NotebookArgs(\n",
    "    train_efd=Path(\"../preclassified_data/energies_forces_dipoles_train.npz\"),\n",
    "    train_grid=Path(\"../preclassified_data/grids_esp_train.npz\"),\n",
    "    valid_efd=Path(\"../preclassified_data/energies_forces_dipoles_valid.npz\"),\n",
    "    valid_grid=Path(\"../preclassified_data/grids_esp_valid.npz\"),\n",
    "    output_dir=Path(\"./output\"),\n",
    "    batch_size=1000,\n",
    "    epochs=5000,\n",
    "    learning_rate=5e-4,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0be27f-d4ce-4eba-a2fb-1a2484038baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can call your functions directly\n",
    "train_data = load_co2_data(args.train_efd, args.train_grid)\n",
    "valid_data = load_co2_data(args.valid_efd, args.valid_grid)\n",
    "\n",
    "# Or if your `main()` function expects args like from argparse:\n",
    "# \n",
    "\n",
    "len(valid_data[\"R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34194dd0-de56-4c42-8bcf-5131b122eda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "train_model(\n",
       "    key,\n",
       "    model,\n",
       "    train_data,\n",
       "    valid_data,\n",
       "    num_epochs,\n",
       "    learning_rate,\n",
       "    batch_size,\n",
       "    writer,\n",
       "    ndcm,\n",
       "    esp_w=\u001b[32m1.0\u001b[39m,\n",
       "    chg_w=\u001b[32m0.01\u001b[39m,\n",
       "    restart_params=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    ema_decay=\u001b[32m0.999\u001b[39m,\n",
       "    num_atoms=\u001b[32m60\u001b[39m,\n",
       "    use_grad_clip=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    grad_clip_norm=\u001b[32m2.0\u001b[39m,\n",
       "    mono_imputation_fn=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    distance_weighting=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    distance_scale=\u001b[32m2.0\u001b[39m,\n",
       "    distance_min=\u001b[32m0.5\u001b[39m,\n",
       "    esp_magnitude_weighting=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    charge_conservation_w=\u001b[32m1.0\u001b[39m,\n",
<<<<<<< HEAD
       "    esp_grid_units=\u001b[33m'angstrom'\u001b[39m,\n",
       "    radii_cutoff_multiplier=\u001b[32m2.0\u001b[39m,\n",
=======
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Train DCMNet model with ESP and monopole losses.\n",
       "\n",
       "Performs full training loop with validation, logging, and checkpointing.\n",
       "Uses exponential moving average (EMA) for parameter smoothing and saves\n",
       "best parameters based on validation loss.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "key : jax.random.PRNGKey\n",
       "    Random key for training\n",
       "model : MessagePassingModel\n",
       "    DCMNet model instance\n",
       "train_data : dict\n",
       "    Training dataset dictionary\n",
       "valid_data : dict\n",
       "    Validation dataset dictionary\n",
       "num_epochs : int\n",
       "    Number of training epochs\n",
       "learning_rate : float\n",
       "    Learning rate for optimization\n",
       "batch_size : int\n",
       "    Batch size for training\n",
       "writer : SummaryWriter\n",
       "    TensorBoard writer for logging\n",
       "ndcm : int\n",
       "    Number of distributed multipoles per atom\n",
       "esp_w : float, optional\n",
       "    Weight for ESP loss term, by default 1.0\n",
       "chg_w : float, optional\n",
       "    Weight for charge/monopole loss term, by default 0.01\n",
       "restart_params : Any, optional\n",
       "    Parameters to restart from, by default None\n",
       "ema_decay : float, optional\n",
       "    Exponential moving average decay rate, by default 0.999\n",
       "num_atoms : int, optional\n",
       "    Maximum number of atoms for batching, by default 60\n",
       "use_grad_clip : bool, optional\n",
       "    Whether to use gradient clipping, by default False\n",
       "grad_clip_norm : float, optional\n",
       "    Maximum gradient norm for clipping, by default 2.0\n",
       "mono_imputation_fn : callable, optional\n",
       "    Function to impute monopoles if missing from batches. Should take a batch dict\n",
       "    and return monopoles with shape (batch_size * num_atoms,). By default None\n",
       "distance_weighting : bool, optional\n",
       "    Whether to apply distance-based weighting to ESP loss. Errors further from atoms\n",
       "    will have HIGHER weight (reversed from typical). By default False\n",
       "distance_scale : float, optional\n",
       "    Scale parameter for distance weighting (in Angstroms). Larger values give slower\n",
       "    increase with distance. Weight = exp((distance - distance_min) / distance_scale),\n",
       "    normalized to have mean=1. By default 2.0\n",
       "distance_min : float, optional\n",
       "    Minimum distance for weighting (in Angstroms). Distances below this are clamped\n",
       "    to avoid singularities. By default 0.5\n",
       "esp_magnitude_weighting : bool, optional\n",
       "    Whether to weight by ESP magnitude instead of distance. Errors at points with\n",
       "    larger |ESP| values will have LOWER weight. This reduces the impact of points\n",
       "    where nuclear-electron shielding occurs and ESP approaches singularity (near\n",
       "    atomic nuclei). By default False\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "tuple\n",
       "    (final_params, final_valid_loss)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/mmml/dcmnet/dcmnet/training.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?prepare_datasets\n",
    "?train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8c7e7b-b633-4124-9e0c-1186c963533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_charge_predictor import load_charge_data\n",
    "\n",
    "# # Use only HF level\n",
    "# R, Z, mono = load_charge_data(csv_file, scheme='Hirshfeld', level='hf')\n",
    "\n",
    "# # Use only MP2 level\n",
    "# R, Z, mono = load_charge_data(csv_file, scheme='Hirshfeld', level='mp2')\n",
    "\n",
    "# # Use all levels (default)\n",
    "# R, Z, mono = load_charge_data(csv_file, scheme='Hirshfeld', level=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d56ade3-5d28-4693-81c5-23e5d645abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CO2 Charge Predictor Training Example\n",
      "======================================================================\n",
      "\n",
      "Loading data...\n",
      "Loaded 27540 rows from ../detailed_charges/df_charges_long.csv\n",
      "Available schemes: ['Hirshfeld' 'VDD' 'Becke' 'ADCH' 'CHELPG' 'MK' 'CM5' 'MBIS' 'MBIS_raw']\n",
      "Available levels: ['hf' 'mp2']\n",
      "Using level: mp2, 13770 rows\n",
      "Using scheme: MBIS_raw, 1530 rows\n",
      "Found 510 unique geometry+level combinations\n",
      "\n",
      "Prepared data:\n",
      "  R shape: (510, 3, 3)\n",
      "  Z shape: (510, 3)\n",
      "  mono shape: (510, 3)\n",
      "\n",
      "Training models...\n",
      "\n",
      "======================================================================\n",
      "Training Gradient Boosting Charge Predictors\n",
      "======================================================================\n",
      "\n",
      "Computing molecular features...\n",
      "Feature matrix shape: (510, 12)\n",
      "\n",
      "======================================================================\n",
      "Training model for atom 0 (Z=6)\n",
      "======================================================================\n",
<<<<<<< HEAD
      "  Train samples: 504\n",
      "  Test samples: 6\n",
=======
      "  Train samples: 408\n",
      "  Test samples: 102\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "  Charge range: [0.7880, 1.4690]\n",
      "  Charge mean: 1.1948, std: 0.1349\n",
      "\n",
      "  Training...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
<<<<<<< HEAD
      "         1           0.0152           0.0029            0.20s\n",
      "         2           0.0125           0.0028            0.18s\n",
      "         3           0.0104           0.0031            0.17s\n",
      "         4           0.0078          -0.0011            0.16s\n",
      "         5           0.0069           0.0035            0.16s\n",
      "         6           0.0052          -0.0007            0.16s\n",
      "         7           0.0044           0.0018            0.16s\n",
      "         8           0.0036           0.0010            0.15s\n",
      "         9           0.0028          -0.0001            0.15s\n",
      "        10           0.0023           0.0007            0.15s\n",
      "        20           0.0003           0.0001            0.13s\n",
      "        30           0.0001           0.0000            0.11s\n",
      "        40           0.0000           0.0000            0.10s\n",
      "        50           0.0000          -0.0000            0.08s\n",
      "        60           0.0000           0.0000            0.06s\n",
      "        70           0.0000           0.0000            0.05s\n",
      "        80           0.0000          -0.0000            0.03s\n",
      "        90           0.0000          -0.0000            0.02s\n",
      "       100           0.0000           0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000545\n",
      "    RMSE: 0.000698\n",
      "    R¬≤:   0.999973\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.001053\n",
      "    RMSE: 0.001111\n",
      "    R¬≤:   0.999846\n",
=======
      "         1           0.0149           0.0029            0.17s\n",
      "         2           0.0114          -0.0006            0.15s\n",
      "         3           0.0096           0.0039            0.15s\n",
      "         4           0.0080           0.0027            0.14s\n",
      "         5           0.0063           0.0007            0.14s\n",
      "         6           0.0054           0.0023            0.14s\n",
      "         7           0.0045           0.0012            0.13s\n",
      "         8           0.0033          -0.0006            0.13s\n",
      "         9           0.0029           0.0015            0.13s\n",
      "        10           0.0023           0.0005            0.13s\n",
      "        20           0.0003           0.0001            0.11s\n",
      "        30           0.0000           0.0000            0.10s\n",
      "        40           0.0000           0.0000            0.08s\n",
      "        50           0.0000           0.0000            0.07s\n",
      "        60           0.0000          -0.0000            0.05s\n",
      "        70           0.0000          -0.0000            0.04s\n",
      "        80           0.0000          -0.0000            0.03s\n",
      "        90           0.0000          -0.0000            0.01s\n",
      "       100           0.0000          -0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000576\n",
      "    RMSE: 0.000735\n",
      "    R¬≤:   0.999970\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.006144\n",
      "    RMSE: 0.016929\n",
      "    R¬≤:   0.984799\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "\n",
      "======================================================================\n",
      "Training model for atom 1 (Z=8)\n",
      "======================================================================\n",
<<<<<<< HEAD
      "  Train samples: 504\n",
      "  Test samples: 6\n",
=======
      "  Train samples: 408\n",
      "  Test samples: 102\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "  Charge range: [-0.7345, -0.2623]\n",
      "  Charge mean: -0.5146, std: 0.1162\n",
      "\n",
      "  Training...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
<<<<<<< HEAD
      "         1           0.0112           0.0023            0.16s\n",
      "         2           0.0091           0.0021            0.16s\n",
      "         3           0.0075           0.0019            0.15s\n",
      "         4           0.0058          -0.0001            0.15s\n",
      "         5           0.0050           0.0023            0.15s\n",
      "         6           0.0037          -0.0004            0.15s\n",
      "         7           0.0032           0.0014            0.15s\n",
      "         8           0.0026           0.0007            0.15s\n",
      "         9           0.0020           0.0000            0.14s\n",
      "        10           0.0017           0.0006            0.14s\n",
      "        20           0.0002           0.0001            0.13s\n",
      "        30           0.0000           0.0000            0.11s\n",
      "        40           0.0000           0.0000            0.09s\n",
      "        50           0.0000          -0.0000            0.08s\n",
      "        60           0.0000           0.0000            0.06s\n",
      "        70           0.0000           0.0000            0.05s\n",
      "        80           0.0000          -0.0000            0.03s\n",
      "        90           0.0000          -0.0000            0.02s\n",
      "       100           0.0000           0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000378\n",
      "    RMSE: 0.000490\n",
      "    R¬≤:   0.999982\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.000756\n",
      "    RMSE: 0.001206\n",
      "    R¬≤:   0.999861\n",
=======
      "         1           0.0109           0.0024            0.14s\n",
      "         2           0.0086           0.0011            0.13s\n",
      "         3           0.0072           0.0026            0.13s\n",
      "         4           0.0060           0.0019            0.13s\n",
      "         5           0.0048           0.0007            0.13s\n",
      "         6           0.0039           0.0011            0.13s\n",
      "         7           0.0033           0.0012            0.13s\n",
      "         8           0.0025          -0.0003            0.13s\n",
      "         9           0.0021           0.0009            0.12s\n",
      "        10           0.0017           0.0004            0.12s\n",
      "        20           0.0002           0.0000            0.11s\n",
      "        30           0.0000           0.0000            0.09s\n",
      "        40           0.0000           0.0000            0.08s\n",
      "        50           0.0000           0.0000            0.07s\n",
      "        60           0.0000          -0.0000            0.05s\n",
      "        70           0.0000           0.0000            0.04s\n",
      "        80           0.0000          -0.0000            0.03s\n",
      "        90           0.0000           0.0000            0.01s\n",
      "       100           0.0000           0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000329\n",
      "    RMSE: 0.000414\n",
      "    R¬≤:   0.999987\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.002548\n",
      "    RMSE: 0.008003\n",
      "    R¬≤:   0.995176\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "\n",
      "======================================================================\n",
      "Training model for atom 2 (Z=8)\n",
      "======================================================================\n",
<<<<<<< HEAD
      "  Train samples: 504\n",
      "  Test samples: 6\n",
=======
      "  Train samples: 408\n",
      "  Test samples: 102\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "  Charge range: [-0.7345, -0.4785]\n",
      "  Charge mean: -0.6802, std: 0.0374\n",
      "\n",
      "  Training...\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
<<<<<<< HEAD
      "         1           0.0012           0.0002            0.16s\n",
      "         2           0.0010           0.0002            0.16s\n",
      "         3           0.0009           0.0003            0.16s\n",
      "         4           0.0007          -0.0001            0.15s\n",
      "         5           0.0006           0.0002            0.15s\n",
      "         6           0.0005          -0.0000            0.15s\n",
      "         7           0.0004           0.0000            0.15s\n",
      "         8           0.0003           0.0001            0.15s\n",
      "         9           0.0003           0.0000            0.15s\n",
      "        10           0.0002           0.0000            0.14s\n",
      "        20           0.0000           0.0000            0.13s\n",
      "        30           0.0000           0.0000            0.11s\n",
      "        40           0.0000           0.0000            0.09s\n",
      "        50           0.0000           0.0000            0.08s\n",
      "        60           0.0000           0.0000            0.06s\n",
      "        70           0.0000           0.0000            0.05s\n",
      "        80           0.0000          -0.0000            0.03s\n",
      "        90           0.0000          -0.0000            0.02s\n",
      "       100           0.0000           0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000350\n",
      "    RMSE: 0.000448\n",
      "    R¬≤:   0.999857\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.000581\n",
      "    RMSE: 0.000657\n",
      "    R¬≤:   0.999568\n",
=======
      "         1           0.0012           0.0002            0.14s\n",
      "         2           0.0008          -0.0004            0.14s\n",
      "         3           0.0008           0.0005            0.13s\n",
      "         4           0.0006          -0.0002            0.13s\n",
      "         5           0.0005           0.0001            0.13s\n",
      "         6           0.0005           0.0005            0.13s\n",
      "         7           0.0004           0.0000            0.13s\n",
      "         8           0.0003          -0.0000            0.13s\n",
      "         9           0.0003           0.0001            0.13s\n",
      "        10           0.0002           0.0000            0.12s\n",
      "        20           0.0000           0.0000            0.11s\n",
      "        30           0.0000           0.0000            0.10s\n",
      "        40           0.0000          -0.0000            0.08s\n",
      "        50           0.0000           0.0000            0.07s\n",
      "        60           0.0000           0.0000            0.05s\n",
      "        70           0.0000           0.0000            0.04s\n",
      "        80           0.0000           0.0000            0.03s\n",
      "        90           0.0000           0.0000            0.01s\n",
      "       100           0.0000           0.0000            0.00s\n",
      "\n",
      "  Training Metrics:\n",
      "    MAE:  0.000322\n",
      "    RMSE: 0.000406\n",
      "    R¬≤:   0.999876\n",
      "\n",
      "  Test Metrics:\n",
      "    MAE:  0.003140\n",
      "    RMSE: 0.008604\n",
      "    R¬≤:   0.956313\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "\n",
      "======================================================================\n",
      "Saving models to charge_predictor_MBIS_raw.pkl\n",
      "======================================================================\n",
      "Saved models and metadata\n",
      "\n",
      "======================================================================\n",
      "Training Complete!\n",
      "======================================================================\n",
      "\n",
      "Model saved to: charge_predictor_hirshfeld.pkl\n",
      "\n",
      "To use with DCMNet training:\n",
      "  from train_charge_predictor_usage import create_mono_imputation_fn_from_gb\n",
      "  mono_imputation_fn = create_mono_imputation_fn_from_gb('charge_predictor_hirshfeld.pkl')\n",
      "  train_model(..., mono_imputation_fn=mono_imputation_fn)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Quick example: Train charge predictor on CO2 data\n",
    "\n",
    "This script demonstrates how to train the gradient boosting charge predictor\n",
    "using the CO2 charge data.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from train_charge_predictor import load_charge_data, train_charge_predictor\n",
    "\n",
    "# Path to your data\n",
    "data_file = Path(\"../detailed_charges/df_charges_long.csv\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CO2 Charge Predictor Training Example\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load data - you can choose different schemes: Hirshfeld, VDD, Becke, etc.\n",
    "# and levels: hf, mp2\n",
    "print(\"\\nLoading data...\")\n",
    "R, Z, mono = load_charge_data(data_file, scheme='MBIS_raw', level='mp2')\n",
    "\n",
    "# Train models\n",
    "print(\"\\nTraining models...\")\n",
    "results = train_charge_predictor(\n",
    "    R=R,\n",
    "    Z=Z,\n",
    "    mono=mono,\n",
<<<<<<< HEAD
    "    test_size=0.01,\n",
=======
    "    test_size=0.2,\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    save_path=\"charge_predictor_MBIS_raw.pkl\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Training Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nModel saved to: charge_predictor_hirshfeld.pkl\")\n",
    "print(\"\\nTo use with DCMNet training:\")\n",
    "print(\"  from train_charge_predictor_usage import create_mono_imputation_fn_from_gb\")\n",
    "print(\"  mono_imputation_fn = create_mono_imputation_fn_from_gb('charge_predictor_hirshfeld.pkl')\")\n",
    "print(\"  train_model(..., mono_imputation_fn=mono_imputation_fn)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0eb290-1485-491f-bdb3-b5c0b9c8beb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m mono_imputation_fn(batch: Dict) -> jax.Array\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Impute monopoles for a batch.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "batch : dict\n",
       "    Batch dictionary containing 'Z', 'R', 'dst_idx', 'src_idx', 'batch_segments'\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "jnp.ndarray\n",
       "    Atomic monopoles with shape (batch_size * num_atoms,)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/examples/co2/dcmnet_train/train_charge_predictor_usage.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train_charge_predictor_usage import create_mono_imputation_fn_from_gb\n",
    "mono_imputation_fn = create_mono_imputation_fn_from_gb('charge_predictor_MBIS_raw.pkl')\n",
    "mono_imputation_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1131023a-d1ff-49c4-96de-891eb6014c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 3), (60, 3))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"R\"][0].shape, train_data[\"R\"][0].shape"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "id": "59796b55-16d7-418d-818c-b001027a2d47",
   "metadata": {},
   "source": [
    "#  3\n"
   ]
  },
  {
=======
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   "cell_type": "code",
   "execution_count": 10,
   "id": "14acf1e9-ca77-4d24-b00a-c7fc70017fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['R', 'Z', 'N', 'esp', 'vdw_surface', 'Dxyz', 'E'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ceffbf2-ff6f-41db-a6c7-eb93e7a0f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize JAX random key\n",
    "key = jax.random.PRNGKey(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d03962-203a-4f0d-9e50-85bd9675565b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Data Files:\n",
      "  Train EFD:  ../preclassified_data/energies_forces_dipoles_train.npz\n",
      "  Train Grid: ../preclassified_data/grids_esp_train.npz\n",
      "  Valid EFD:  ../preclassified_data/energies_forces_dipoles_valid.npz\n",
      "  Valid Grid: ../preclassified_data/grids_esp_valid.npz\n",
      "  Output: output/co2_dcmnet\n",
      "\n",
      "######################################################################\n",
      "# Loading Data\n",
      "######################################################################\n",
      "\n",
      "Loading training data...\n",
      "Loading validation data...\n",
      "\n",
      "‚úÖ Data loaded:\n",
      "  Training samples: 8000\n",
      "  Validation samples: 1000\n",
      "  Data keys: ['R', 'Z', 'N', 'esp', 'vdw_surface', 'Dxyz', 'E']\n",
      "\n",
      "Preparing datasets (computing edge lists, etc.)...\n",
      "‚úÖ Datasets prepared\n",
      "  Training batches: 7\n",
      "  Validation batches: 7\n",
      "\n",
      "######################################################################\n",
      "# Building Model\n",
      "######################################################################\n",
      "\n",
      "Model hyperparameters:\n",
<<<<<<< HEAD
      "  Features: 128\n",
      "  Max degree: 2\n",
      "  Message passing iterations: 2\n",
      "  Basis functions: 128\n",
      "  Cutoff: 10.0 √Ö\n",
      "  Distributed multipoles per atom: 4\n",
      "  Include pseudotensors: False\n",
      "\n",
      "‚úÖ Model created: DCMNet (n_dcm=4)\n",
=======
      "  Features: 256\n",
      "  Max degree: 2\n",
      "  Message passing iterations: 3\n",
      "  Basis functions: 256\n",
      "  Cutoff: 10.0 √Ö\n",
      "  Distributed multipoles per atom: 6\n",
      "  Include pseudotensors: False\n",
      "\n",
      "‚úÖ Model created: DCMNet (n_dcm=6)\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "\n",
      "######################################################################\n",
      "# Training Setup\n",
      "######################################################################\n",
      "\n",
      "Training hyperparameters:\n",
      "  Batch size: 1000\n",
      "  Epochs: 5000\n",
      "  Learning rate: 0.0005\n",
      "  ESP weight: 10000.0\n",
      "  Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import Dict, Tuple, Optional, Any, Mapping\n",
    "\n",
    "# Add mmml to path\n",
    "# repo_root = Path(__file__).parent / \"../../..\"\n",
    "# sys.path.insert(0, str(repo_root.resolve()))\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from mmml.dcmnet.dcmnet.modules import MessagePassingModel\n",
    "from mmml.dcmnet.dcmnet.training import train_model\n",
    "# from mmml.dcmnet.dcmnet.data import prepare_datasets\n",
    "\n",
    "# Validate input files\n",
    "for fname, fpath in [\n",
    "    ('Train EFD', args.train_efd),\n",
    "    ('Train Grid', args.train_grid),\n",
    "    ('Valid EFD', args.valid_efd),\n",
    "    ('Valid Grid', args.valid_grid)\n",
    "]:\n",
    "    if not fpath.exists():\n",
    "        print(f\"‚ùå Error: {fname} file not found: {fpath}\")\n",
    "        raise FileNotFoundError(f\"{fname} file not found: {fpath}\")\n",
    "\n",
    "print(f\"\\nüìÅ Data Files:\")\n",
    "print(f\"  Train EFD:  {args.train_efd}\")\n",
    "print(f\"  Train Grid: {args.train_grid}\")\n",
    "print(f\"  Valid EFD:  {args.valid_efd}\")\n",
    "print(f\"  Valid Grid: {args.valid_grid}\")\n",
    "\n",
    "# Setup output directory\n",
    "args.output_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"  Output: {args.output_dir / args.name}\")\n",
    "\n",
    "# Load data\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Loading Data\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "if args.verbose:\n",
    "    print(f\"\\nLoading training data...\")\n",
    "train_data_raw = load_co2_data(args.train_efd, args.train_grid)\n",
    "\n",
    "if args.verbose:\n",
    "    print(f\"Loading validation data...\")\n",
    "valid_data_raw = load_co2_data(args.valid_efd, args.valid_grid)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded:\")\n",
    "print(f\"  Training samples: {len(train_data_raw['R'])}\")\n",
    "print(f\"  Validation samples: {len(valid_data_raw['R'])}\")\n",
    "print(f\"  Data keys: {list(train_data_raw.keys())}\")\n",
    "\n",
    "# Prepare datasets (convert to DCMnet format with edge lists, etc.)\n",
    "print(f\"\\nPreparing datasets (computing edge lists, etc.)...\")\n",
    "# train_data, valid_data = prepare_datasets(\n",
    "#     train_data_raw,\n",
    "#     valid_data_raw,\n",
    "#     num_valid = \n",
    "#     # cutoff=args.cutoff,\n",
    "#     # batch_size=args.batch_size,\n",
    "# )\n",
    "train_data = train_data_raw\n",
    "valid_data = valid_data_raw\n",
    "print(f\"‚úÖ Datasets prepared\")\n",
    "print(f\"  Training batches: {len(train_data)}\")\n",
    "print(f\"  Validation batches: {len(valid_data)}\")\n",
    "\n",
    "# Build model\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Building Model\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "print(f\"\\nModel hyperparameters:\")\n",
    "print(f\"  Features: {args.features}\")\n",
    "print(f\"  Max degree: {args.max_degree}\")\n",
    "print(f\"  Message passing iterations: {args.num_iterations}\")\n",
    "print(f\"  Basis functions: {args.num_basis_functions}\")\n",
    "print(f\"  Cutoff: {args.cutoff} √Ö\")\n",
    "print(f\"  Distributed multipoles per atom: {args.n_dcm}\")\n",
    "print(f\"  Include pseudotensors: {args.include_pseudotensors}\")\n",
    "\n",
    "model = MessagePassingModel(\n",
    "    features=args.features,\n",
    "    max_degree=args.max_degree,\n",
    "    num_iterations=args.num_iterations,\n",
    "    num_basis_functions=args.num_basis_functions,\n",
    "    cutoff=args.cutoff,\n",
    "    n_dcm=args.n_dcm,\n",
    "    include_pseudotensors=args.include_pseudotensors,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model created: DCMNet (n_dcm={args.n_dcm})\")\n",
    "\n",
    "# Training setup\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Training Setup\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "print(f\"\\nTraining hyperparameters:\")\n",
    "print(f\"  Batch size: {args.batch_size}\")\n",
    "print(f\"  Epochs: {args.epochs}\")\n",
    "print(f\"  Learning rate: {args.learning_rate}\")\n",
    "print(f\"  ESP weight: {args.esp_weight}\")\n",
    "print(f\"  Random seed: {args.seed}\")\n",
    "\n",
    "# Load restart parameters if provided\n",
    "restart_params = None\n",
    "if args.restart:\n",
    "    print(f\"\\nüìÇ Loading restart checkpoint: {args.restart}\")\n",
    "    with open(args.restart, 'rb') as f:\n",
    "        restart_params = pickle.load(f)\n",
    "    print(f\"‚úÖ Checkpoint loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b751cd86-5781-4308-b6e0-bbe3467035fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "prepare_datasets(\n",
       "    key,\n",
       "    num_train,\n",
       "    num_valid,\n",
       "    filename,\n",
       "    natoms=\u001b[32m60\u001b[39m,\n",
       "    clean=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    esp_mask=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    clip_esp=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Prepare datasets for training and validation.\n",
       "\n",
       "Wrapper function that calls prepare_multiple_datasets and then\n",
       "creates train/validation splits and dictionaries.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "key : jax.random.PRNGKey\n",
       "    Random key for dataset shuffling\n",
       "num_train : int\n",
       "    Number of training samples\n",
       "num_valid : int\n",
       "    Number of validation samples\n",
       "filename : str or list\n",
       "    Filename(s) to load datasets from\n",
       "clean : bool, optional\n",
       "    Whether to filter failed calculations, by default False\n",
       "esp_mask : bool, optional\n",
       "    Whether to create ESP masks, by default False\n",
       "clip_esp : bool, optional\n",
       "    Whether to clip ESP to first 1000 points, by default False\n",
       "natoms : int, optional\n",
       "    Maximum number of atoms per system, by default 60\n",
       "\n",
       "Returns\n",
       "-------\n",
       "tuple\n",
       "    A tuple containing train_data and valid_data dictionaries\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/mmml/dcmnet/dcmnet/data.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prepare_datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab49c8d7-f477-4f02-a29b-4eafcec321fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0052505,  0.0033848,  0.037617 , ...,  0.0093954, -0.023834 ,\n",
       "         0.0059184],\n",
       "       [ 0.0043249,  0.0058309, -0.0074244, ..., -0.017754 ,  0.013946 ,\n",
       "        -0.006544 ],\n",
       "       [ 0.018399 ,  0.011036 ,  0.0095978, ..., -0.011879 , -0.010322 ,\n",
       "         0.0057994],\n",
       "       ...,\n",
       "       [ 0.042213 ,  0.032696 , -0.011879 , ..., -0.0024751,  0.032268 ,\n",
       "         0.015244 ],\n",
       "       [-0.0083788,  0.0076804, -0.010421 , ..., -0.010508 ,  0.0033204,\n",
       "        -0.0011256],\n",
       "       [-0.031544 , -0.0094387, -0.0063055, ..., -0.014822 , -0.002533 ,\n",
       "        -0.0051037]], shape=(8000, 3000), dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"esp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1d10d14-db80-4f1d-92f5-4673cee5b50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "train_model(\n",
       "    key,\n",
       "    model,\n",
       "    train_data,\n",
       "    valid_data,\n",
       "    num_epochs,\n",
       "    learning_rate,\n",
       "    batch_size,\n",
       "    writer,\n",
       "    ndcm,\n",
       "    esp_w=\u001b[32m1.0\u001b[39m,\n",
       "    chg_w=\u001b[32m0.01\u001b[39m,\n",
       "    restart_params=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    ema_decay=\u001b[32m0.999\u001b[39m,\n",
       "    num_atoms=\u001b[32m60\u001b[39m,\n",
       "    use_grad_clip=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    grad_clip_norm=\u001b[32m2.0\u001b[39m,\n",
       "    mono_imputation_fn=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    distance_weighting=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    distance_scale=\u001b[32m2.0\u001b[39m,\n",
       "    distance_min=\u001b[32m0.5\u001b[39m,\n",
       "    esp_magnitude_weighting=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "    charge_conservation_w=\u001b[32m1.0\u001b[39m,\n",
<<<<<<< HEAD
       "    esp_grid_units=\u001b[33m'angstrom'\u001b[39m,\n",
       "    radii_cutoff_multiplier=\u001b[32m2.0\u001b[39m,\n",
=======
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
       ")\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Train DCMNet model with ESP and monopole losses.\n",
       "\n",
       "Performs full training loop with validation, logging, and checkpointing.\n",
       "Uses exponential moving average (EMA) for parameter smoothing and saves\n",
       "best parameters based on validation loss.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "key : jax.random.PRNGKey\n",
       "    Random key for training\n",
       "model : MessagePassingModel\n",
       "    DCMNet model instance\n",
       "train_data : dict\n",
       "    Training dataset dictionary\n",
       "valid_data : dict\n",
       "    Validation dataset dictionary\n",
       "num_epochs : int\n",
       "    Number of training epochs\n",
       "learning_rate : float\n",
       "    Learning rate for optimization\n",
       "batch_size : int\n",
       "    Batch size for training\n",
       "writer : SummaryWriter\n",
       "    TensorBoard writer for logging\n",
       "ndcm : int\n",
       "    Number of distributed multipoles per atom\n",
       "esp_w : float, optional\n",
       "    Weight for ESP loss term, by default 1.0\n",
       "chg_w : float, optional\n",
       "    Weight for charge/monopole loss term, by default 0.01\n",
       "restart_params : Any, optional\n",
       "    Parameters to restart from, by default None\n",
       "ema_decay : float, optional\n",
       "    Exponential moving average decay rate, by default 0.999\n",
       "num_atoms : int, optional\n",
       "    Maximum number of atoms for batching, by default 60\n",
       "use_grad_clip : bool, optional\n",
       "    Whether to use gradient clipping, by default False\n",
       "grad_clip_norm : float, optional\n",
       "    Maximum gradient norm for clipping, by default 2.0\n",
       "mono_imputation_fn : callable, optional\n",
       "    Function to impute monopoles if missing from batches. Should take a batch dict\n",
       "    and return monopoles with shape (batch_size * num_atoms,). By default None\n",
       "distance_weighting : bool, optional\n",
       "    Whether to apply distance-based weighting to ESP loss. Errors further from atoms\n",
       "    will have HIGHER weight (reversed from typical). By default False\n",
       "distance_scale : float, optional\n",
       "    Scale parameter for distance weighting (in Angstroms). Larger values give slower\n",
       "    increase with distance. Weight = exp((distance - distance_min) / distance_scale),\n",
       "    normalized to have mean=1. By default 2.0\n",
       "distance_min : float, optional\n",
       "    Minimum distance for weighting (in Angstroms). Distances below this are clamped\n",
       "    to avoid singularities. By default 0.5\n",
       "esp_magnitude_weighting : bool, optional\n",
       "    Whether to weight by ESP magnitude instead of distance. Errors at points with\n",
       "    larger |ESP| values will have LOWER weight. This reduces the impact of points\n",
       "    where nuclear-electron shielding occurs and ESP approaches singularity (near\n",
       "    atomic nuclei). By default False\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "tuple\n",
       "    (final_params, final_valid_loss)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/mmml/dcmnet/dcmnet/training.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
<<<<<<< HEAD
   "id": "11c60424-60d6-4122-832f-b06c9da381bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m align_esp_grids(data: Dict, verbose: bool = \u001b[38;5;28;01mTrue\u001b[39;00m) -> Dict\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Align ESP grids to molecular reference frames by centering grids on atom COM.\n",
       "\n",
       "This ensures ESP grids and atom positions are in the same coordinate frame,\n",
       "which is critical for accurate ESP prediction.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : dict\n",
       "    Data dictionary with keys: 'R', 'N', 'vdw_surface'\n",
       "    - 'R': atomic positions, shape (n_samples, natoms, 3) or (natoms, 3)\n",
       "    - 'N': number of atoms per sample, shape (n_samples,) or scalar\n",
       "    - 'vdw_surface': ESP grid points, shape (n_samples, ngrid, 3) or (ngrid, 3)\n",
       "verbose : bool\n",
       "    Whether to print alignment information\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "dict\n",
       "    Data dictionary with aligned 'vdw_surface'\n",
       "    \n",
       "Notes\n",
       "-----\n",
       "The alignment works by:\n",
       "1. Computing atom COM (center of mass) for each molecule\n",
       "2. Computing grid COM for each molecule\n",
       "3. Computing offset = grid_com - atom_com\n",
       "4. Shifting grids: vdw_surface_aligned = vdw_surface - offset\n",
       "\n",
       "After alignment, grid COM should match atom COM (within numerical precision).\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/examples/co2/dcmnet_train/align_esp_grids.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
=======
   "id": "7898866a-5479-4810-85e9-1127e0499c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Aligning ESP Grids\n",
      "======================================================================\n",
      "\n",
      "Aligning training data...\n",
      "‚úÖ Aligned ESP grids to molecular reference frames\n",
      "   Number of samples: 8000\n",
      "\n",
      "   Sample 0 details:\n",
      "     Atom COM:        [0.         0.14525378 0.11470596]\n",
      "     Grid COM before: [[3.25342429 3.24367862 3.3973045 ]\n",
      " [3.29037849 3.42968506 3.37285263]\n",
      " [3.26749158 3.2349472  3.04755038]\n",
      " ...\n",
      " [3.23463851 3.24004016 3.27062503]\n",
      " [3.23331557 3.19962463 3.1881812 ]\n",
      " [3.29324486 3.22379038 3.37600344]]\n",
      "     Grid COM after:  [2.56091444e-16 1.45253775e-01 1.14705956e-01]\n",
      "     Offset corrected: [3.25342429 3.09842484 3.28259855] √Ö\n",
      "\n",
      "   Sense check:\n",
      "     Alignment error: 1.122908e-14 √Ö\n",
      "     ‚úì Alignment verified: grids are centered on atom COM\n",
      "\n",
      "     ‚ö†Ô∏è  Large offset detected: 5.564 √Ö\n",
      "        This suggests ESP grids and atoms were in different reference frames.\n",
      "\n",
      "Aligning validation data...\n",
      "‚úÖ Aligned ESP grids to molecular reference frames\n",
      "   Number of samples: 1000\n",
      "\n",
      "   Sample 0 details:\n",
      "     Atom COM:        [0.         0.25326187 0.02194556]\n",
      "     Grid COM before: [[3.22872937 3.4025402  3.33670261]\n",
      " [3.15376263 3.21823402 3.28853512]\n",
      " [3.29284798 3.23636282 3.32147785]\n",
      " ...\n",
      " [3.30034465 3.5232823  3.59271659]\n",
      " [3.23821046 3.44180257 3.51664558]\n",
      " [3.27238647 3.57924288 3.50544553]]\n",
      "     Grid COM after:  [2.56683563e-15 2.53261870e-01 2.19455598e-02]\n",
      "     Offset corrected: [3.22872937 3.14927833 3.31475705] √Ö\n",
      "\n",
      "   Sense check:\n",
      "     Alignment error: 1.205896e-14 √Ö\n",
      "     ‚úì Alignment verified: grids are centered on atom COM\n",
      "\n",
      "     ‚ö†Ô∏è  Large offset detected: 5.597 √Ö\n",
      "        This suggests ESP grids and atoms were in different reference frames.\n",
      "\n",
      "======================================================================\n",
      "Sense Check\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Sense Check for Sample 0\n",
      "======================================================================\n",
      "\n",
      "Atom positions (first 3 atoms):\n",
      "  Atom 0: [0. 0. 0.]\n",
      "  Atom 1: [0.    0.    1.417]\n",
      "  Atom 2: [ 0.          0.43576133 -1.07288213]\n",
      "\n",
      "Atom COM: [0.         0.14525378 0.11470596]\n",
      "Grid COM:  [2.56091444e-16 1.45253775e-01 1.14705956e-01]\n",
      "Offset:    [2.56091444e-16 1.03805853e-14 4.27435864e-15]\n",
      "\n",
      "Alignment error: 1.122908e-14 √Ö\n",
      "Offset magnitude: 0.000 √Ö\n",
      "\n",
      "‚úÖ PASS: Grids are properly aligned\n",
      "\n",
      "======================================================================\n",
      "Sense Check for Sample 0\n",
      "======================================================================\n",
      "\n",
      "Atom positions (first 3 atoms):\n",
      "  Atom 0: [0. 0. 0.]\n",
      "  Atom 1: [0.    0.    1.042]\n",
      "  Atom 2: [ 0.          0.75978561 -0.97616332]\n",
      "\n",
      "Atom COM: [0.         0.25326187 0.02194556]\n",
      "Grid COM:  [2.56683563e-15 2.53261870e-01 2.19455598e-02]\n",
      "Offset:    [2.56683563e-15 1.17128529e-14 1.28022593e-15]\n",
      "\n",
      "Alignment error: 1.205896e-14 √Ö\n",
      "Offset magnitude: 0.000 √Ö\n",
      "\n",
      "‚úÖ PASS: Grids are properly aligned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'atom_com': array([0.        , 0.25326187, 0.02194556]),\n",
       " 'grid_com': array([2.56683563e-15, 2.53261870e-01, 2.19455598e-02]),\n",
       " 'alignment_error': np.float64(1.2058961268398482e-14),\n",
       " 'offset': array([2.56683563e-15, 1.17128529e-14, 1.28022593e-15]),\n",
       " 'offset_magnitude': np.float64(1.2058961268398482e-14),\n",
       " 'is_aligned': np.True_}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
    }
   ],
   "source": [
    "from align_esp_grids import align_esp_grids, sense_check_alignment\n",
<<<<<<< HEAD
    "align_esp_grids?"
=======
    "\n",
    "# Apply alignment to training and validation data\n",
    "print(\"=\"*70)\n",
    "print(\"Aligning ESP Grids\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nAligning training data...\")\n",
    "train_data = align_esp_grids(train_data, verbose=args.verbose)\n",
    "\n",
    "print(\"\\nAligning validation data...\")\n",
    "valid_data = align_esp_grids(valid_data, verbose=args.verbose)\n",
    "\n",
    "# Sense check\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Sense Check\")\n",
    "print(\"=\"*70)\n",
    "sense_check_alignment(train_data, sample_idx=0, verbose=True)\n",
    "sense_check_alignment(valid_data, sample_idx=0, verbose=True)"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
<<<<<<< HEAD
   "id": "7898866a-5479-4810-85e9-1127e0499c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Apply alignment to training and validation data\n",
    "# print(\"=\"*70)\n",
    "# print(\"Aligning ESP Grids\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# print(\"\\nAligning training data...\")\n",
    "# train_data = align_esp_grids(train_data, verbose=args.verbose)\n",
    "\n",
    "# print(\"\\nAligning validation data...\")\n",
    "# valid_data = align_esp_grids(valid_data, verbose=args.verbose)\n",
    "\n",
    "# # Sense check\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"Sense Check\")\n",
    "# print(\"=\"*70)\n",
    "# sense_check_alignment(train_data, sample_idx=0, verbose=True)\n",
    "# sense_check_alignment(valid_data, sample_idx=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
=======
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   "id": "010a279a-2709-499d-800a-b4a146124ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m mono_imputation_fn(batch: Dict) -> jax.Array\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Impute monopoles for a batch.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "batch : dict\n",
       "    Batch dictionary containing 'Z', 'R', 'dst_idx', 'src_idx', 'batch_segments'\n",
       "    \n",
       "Returns\n",
       "-------\n",
       "jnp.ndarray\n",
       "    Atomic monopoles with shape (batch_size * num_atoms,)\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/examples/co2/dcmnet_train/train_charge_predictor_usage.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mono_imputation_fn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d966dad-dce0-4e88-8ebb-a592bd76d276",
<<<<<<< HEAD
   "metadata": {
    "scrolled": true
   },
=======
   "metadata": {},
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STARTING TRAINING\n",
      "======================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DATA STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Training Data:\n",
      "  Samples: 8000\n",
      "  Atoms per sample: 60\n",
<<<<<<< HEAD
      "  Grid points per sample: mean=3000, min=3000, max=3000\n",
      "  Total ESP grid points: 24,000,000\n",
      "  Monopoles:\n",
      "    Shape: (0,)\n",
      "    Mean: 0.000000 e\n",
      "    Std: 0.000000 e\n",
      "    Range: [0.000000, 0.000000] e\n",
      "    Sum(abs): 0.000000 e\n",
      "    Non-zero count: 0.0 / 0\n",
      "  ESP:\n",
      "    Mean: 0.014748 Ha/e (9.254 kcal/mol/e)\n",
      "    Std: 0.067087 Ha/e (42.097 kcal/mol/e)\n",
      "    Range: [-0.058102, 0.859140] Ha/e\n",
      "    Range: [-36.459, 539.110] kcal/mol/e\n",
      "    Median: 0.002183 Ha/e (1.370 kcal/mol/e)\n",
      "    Q25-Q75: [-0.005583, 0.011786] Ha/e\n",
      "    NaN count: 0.0, Inf count: 0.0\n",
      "  VDW Surface (first sample):\n",
      "    Shape: (3000, 3)\n",
      "    Position range: [0.0000, 3.5214] √Ö (converted from Bohr)\n",
      "    Position mean: 1.7453 √Ö (converted from Bohr), std: 1.0199 √Ö (converted from Bohr)\n",
      "    Position range (Bohr): [0.0000, 6.6545] Bohr\n",
=======
      "  Grid points per sample: 3000\n",
      "  Monopoles: mean=0.000000 e, std=0.000000 e\n",
      "  ESP: mean=0.014748 Ha/e (9.254 kcal/mol/e)\n",
      "        std=0.067087 Ha/e (42.097 kcal/mol/e)\n",
      "        range=[-0.058102, 0.859140] Ha/e\n",
      "        range=[-36.459, 539.110] kcal/mol/e\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "\n",
      "Validation Data:\n",
      "  Samples: 1000\n",
      "  Atoms per sample: 60\n",
<<<<<<< HEAD
      "  Grid points per sample: mean=3000, min=3000, max=3000\n",
      "  Total ESP grid points: 3,000,000\n",
      "  Monopoles:\n",
      "    Shape: (0,)\n",
      "    Mean: 0.000000 e\n",
      "    Std: 0.000000 e\n",
      "    Range: [0.000000, 0.000000] e\n",
      "    Sum(abs): 0.000000 e\n",
      "    Non-zero count: 0.0 / 0\n",
      "  ESP:\n",
      "    Mean: 0.014783 Ha/e (9.277 kcal/mol/e)\n",
      "    Std: 0.067306 Ha/e (42.234 kcal/mol/e)\n",
      "    Range: [-0.058142, 0.862270] Ha/e\n",
      "    Range: [-36.484, 541.074] kcal/mol/e\n",
      "    Median: 0.002217 Ha/e (1.391 kcal/mol/e)\n",
      "    Q25-Q75: [-0.005635, 0.011821] Ha/e\n",
      "    NaN count: 0.0, Inf count: 0.0\n",
      "  VDW Surface (first sample):\n",
      "    Shape: (3000, 3)\n",
      "    Position range: [0.0000, 3.5123] √Ö (converted from Bohr)\n",
      "    Position mean: 1.7583 √Ö (converted from Bohr), std: 1.0133 √Ö (converted from Bohr)\n",
      "    Position range (Bohr): [0.0000, 6.6373] Bohr\n",
      "\n",
      "Training Configuration:\n",
      "  Batch size: 10\n",
      "  Steps per epoch: 800\n",
      "  ESP weight: 10000\n",
      "  Charge weight: 1e-06\n",
      "  Charge conservation weight: 0\n",
      "  Distance weighting: False\n",
      "    Distance scale: 2.0 √Ö\n",
      "    Distance min: 0.5 √Ö\n",
      "  ESP magnitude weighting: True\n",
      "  ESP grid units: bohr\n",
      "  Radii cutoff multiplier: 1.5\n",
      "  Use atomic radii mask: True\n",
      "  Learning rate: 0.005\n",
      "  Number of DCM per atom: 4\n",
      "  Total parameters: 305,522\n",
=======
      "  Grid points per sample: 3000\n",
      "  Monopoles: mean=0.000000 e, std=0.000000 e\n",
      "  ESP: mean=0.014783 Ha/e (9.277 kcal/mol/e)\n",
      "        std=0.067306 Ha/e (42.234 kcal/mol/e)\n",
      "        range=[-0.058142, 0.862270] Ha/e\n",
      "        range=[-36.484, 541.074] kcal/mol/e\n",
      "\n",
      "Training Configuration:\n",
      "  Batch size: 500\n",
      "  Steps per epoch: 16\n",
      "  ESP weight: 10000\n",
      "  Charge weight: 10\n",
      "  Distance weighting: True\n",
      "  ESP magnitude weighting: True\n",
      "  Learning rate: 0.001\n",
      "  Number of DCM per atom: 6\n",
      "  Total parameters: 1,801,134\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "================================================================================\n",
      "\n",
      "Preparing batches\n",
      "..................\n",
      "\n",
      "Preprocessing monopoles...\n",
      "  Imputing monopoles for 8000 samples...\n",
<<<<<<< HEAD
      "  Using padded_size=60 (from data shape), actual_atoms=3 per molecule, batch_size=10\n",
      "  ‚úì Monopole imputation complete. Mean_abs=0.038144 e, Std=0.183701 e\n",
      "  Imputing monopoles for 1000 samples...\n",
      "  Using padded_size=60 (from data shape), actual_atoms=3 per molecule, batch_size=10\n",
      "  ‚úì Monopole imputation complete. Mean_abs=0.038327 e, Std=0.184470 e\n",
      "\n",
      "Post-imputation Statistics:\n",
      "  Training monopoles after imputation:\n",
      "    Mean: 0.000461 e\n",
      "    Std: 0.183701 e\n",
      "    Range: [-0.732357, 1.455572] e\n",
      "    Sum(abs): 18308.945312 e\n",
      "    Non-zero: 24,000.0 / 480,000\n",
      "  Validation monopoles after imputation:\n",
      "    Mean: 0.000448 e\n",
      "    Std: 0.184470 e\n",
      "    Range: [-0.720894, 1.377468] e\n",
      "    Sum(abs): 2299.646973 e\n",
      "    Non-zero: 3,000.0 / 60,000\n",
=======
      "  Using padded_size=60 (from data shape), actual_atoms=3 per molecule, batch_size=500\n",
      "  ‚úì Monopole imputation complete. Mean_abs=0.038398 e, Std=0.184355 e\n",
      "  Imputing monopoles for 1000 samples...\n",
      "  Using padded_size=60 (from data shape), actual_atoms=3 per molecule, batch_size=500\n",
      "  ‚úì Monopole imputation complete. Mean_abs=0.038579 e, Std=0.185109 e\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "\n",
      "================================================================================\n",
      "ESP Grid Verification\n",
      "================================================================================\n",
      "Checking ESP grid alignment and masking...\n",
<<<<<<< HEAD
      "  ‚ö†Ô∏è  Training: ESP grids may be misaligned\n",
      "      Average COM alignment error: 5.5866 √Ö\n",
      "      Max alignment error: 5.6202 √Ö\n",
      "      Sample 0: 46/3000 points too close\n",
      "      Radii: [0.76 0.66 0.66]\n",
      "      Cutoffs per atom: [1.52 1.32 1.32]\n",
      "      Min distances range: [0.3059, 10.1586] √Ö\n",
      "  ‚ö†Ô∏è  Training: 5/5 samples have ESP points too close to atoms\n",
      "      (These should be masked by atomic_radii_mask)\n",
      "  ‚ö†Ô∏è  Validation: ESP grids may be misaligned\n",
      "      Average COM alignment error: 5.5640 √Ö\n",
      "      Max alignment error: 5.5973 √Ö\n",
      "      Sample 0: 26/3000 points too close\n",
      "      Radii: [0.76 0.66 0.66]\n",
      "      Cutoffs per atom: [1.52 1.32 1.32]\n",
      "      Min distances range: [0.4476, 10.4513] √Ö\n",
=======
      "  ‚úì  Training: ESP grids aligned (avg error: 0.0000 √Ö)\n",
      "  ‚ö†Ô∏è  Training: 5/5 samples have ESP points too close to atoms\n",
      "      (These should be masked by atomic_radii_mask)\n",
      "  ‚úì  Validation: ESP grids aligned (avg error: 0.0000 √Ö)\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
      "  ‚ö†Ô∏è  Validation: 5/5 samples have ESP points too close to atoms\n",
      "      (These should be masked by atomic_radii_mask)\n",
      "================================================================================\n",
      "\n",
<<<<<<< HEAD
      "\n",
      "Preparing validation batches (batch_size=10, num_atoms=3)...\n",
      "  Created 100 validation batches\n",
      "  First validation batch shapes:\n",
      "    Dxyz: (10, 3) (dtype=float32)\n",
      "    N: (10,) (dtype=int32)\n",
      "    R: (600, 3) (dtype=float32)\n",
      "    Z: (600,) (dtype=int32)\n",
      "    atom_mask: (10, 3) (dtype=float32)\n",
      "    batch_segments: (30,) (dtype=int32)\n",
      "    dst_idx: (60,) (dtype=int32)\n",
      "    esp: (10, 3000) (dtype=float32)\n",
      "    mono: (600,) (dtype=float32)\n",
      "    n_grid: (10,) (dtype=int32)\n",
      "    src_idx: (60,) (dtype=int32)\n",
      "    vdw_surface: (10, 3000, 3) (dtype=float32)\n",
      "\n",
      "================================================================================\n",
      "ESP Sense Check (Monopoles)\n",
      "================================================================================\n",
      "Computing ESP from reference monopoles on validation set...\n",
      "\n",
      "ESP from Reference Monopoles (Validation Set):\n",
      "  Total samples: 1000\n",
      "  Total grid points: 3,000,000\n",
      "  Valid grid points (masked): 2,892,521 / 3,000,000 (96.42%)\n",
      "\n",
      "  Unmasked Statistics:\n",
      "    MAE: 0.037683 Ha/e (23.646 kcal/mol/e)\n",
      "    RMSE: 0.195500 Ha/e (122.676 kcal/mol/e)\n",
      "    R¬≤: -7.437018\n",
      "    Per-sample RMSE: mean=0.119667, median=0.102521, max=4.441668 Ha/e\n",
      "\n",
      "  Masked Statistics:\n",
      "    MAE: 0.029457 Ha/e (18.484 kcal/mol/e)\n",
      "    RMSE: 0.073146 Ha/e (45.899 kcal/mol/e)\n",
      "    R¬≤: -0.139499\n",
      "\n",
      "  Worst 5 samples (by RMSE):\n",
      "    1. Sample 80: RMSE=4.441668 Ha/e (2787.147 kcal/mol/e), MAE=0.117514 Ha/e (73.740 kcal/mol/e)\n",
      "    2. Sample 67: RMSE=1.261772 Ha/e (791.762 kcal/mol/e), MAE=0.066183 Ha/e (41.530 kcal/mol/e)\n",
      "    3. Sample 408: RMSE=1.076827 Ha/e (675.709 kcal/mol/e), MAE=0.064246 Ha/e (40.315 kcal/mol/e)\n",
      "    4. Sample 454: RMSE=0.761277 Ha/e (477.702 kcal/mol/e), MAE=0.052370 Ha/e (32.862 kcal/mol/e)\n",
      "    5. Sample 74: RMSE=0.745648 Ha/e (467.894 kcal/mol/e), MAE=0.063295 Ha/e (39.717 kcal/mol/e)\n",
      "\n",
      "  Error Distribution:\n",
      "    Errors > 0.100 Ha/e (62.8 kcal/mol/e): 219,390 / 3,000,000 (7.31%)\n",
      "    Error percentiles:\n",
      "      50th: 0.012682 Ha/e (7.958 kcal/mol/e)\n",
      "      75th: 0.030091 Ha/e (18.882 kcal/mol/e)\n",
      "      90th: 0.074454 Ha/e (46.720 kcal/mol/e)\n",
      "      95th: 0.144002 Ha/e (90.361 kcal/mol/e)\n",
      "      99th: 0.488208 Ha/e (306.351 kcal/mol/e)\n",
      "\n",
      "  ‚ö†Ô∏è  ESP calculation has large errors (RMSE < 0.5 Ha/e)\n",
      "      This may indicate issues with:\n",
      "      - Monopole values (may need higher-order multipoles)\n",
      "      - Grid alignment\n",
      "      - Unit conversions\n",
      "      - 7.3% of points have errors > 62.8 kcal/mol/e\n",
      "      - Consider increasing radii_cutoff_multiplier from 1.5 to >= 2.0\n",
      "        to mask more points near atomic nuclei (where ESP has singularities)\n",
      "\n",
      "  ‚ö†Ô∏è  Low R¬≤ (-7.4370) suggests monopoles alone cannot\n",
      "      accurately reproduce the target ESP. This is expected if:\n",
      "      - Target ESP includes higher-order multipole contributions\n",
      "      - Target ESP is from quantum mechanical calculations\n",
      "      - Distributed multipoles (DCM) are needed for accuracy\n",
      "\n",
      "  Unit and Masking Diagnostics:\n",
      "    ESP grid units: bohr\n",
      "    Radii cutoff multiplier: 1.5\n",
      "    ‚ö†Ô∏è  WARNING: Radii cutoff multiplier (1.5) is very low!\n",
      "       This means only points within 1.5√ó covalent radius are masked.\n",
      "       Many points near atomic nuclei (where ESP has singularities) will NOT be masked.\n",
      "       Recommended: Use radii_cutoff_multiplier >= 2.0 (typically 2.0-4.0)\n",
      "    Use atomic radii mask: True (always enabled in sense check)\n",
      "    First sample grid range (Bohr): [-0.0824, 6.5894]\n",
      "    First sample grid range (Angstrom): [-0.0436, 3.4870]\n",
      "    First sample atom positions range (Angstrom): [-1.2269, 1.0620]\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ESP Grid Shift Optimization\n",
      "================================================================================\n",
      "Finding optimal grid shifts to minimize monopole ESP error...\n",
      "\n",
      "  Processed 1000 samples\n",
      "  Shift statistics (Angstrom):\n",
      "    Mean shift: [0.108915, 0.140140, 0.136744]\n",
      "    Std shift: [0.362281, 0.402012, 0.477902]\n",
      "    Min shift: [-0.243098, 0.000000, -2.000000]\n",
      "    Max shift: [2.000000, 2.000000, 2.000000]\n",
      "  RMSE improvement:\n",
      "    Mean improvement: 0.023884 Ha/e (14.987 kcal/mol/e)\n",
      "    Mean improvement %: 10.17%\n",
      "    Max improvement: 4.297238 Ha/e (2696.517 kcal/mol/e)\n",
      "\n",
      "  ‚úì Saved grid shifts to: grid_shifts.npz\n",
      "    File contains: shifts array, improvements, and sample indices\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Training\n",
      "..................\n",
      "\n",
      "  Created 800 training batches\n",
      "  First training batch shapes:\n",
      "    Dxyz: (10, 3) (dtype=float32)\n",
      "    N: (10,) (dtype=int32)\n",
      "    R: (600, 3) (dtype=float32)\n",
      "    Z: (600,) (dtype=int32)\n",
      "    atom_mask: (10, 3) (dtype=float32)\n",
      "    batch_segments: (30,) (dtype=int32)\n",
      "    dst_idx: (60,) (dtype=int32)\n",
      "    esp: (10, 3000) (dtype=float32)\n",
      "    mono: (600,) (dtype=float32)\n",
      "    n_grid: (10,) (dtype=int32)\n",
      "    src_idx: (60,) (dtype=int32)\n",
      "    vdw_surface: (10, 3000, 3) (dtype=float32)\n",
      "    ESP shape: (10, 3000)\n",
      "    VDW surface shape: (10, 3000, 3)\n",
      "    n_grid: Array[10] i32 x‚àà[3000, 3000] Œº=3.000e+03 œÉ=0. gpu:0 [3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000, 3000]\n",
      "    atom_mask shape: (10, 3), sum: 30.0\n",
      "\n",
      "  First batch (epoch 1, batch 0) statistics:\n",
      "    Loss: 2.983044e+00\n",
      "    Loss components: {'charge_conservation_loss': Array gpu:0 0.000, 'charge_conservation_loss_weighted': Array gpu:0 0., 'esp_loss': Array gpu:0 0.000, 'esp_loss_weighted': Array gpu:0 2.983, 'mono_loss': Array gpu:0 0.071, 'mono_loss_weighted': Array gpu:0 7.094e-08}\n",
      "    ESP mask shape: (10, 3000)\n",
      "    ESP mask dtype: float32\n",
      "    ESP mask min: 0.000000, max: 1.000000\n",
      "    ESP mask mean: 0.963500\n",
      "    ESP mask sum: 28905.000000\n",
      "    ESP mask size: 30000\n",
      "    ESP mask valid count (>0.5): 28905.0\n",
      "    ESP mask valid fraction: 0.963500\n",
      "    ESP pred shape: (10, 3000), mean: -0.001716, std: 0.029769\n",
      "    ESP target shape: (10, 3000), mean: 0.013886, std: 0.063985\n",
      "    ESP error shape: (10, 3000), mean: -0.015602, std: 0.070759\n",
      "    ESP error MAE: 0.024987 Ha/e\n"
=======
      "Training\n",
      "..................\n"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Start training\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STARTING TRAINING\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "try:\n",
    "    final_params = train_model(\n",
    "        key=key,\n",
    "        model=model,\n",
<<<<<<< HEAD
    "        train_data=train_data.copy(),\n",
    "        valid_data=valid_data.copy(),\n",
    "        num_epochs=10,\n",
    "        learning_rate=0.005,\n",
    "        batch_size=10,\n",
    "        esp_w=10000,\n",
    "        restart_params=pd.read_pickle(\"best_10000_params.pkl\"),\n",
    "        writer=None,\n",
    "        chg_w=0.000001,\n",
=======
    "        train_data=train_data,\n",
    "        valid_data=valid_data,\n",
    "        num_epochs=50,\n",
    "        learning_rate=0.001,\n",
    "        batch_size=500,\n",
    "        esp_w=10000,\n",
    "        restart_params=pd.read_pickle(\"best_10000_params.pkl\"),\n",
    "        writer=None,\n",
    "        chg_w=10,\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
    "        ndcm=args.n_dcm,\n",
    "        mono_imputation_fn=mono_imputation_fn,\n",
    "        num_atoms = 3,\n",
    "        use_grad_clip=True,\n",
<<<<<<< HEAD
    "        grad_clip_norm=10000,\n",
    "        distance_weighting=False,\n",
    "        esp_magnitude_weighting=True,\n",
    "        charge_conservation_w=0,\n",
    "        esp_grid_units=\"bohr\",  # Specify that grid is in Bohr\n",
    "        radii_cutoff_multiplier=1.5,\n",
=======
    "        grad_clip_norm=10,\n",
    "        distance_weighting=True,\n",
    "        esp_magnitude_weighting=True,\n",
    "        charge_conservation_w=0.1,\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
    "        # tag=args.name,\n",
    "        # output_dir=args.output_dir,\n",
    "        # print_freq=args.print_freq,\n",
    "    )\n",
    "    \n",
    "    # Save final model\n",
    "    final_path = args.output_dir / f\"{args.name}_final.pkl\"\n",
    "    with open(final_path, 'wb') as f:\n",
    "        pickle.dump(final_params, f)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nFinal parameters saved to: {final_path}\")\n",
    "    print(f\"\\nTo use the trained model:\")\n",
    "    print(f\"  from mmml.dcmnet.dcmnet.modules import MessagePassingModel\")\n",
    "    print(f\"  import pickle\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Load parameters\")\n",
    "    print(f\"  with open('{final_path}', 'rb') as f:\")\n",
    "    print(f\"      params = pickle.load(f)\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Create model and predict\")\n",
    "    print(f\"  model = MessagePassingModel(...)\")\n",
    "    print(f\"  mono, dipo = model.apply(params, Z, R, dst_idx, src_idx)\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Calculate ESP\")\n",
    "    print(f\"  from mmml.dcmnet.dcmnet.electrostatics import calc_esp\")\n",
    "    print(f\"  esp_pred = calc_esp(mono, dipo, R, vdw_surface)\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n\\n‚ö†Ô∏è  Training interrupted by user\")\n",
    "    print(f\"Checkpoints saved to: {args.output_dir}\")\n",
    "    sys.exit(0)\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\n‚ùå Training failed with error:\")\n",
    "    print(f\"  {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5ca54-29d1-4323-9be8-66d8db33e4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12507cc-6ba2-4b45-8067-b6b02db1bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4495dd84-69be-432c-9f7a-59075f389871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c80cfe-9c3b-4e9a-8cd4-6a57fcd5919a",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "valid_data[\"R\"][0][:3].mean(axis=0)"
=======
    "valid_data[\"R\"][0]"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91356807-f3f6-40ae-bc91-947efdb5aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmml.dcmnet.dcmnet.modules import MessagePassingModel\n",
    "import pickle\n",
    "import e3x\n",
    "# Load parameters\n",
<<<<<<< HEAD
    "# with open('output/co2_dcmnet_final.pkl', 'rb') as f:\n",
    "#   params = pickle.load(f)\n",
=======
    "with open('output/co2_dcmnet_final.pkl', 'rb') as f:\n",
    "  params = pickle.load(f)\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
    "with open('best_10000_params.pkl', 'rb') as f:\n",
    "  params = pickle.load(f)\n",
    "# # Create model and predict\n",
    "# model = MessagePassingModel()\n",
    "dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(3)\n",
<<<<<<< HEAD
    "mono, dipo = model.apply(params, valid_data[\"Z\"][0], valid_data[\"R\"][0] * 1.88973 , dst_idx, src_idx)\n",
=======
    "mono, dipo = model.apply(params, valid_data[\"Z\"][0], valid_data[\"R\"][0], dst_idx, src_idx)\n",
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
    "\n",
    "mono, dipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966698e1-e419-4627-92e2-a1a2832df5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mono[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57526152-73eb-4b1f-aac0-3c1862bd7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(valid_data[\"R\"][0])[:3,np.newaxis,:] - np.array(dipo[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb0ca3-cbe4-4bd5-a91b-1425b76692db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mono[:3]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df8ca4-021d-45bd-8a7d-6acd0adebee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mono[:3]), np.array(dipo[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8af8c1-554e-483f-a97d-782be97c8a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dcm = model.n_dcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaec1ed-b0ea-42e6-99ea-da57e86445ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = jnp.moveaxis(dipo, -1, -2).reshape(1, 60 * n_dcm, 3)\n",
<<<<<<< HEAD
    "m = mono.reshape(1, 60 * n_dcm) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858467e8-680b-4a7d-a8bd-fe8c1fa76ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.mean(axis=1)"
=======
    "m = mono.reshape(1, 60 * n_dcm)"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c8f9b-e5cc-4043-abec-ed1fc47a557b",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "valid_data[\"vdw_surface\"][0].mean(axis=0)"
   ]
=======
   "source": []
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae66eb97-df6e-4f70-8938-74f4f7dd7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_esp?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "7fb8a44d-248b-4dbb-9010-d3f0ff77db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    " valid_data[\"vdw_surface\"][0].mean(axis=0) / 1.88973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   "id": "73b1937d-7e07-4998-a9ed-33bc90583cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mmml.dcmnet.dcmnet.electrostatics import calc_esp\n",
<<<<<<< HEAD
    "esp_pred = calc_esp(d , m, valid_data[\"vdw_surface\"][0])"
=======
    "esp_pred = calc_esp(d[:9], m[:9], valid_data[\"vdw_surface\"][0])"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91457d2-53a2-4849-bf2b-80d1db71f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "jnp.array(esp_pred)"
=======
    "np.array(esp_pred)"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f93c6a-e048-48df-ac7b-5b42d702bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "jnp.array(valid_data[\"esp\"][0] )"
=======
    "valid_data[\"esp\"][0] "
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9cd89a-45f7-4244-a6fa-2a1dab01ed03",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "plt.scatter(np.array(esp_pred), valid_data[\"esp\"][0], alpha=0.1)\n",
    "plt.xlim(-.025,.025)\n",
    "plt.ylim(-.025,0.025)\n",
    "ax = plt.gca()\n",
    "plt.grid()\n",
    "ax.plot([0,1], [0,1], transform=ax.transAxes)\n",
    "ax.set_aspect(\"equal\")"
=======
    "plt.scatter(np.array(esp_pred), valid_data[\"esp\"][0] )\n",
    "# plt.xlim(-0.1, 0.1)\n",
    "# plt.ylim(-0.1, 0.1)"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efcaa8-f90a-4f81-b737-61c4cd3fd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(esp_pred))\n",
    "plt.plot(valid_data[\"esp\"][0], alpha=0.1)\n",
    "plt.ylim(-0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d3fdc-8f9c-40f8-8375-488455d40646",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(esp_pred) - valid_data[\"esp\"][0], \"-o\", alpha=0.1)\n",
    "plt.ylim(-0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ecd4f-5ed1-4b52-b270-b5c0a56c20a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "esp = valid_data[\"esp\"][0]         # (N,)\n",
    "grid = valid_data[\"vdw_surface\"][0]     # (N, 3) in Angstrom\n",
    "R =  valid_data[\"R\"][0]          # (M, 3)\n",
    "Z = valid_data[\"Z\"][0]               # (M,)\n",
    "\n",
    "# Define a cube (rectilinear) grid around the molecule\n",
    "pad = 4.0  # Angstrom padding\n",
    "mins = np.min(R, axis=0) - pad\n",
    "maxs = np.max(R, axis=0) + pad\n",
    "nx, ny, nz = 40, 40, 40\n",
    "xs = np.linspace(mins[0], maxs[0], nx)\n",
    "ys = np.linspace(mins[1], maxs[1], ny)\n",
    "zs = np.linspace(mins[2], maxs[2], nz)\n",
    "X, Y, Zz = np.meshgrid(xs, ys, zs, indexing=\"ij\")\n",
    "cube_points = np.stack([X, Y, Zz], axis=-1).reshape(-1, 3)\n",
    "\n",
    "# Interpolate scattered ESP onto the rectilinear grid (nearest-neighbor)\n",
    "from scipy.spatial import cKDTree\n",
    "tree = cKDTree(grid)\n",
    "_, idx = tree.query(cube_points, k=1)\n",
    "cube_values = esp[idx].reshape(nx, ny, nz)\n",
    "\n",
    "def write_cube(path, atoms_Z, atoms_R, origin, axes, values):\n",
    "    # values must be shaped (nx, ny, nz)\n",
    "    nx, ny, nz = values.shape\n",
    "    ax, ay, az = axes  # each is (3,) box vector in Angstrom / count\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(\"ESP cube generated by mmml\\n\")\n",
    "        f.write(\"ESP on a rectilinear grid\\n\")\n",
    "        f.write(f\"{len(atoms_Z):4d} {origin[0]:12.6f} {origin[1]:12.6f} {origin[2]:12.6f}\\n\")\n",
    "        f.write(f\"{nx:4d} {ax[0]:12.6f} {ax[1]:12.6f} {ax[2]:12.6f}\\n\")\n",
    "        f.write(f\"{ny:4d} {ay[0]:12.6f} {ay[1]:12.6f} {ay[2]:12.6f}\\n\")\n",
    "        f.write(f\"{nz:4d} {az[0]:12.6f} {az[1]:12.6f} {az[2]:12.6f}\\n\")\n",
    "        for Zq, Rq in zip(atoms_Z, atoms_R):\n",
    "            f.write(f\"{int(Zq):4d} {float(Zq):12.6f} {Rq[0]:12.6f} {Rq[1]:12.6f} {Rq[2]:12.6f}\\n\")\n",
    "        # Write voxel data, 6 values per line\n",
    "        count = 0\n",
    "        for i in range(nx):\n",
    "            for j in range(ny):\n",
    "                line_vals = []\n",
    "                for k in range(nz):\n",
    "                    line_vals.append(f\"{values[i, j, k]:13.5e}\")\n",
    "                    count += 1\n",
    "                    if len(line_vals) == 6:\n",
    "                        f.write(\" \".join(line_vals) + \"\\n\")\n",
    "                        line_vals = []\n",
    "                if line_vals:\n",
    "                    f.write(\" \".join(line_vals) + \"\\n\")\n",
    "\n",
    "# Build cube axes from box lengths\n",
    "ax = np.array([xs[1]-xs[0], 0.0, 0.0])\n",
    "ay = np.array([0.0, ys[1]-ys[0], 0.0])\n",
    "az = np.array([0.0, 0.0, zs[1]-zs[0]])\n",
    "write_cube(\n",
    "    \"esp.cube\",\n",
    "    atoms_Z=Z,\n",
    "    atoms_R=R,\n",
    "    origin=np.array([xs[0], ys[0], zs[0]]),\n",
    "    axes=(ax, ay, az),\n",
    "    values=cube_values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43337d8-436e-49c5-8235-582c5abeeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "indices = abs(valid_data[\"esp\"][0]) * 627.5 < 2"
=======
    "indices = abs(valid_data[\"esp\"][0]) < 0.06"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5366738-a27a-42a9-970c-b74c1decc975",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "VMAX = 0.01\n",
    "esp_pred[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b31161c-5ee0-42ec-ad1a-b2acd17e1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "jnp.array(valid_data[\"esp\"][0][indices])"
=======
    "VMAX = 0.06"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8df62-8704-4a34-b17a-80b525d6af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "9af9e9a0-534e-4b96-ba0d-f9f53efc43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(esp_pred)[indices], valid_data[\"esp\"][0][indices] , alpha=0.1)\n",
    "plt.xlim(-.025,.025)\n",
    "plt.ylim(-.025,0.025)\n",
    "ax = plt.gca()\n",
    "plt.grid()\n",
    "ax.plot([0,1], [0,1], transform=ax.transAxes)\n",
    "ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   "id": "044a738d-3b2b-4f92-a8fc-b2dabd18fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "VDW = valid_data[\"vdw_surface\"][0]\n",
    "X,Y,Z = VDW.T\n",
    "plt.scatter(X[indices],Y[indices], c=esp_pred[indices], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
    "plt.scatter(X[indices],Z[indices], c=esp_pred[indices], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
<<<<<<< HEAD
    "plt.scatter(Y[indices],Z[indices], c=esp_pred[indices], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
    "plt.scatter(X[indices],Y[indices], c= valid_data[\"esp\"][0][indices], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
    "plt.scatter(X[indices],Z[indices],c= valid_data[\"esp\"][0][indices], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
    "plt.scatter(Y[indices],Z[indices], c= valid_data[\"esp\"][0][indices], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()"
=======
    "plt.scatter(Y[indices],Z[indices], c=esp_pred[indices], vmin=-VMAX, vmax=VMAX)"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "52c05400-694a-4291-bd6b-53e12253c42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b070c5-b8dc-461f-8dd9-2cfed4f55c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87b321-67b1-4243-a3ab-c11cb883c1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df21e3a-0073-43e0-954d-1dd6a3e73d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VMAX = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84153b67-4ba5-448f-bbc3-357c650b296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D scatter plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "sc = ax.scatter(X[indices], Y[indices], Z[indices], c=valid_data[\"esp\"][0][indices], s=0.7, alpha=0.9, cmap='coolwarm', vmin=-VMAX, vmax=VMAX)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Y Axis')\n",
    "ax.set_zlabel('Z Axis')\n",
    "fig.colorbar(sc, ax=ax, label='Color scale')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc5dc6-3646-4103-b1f2-50037b18d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D scatter plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "sc = ax.scatter(X[indices], Y[indices], Z[indices], c=esp_pred[indices], s=0.7, alpha=0.9, cmap='coolwarm', vmin=-VMAX, vmax=VMAX)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Y Axis')\n",
    "ax.set_zlabel('Z Axis')\n",
    "fig.colorbar(sc, ax=ax, label='Color scale')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3031a87d-709f-4063-a4c1-079204e499d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(esp_pred[indices] - valid_data[\"esp\"][0][indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d923bd-084b-48da-8100-829e18ec17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D scatter plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "sc = ax.scatter(X[indices], Y[indices], Z[indices], c=esp_pred[indices]/2 - valid_data[\"esp\"][0][indices], s=0.7, alpha=0.9, cmap='coolwarm', vmin=-VMAX, vmax=VMAX)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel('X Axis')\n",
    "ax.set_ylabel('Y Axis')\n",
    "ax.set_zlabel('Z Axis')\n",
    "fig.colorbar(sc, ax=ax, label='Color scale')\n",
    "\n",
    "plt.show()"
=======
   "id": "9a87b321-67b1-4243-a3ab-c11cb883c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "VDW = valid_data[\"vdw_surface\"][0]\n",
    "X,Y,Z = VDW.T\n",
    "plt.scatter(X,Y, c= valid_data[\"esp\"][0], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
    "plt.scatter(X,Z, c= valid_data[\"esp\"][0], vmin=-VMAX, vmax=VMAX)\n",
    "plt.show()\n",
    "plt.scatter(Y,Z, c= valid_data[\"esp\"][0], vmin=-VMAX, vmax=VMAX)"
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c078e-68ef-497e-9a81-c2f9ecee2ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc04275-0b19-4545-a155-437d60716a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad057882-c5ef-4de1-8b58-08b7867b3839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86821789-c8b0-42ab-a9be-2c492e034e6c",
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f40edd-bbcc-4dfd-be81-65084461a6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e9f7e-cb07-4e36-82ce-21506dbdcb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f7eb4a-b03a-46d4-b7db-3d31691269f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798565f-0175-4220-9d5b-dad3a88dd594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3c79b-d3f2-4c99-a5d5-47db85de03f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600a987a-ee6d-4183-be66-d83856fa9a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e520546-3151-49f2-9a09-5bdf4bf8d050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98495cee-c1d8-49aa-aee0-f0e5fb0ce13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552278ec-058f-4310-a9eb-019ed59fb6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e9ac24-85a2-418f-ae02-6f66c8b984e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa287544-f621-4e49-87b0-42ea2554307d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5395ec-474f-4155-bc69-75033802b4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16392c93-c916-41cc-800c-7b4e4916bb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99634c8b-84cf-4472-be1c-3d2ae48991ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c403296-3382-44e6-9818-45e724f4f29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17318535-a149-41cb-adb8-ddc2d0f8b3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284442d5-078b-4adb-842c-3d9e053d2455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cc5b3-0ac6-40f7-85c3-0159999e54ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822217ee-a227-4ed7-85c8-6e472649a6e8",
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> 8ab8d1fcd0c83e83f5619d6be73c3b324d88e3bf
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
