{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce1a70c-eea0-43eb-a14b-e0433adb80e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovely_jax enabled for enhanced array visualization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CudaDevice(id=0)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trainer import *\n",
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3e1440-6d11-48d1-a104-299ce80d8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookArgs:\n",
    "    \"\"\"\n",
    "    Helper class to mimic argparse.Namespace for Jupyter notebooks.\n",
    "    Example:\n",
    "        args = NotebookArgs(\n",
    "            train_efd=\"../preclassified_data/energies_forces_dipoles_train.npz\",\n",
    "            train_grid=\"../preclassified_data/grids_esp_train.npz\",\n",
    "            valid_efd=\"../preclassified_data/energies_forces_dipoles_valid.npz\",\n",
    "            valid_grid=\"../preclassified_data/grids_esp_valid.npz\",\n",
    "            batch_size=16,\n",
    "            epochs=500,\n",
    "            n_dcm=3,\n",
    "            verbose=True,\n",
    "        )\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # Default values ‚Äî should match argparse defaults\n",
    "        defaults = dict(\n",
    "            train_efd=None,\n",
    "            train_grid=None,\n",
    "            valid_efd=None,\n",
    "            valid_grid=None,\n",
    "            features=32,\n",
    "            max_degree=2,\n",
    "            num_iterations=2,\n",
    "            num_basis_functions=32,\n",
    "            cutoff=10.0,\n",
    "            n_dcm=3,\n",
    "            include_pseudotensors=False,\n",
    "            batch_size=32,\n",
    "            epochs=100,\n",
    "            learning_rate=0.001,\n",
    "            esp_weight=10000.0,\n",
    "            seed=42,\n",
    "            restart=None,\n",
    "            name='co2_dcmnet',\n",
    "            output_dir='./checkpoints',\n",
    "            print_freq=10,\n",
    "            save_freq=5,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # Update defaults with user-specified values\n",
    "        defaults.update(kwargs)\n",
    "\n",
    "        # Assign all attributes\n",
    "        for key, val in defaults.items():\n",
    "            setattr(self, key, val)\n",
    "\n",
    "    def as_dict(self):\n",
    "        \"\"\"Return arguments as a plain dict (useful for logging).\"\"\"\n",
    "        return vars(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50f86473-7bf8-4fa8-8739-f3f5e02d052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import main, load_co2_data\n",
    "\n",
    "\n",
    "args = NotebookArgs(\n",
    "    train_efd=Path(\"../preclassified_data/energies_forces_dipoles_train.npz\"),\n",
    "    train_grid=Path(\"../preclassified_data/grids_esp_train.npz\"),\n",
    "    valid_efd=Path(\"../preclassified_data/energies_forces_dipoles_valid.npz\"),\n",
    "    valid_grid=Path(\"../preclassified_data/grids_esp_valid.npz\"),\n",
    "    output_dir=Path(\"./output\"),\n",
    "    batch_size=1000,\n",
    "    epochs=5,\n",
    "    learning_rate=5e-4,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de0be27f-d4ce-4eba-a2fb-1a2484038baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can call your functions directly\n",
    "train_data = load_co2_data(args.train_efd, args.train_grid)\n",
    "valid_data = load_co2_data(args.valid_efd, args.valid_grid)\n",
    "\n",
    "# Or if your `main()` function expects args like from argparse:\n",
    "# \n",
    "\n",
    "len(valid_data[\"R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca8c7e7b-b633-4124-9e0c-1186c963533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DCMNet Training - CO2 ESP Data\n",
      "======================================================================\n",
      "\n",
      "üìÅ Data Files:\n",
      "  Train EFD:  ../preclassified_data/energies_forces_dipoles_train.npz\n",
      "  Train Grid: ../preclassified_data/grids_esp_train.npz\n",
      "  Valid EFD:  ../preclassified_data/energies_forces_dipoles_valid.npz\n",
      "  Valid Grid: ../preclassified_data/grids_esp_valid.npz\n",
      "  Output: output/co2_dcmnet\n",
      "\n",
      "######################################################################\n",
      "# Loading Data\n",
      "######################################################################\n",
      "\n",
      "Loading training data...\n",
      "Loading validation data...\n",
      "\n",
      "‚úÖ Data loaded:\n",
      "  Training samples: 8000\n",
      "  Validation samples: 1000\n",
      "  Data keys: ['R', 'Z', 'N', 'esp', 'vdw_surface', 'Dxyz', 'E']\n",
      "\n",
      "Preparing datasets (computing edge lists, etc.)...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "prepare_datasets() got an unexpected keyword argument 'cutoff'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Prepare datasets (convert to DCMnet format with edge lists, etc.)\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPreparing datasets (computing edge lists, etc.)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m train_data, valid_data = \u001b[43mprepare_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_data_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Datasets prepared\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Training batches: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: prepare_datasets() got an unexpected keyword argument 'cutoff'"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DCMNet Training - CO2 ESP Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Validate input files\n",
    "for fname, fpath in [\n",
    "    ('Train EFD', args.train_efd),\n",
    "    ('Train Grid', args.train_grid),\n",
    "    ('Valid EFD', args.valid_efd),\n",
    "    ('Valid Grid', args.valid_grid)\n",
    "]:\n",
    "    if not fpath.exists():\n",
    "        print(f\"‚ùå Error: {fname} file not found: {fpath}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "print(f\"\\nüìÅ Data Files:\")\n",
    "print(f\"  Train EFD:  {args.train_efd}\")\n",
    "print(f\"  Train Grid: {args.train_grid}\")\n",
    "print(f\"  Valid EFD:  {args.valid_efd}\")\n",
    "print(f\"  Valid Grid: {args.valid_grid}\")\n",
    "\n",
    "# Setup output directory\n",
    "args.output_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(f\"  Output: {args.output_dir / args.name}\")\n",
    "\n",
    "# Load data\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Loading Data\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "if args.verbose:\n",
    "    print(f\"\\nLoading training data...\")\n",
    "train_data_raw = load_co2_data(args.train_efd, args.train_grid)\n",
    "\n",
    "if args.verbose:\n",
    "    print(f\"Loading validation data...\")\n",
    "valid_data_raw = load_co2_data(args.valid_efd, args.valid_grid)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded:\")\n",
    "print(f\"  Training samples: {len(train_data_raw['R'])}\")\n",
    "print(f\"  Validation samples: {len(valid_data_raw['R'])}\")\n",
    "print(f\"  Data keys: {list(train_data_raw.keys())}\")\n",
    "\n",
    "# Prepare datasets (convert to DCMnet format with edge lists, etc.)\n",
    "print(f\"\\nPreparing datasets (computing edge lists, etc.)...\")\n",
    "train_data, valid_data = prepare_datasets(\n",
    "    train_data_raw,\n",
    "    valid_data_raw,\n",
    "    cutoff=args.cutoff,\n",
    "    batch_size=args.batch_size,\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Datasets prepared\")\n",
    "print(f\"  Training batches: {len(train_data)}\")\n",
    "print(f\"  Validation batches: {len(valid_data)}\")\n",
    "\n",
    "# Build model\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Building Model\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "print(f\"\\nModel hyperparameters:\")\n",
    "print(f\"  Features: {args.features}\")\n",
    "print(f\"  Max degree: {args.max_degree}\")\n",
    "print(f\"  Message passing iterations: {args.num_iterations}\")\n",
    "print(f\"  Basis functions: {args.num_basis_functions}\")\n",
    "print(f\"  Cutoff: {args.cutoff} √Ö\")\n",
    "print(f\"  Distributed multipoles per atom: {args.n_dcm}\")\n",
    "print(f\"  Include pseudotensors: {args.include_pseudotensors}\")\n",
    "\n",
    "model = MessagePassingModel(\n",
    "    features=args.features,\n",
    "    max_degree=args.max_degree,\n",
    "    num_iterations=args.num_iterations,\n",
    "    num_basis_functions=args.num_basis_functions,\n",
    "    cutoff=args.cutoff,\n",
    "    n_dcm=args.n_dcm,\n",
    "    include_pseudotensors=args.include_pseudotensors,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model created: DCMNet (n_dcm={args.n_dcm})\")\n",
    "\n",
    "# Training setup\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Training Setup\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "print(f\"\\nTraining hyperparameters:\")\n",
    "print(f\"  Batch size: {args.batch_size}\")\n",
    "print(f\"  Epochs: {args.epochs}\")\n",
    "print(f\"  Learning rate: {args.learning_rate}\")\n",
    "print(f\"  ESP weight: {args.esp_weight}\")\n",
    "print(f\"  Random seed: {args.seed}\")\n",
    "\n",
    "# Load restart parameters if provided\n",
    "restart_params = None\n",
    "if args.restart:\n",
    "    print(f\"\\nüìÇ Loading restart checkpoint: {args.restart}\")\n",
    "    with open(args.restart, 'rb') as f:\n",
    "        restart_params = pickle.load(f)\n",
    "    print(f\"‚úÖ Checkpoint loaded\")\n",
    "\n",
    "# Initialize JAX random key\n",
    "key = jax.random.PRNGKey(args.seed)\n",
    "\n",
    "# Start training\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"STARTING TRAINING\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "try:\n",
    "    final_params = train_model(\n",
    "        key=key,\n",
    "        model=model,\n",
    "        train_data=train_data,\n",
    "        valid_data=valid_data,\n",
    "        num_epochs=args.epochs,\n",
    "        learning_rate=args.learning_rate,\n",
    "        batch_size=args.batch_size,\n",
    "        esp_w=args.esp_weight,\n",
    "        restart_params=restart_params,\n",
    "        name=args.name,\n",
    "        output_dir=args.output_dir,\n",
    "        print_freq=args.print_freq,\n",
    "        save_freq=args.save_freq,\n",
    "    )\n",
    "    \n",
    "    # Save final model\n",
    "    final_path = args.output_dir / f\"{args.name}_final.pkl\"\n",
    "    with open(final_path, 'wb') as f:\n",
    "        pickle.dump(final_params, f)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nFinal parameters saved to: {final_path}\")\n",
    "    print(f\"\\nTo use the trained model:\")\n",
    "    print(f\"  from mmml.dcmnet.dcmnet.modules import MessagePassingModel\")\n",
    "    print(f\"  import pickle\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Load parameters\")\n",
    "    print(f\"  with open('{final_path}', 'rb') as f:\")\n",
    "    print(f\"      params = pickle.load(f)\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Create model and predict\")\n",
    "    print(f\"  model = MessagePassingModel(...)\")\n",
    "    print(f\"  mono, dipo = model.apply(params, Z, R, dst_idx, src_idx)\")\n",
    "    print(f\"  \")\n",
    "    print(f\"  # Calculate ESP\")\n",
    "    print(f\"  from mmml.dcmnet.dcmnet.electrostatics import calc_esp\")\n",
    "    print(f\"  esp_pred = calc_esp(mono, dipo, R, vdw_surface)\")\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(f\"\\n\\n‚ö†Ô∏è  Training interrupted by user\")\n",
    "    print(f\"Checkpoints saved to: {args.output_dir}\")\n",
    "    sys.exit(0)\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\n‚ùå Training failed with error:\")\n",
    "    print(f\"  {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91356807-f3f6-40ae-bc91-947efdb5aaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
