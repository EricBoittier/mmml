# Complete Guide: Running on Scicore HPC

**Everything you need to run your code on Scicore HPC cluster.**

---

## ğŸ“‹ Table of Contents

1. [Quick Start](#quick-start) (5 minutes)
2. [File Structure](#file-structure)
3. [Workflow Overview](#workflow-overview)
4. [Detailed Steps](#detailed-steps)
5. [Plotting Results](#plotting-results)
6. [Troubleshooting](#troubleshooting)

---

## ğŸš€ Quick Start

```bash
# 1. Setup (first time only)
cd sbatch
bash setup_environment.sh
mkdir -p logs

# 2. Test
sbatch 05_gpu_test.sbatch

# 3. Edit data paths in sbatch scripts
# Open any .sbatch file and update these:
TRAIN_EFD="/path/to/train.npz"
TRAIN_ESP="/path/to/grids_train.npz"
VALID_EFD="/path/to/valid.npz"
VALID_ESP="/path/to/grids_valid.npz"

# 4. Run
sbatch 01_train_dcmnet_quick.sbatch

# 5. Plot results
python plot_comparison_results.py comparisons/*/comparison_results.json
```

---

## ğŸ“‚ File Structure

```
dcmnet_physnet_train/
â”‚
â”œâ”€â”€ sbatch/                                    # HPC submission scripts
â”‚   â”œâ”€â”€ 01_train_dcmnet_quick.sbatch          # Quick training (4h)
â”‚   â”œâ”€â”€ 02_train_dcmnet_full.sbatch           # Full training (24h)
â”‚   â”œâ”€â”€ 03_train_noneq_model.sbatch           # Non-equivariant model
â”‚   â”œâ”€â”€ 04_compare_models.sbatch              # Model comparison
â”‚   â”œâ”€â”€ 05_gpu_test.sbatch                    # Environment test
â”‚   â”œâ”€â”€ 06_hyperparameter_array.sbatch        # Hyperparameter sweep
â”‚   â”œâ”€â”€ setup_environment.sh                   # Conda setup script
â”‚   â”œâ”€â”€ README_SBATCH.md                       # Complete sbatch docs
â”‚   â””â”€â”€ QUICK_START.md                         # Quick reference
â”‚
â”œâ”€â”€ plot_comparison_results.py                 # Plotting CLI tool
â”œâ”€â”€ PLOTTING_CLI_GUIDE.md                      # Complete plotting docs
â”œâ”€â”€ PLOTTING_CLI_EXAMPLES.md                   # Quick plotting examples
â”‚
â”œâ”€â”€ trainer.py                                 # Main training script
â”œâ”€â”€ compare_models.py                          # Model comparison script
â”‚
â”œâ”€â”€ logs/                                      # Job output logs
â”‚   â”œâ”€â”€ train_dcmnet_quick_JOBID.out
â”‚   â”œâ”€â”€ train_dcmnet_quick_JOBID.err
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ checkpoints/                               # Model checkpoints
â”‚   â””â”€â”€ MODEL_NAME/
â”‚       â”œâ”€â”€ best_params.pkl
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ comparisons/                               # Comparison results
    â””â”€â”€ COMPARISON_NAME/
        â”œâ”€â”€ comparison_results.json
        â”œâ”€â”€ performance_comparison.png
        â”œâ”€â”€ efficiency_comparison.png
        â”œâ”€â”€ equivariance_comparison.png
        â””â”€â”€ overview_combined.png
```

---

## ğŸ”„ Workflow Overview

### Simple Training Workflow

```
1. Setup Environment          â†’ bash setup_environment.sh
2. Test GPU/Environment       â†’ sbatch 05_gpu_test.sbatch
3. Quick Training Test        â†’ sbatch 01_train_dcmnet_quick.sbatch
4. Full Training              â†’ sbatch 02_train_dcmnet_full.sbatch
5. Plot/Analyze Results       â†’ python plot_comparison_results.py results.json
```

### Model Comparison Workflow

```
1. Run Comparison             â†’ sbatch 04_compare_models.sbatch
2. Wait for Completion        â†’ squeue -u $USER
3. Check Summary              â†’ python plot_comparison_results.py results.json --summary-only
4. Generate Plots             â†’ python plot_comparison_results.py results.json
5. Analyze Results            â†’ View plots in comparisons/
```

### Hyperparameter Tuning Workflow

```
1. Submit Array Job           â†’ sbatch 06_hyperparameter_array.sbatch
2. Monitor Progress           â†’ watch -n 60 squeue -u $USER
3. Wait for All Jobs          â†’ (all 9 jobs complete)
4. Compare Results            â†’ python plot_comparison_results.py \
                                  comparisons/*/comparison_results.json \
                                  --compare-multiple
5. Select Best Model          â†’ Based on plots
```

---

## ğŸ“– Detailed Steps

### Step 1: Initial Setup (First Time Only)

#### On Scicore Login Node:

```bash
# Navigate to your project
cd /path/to/mmml/examples/co2/dcmnet_physnet_train

# Load conda
module load Anaconda3  # or Miniconda3

# Create conda environment
cd sbatch
bash setup_environment.sh
```

**This will:**
- Create `mmml` conda environment
- Install all dependencies
- Verify installation

**Expected time:** 10-15 minutes

---

### Step 2: Test Your Setup

```bash
# Create logs directory
mkdir -p logs

# Submit test job
sbatch 05_gpu_test.sbatch

# Wait ~2 minutes, then check
tail -f logs/test_gpu_*.out
```

**Look for:**
- âœ… JAX computation test passed
- âœ… GPU devices found
- âœ… All packages imported

**If test fails:** See [Troubleshooting](#troubleshooting)

---

### Step 3: Configure Data Paths

Edit each `.sbatch` file you plan to use:

```bash
# Open in your editor
nano 01_train_dcmnet_quick.sbatch

# Find and update these lines:
TRAIN_EFD="/full/path/to/train.npz"
TRAIN_ESP="/full/path/to/grids_train.npz"
VALID_EFD="/full/path/to/valid.npz"
VALID_ESP="/full/path/to/grids_valid.npz"
```

**Important:** Use absolute paths on Scicore!

```bash
# Good
TRAIN_EFD="/scicore/home/mygroup/myuser/data/train.npz"

# Bad
TRAIN_EFD="train.npz"
TRAIN_EFD="../data/train.npz"
```

---

### Step 4: Submit Training Job

#### Quick Test (4 hours, 50 epochs):

```bash
sbatch 01_train_dcmnet_quick.sbatch
```

#### Full Training (24 hours, 200 epochs):

```bash
sbatch 02_train_dcmnet_full.sbatch
```

#### Model Comparison:

```bash
sbatch 04_compare_models.sbatch
```

---

### Step 5: Monitor Progress

```bash
# Check job status
squeue -u $USER

# View live output
tail -f logs/train_dcmnet_quick_JOBID.out

# Check progress
grep "Epoch" logs/train_dcmnet_quick_JOBID.out | tail -5
```

---

### Step 6: Analyze Results

#### Quick Summary:

```bash
python plot_comparison_results.py \
    comparisons/my_comparison/comparison_results.json \
    --summary-only
```

#### Generate All Plots:

```bash
python plot_comparison_results.py \
    comparisons/my_comparison/comparison_results.json
```

#### High-Resolution for Papers:

```bash
python plot_comparison_results.py \
    comparisons/my_comparison/comparison_results.json \
    --format pdf --dpi 300 \
    --output-dir publication_figures
```

---

## ğŸ“Š Plotting Results

### Basic Usage

```bash
# Plot everything
python plot_comparison_results.py comparison_results.json

# Just text summary
python plot_comparison_results.py comparison_results.json --summary-only

# Specific plot type
python plot_comparison_results.py comparison_results.json --plot-type performance
```

### Advanced Options

```bash
# High-res PDF
python plot_comparison_results.py results.json \
    --format pdf --dpi 300 --output-dir paper_figs

# Custom colors
python plot_comparison_results.py results.json \
    --colors "#FF6B6B,#4ECDC4"

# Compare multiple runs
python plot_comparison_results.py \
    run1/results.json run2/results.json run3/results.json \
    --compare-multiple --metric dipole_mae
```

**See `PLOTTING_CLI_GUIDE.md` for complete documentation.**

---

## ğŸ¯ Common Scenarios

### Scenario 1: First Time User

```bash
# 1. Setup
cd sbatch && bash setup_environment.sh

# 2. Test
sbatch 05_gpu_test.sbatch

# 3. Edit data paths in 01_train_dcmnet_quick.sbatch

# 4. Quick training
sbatch 01_train_dcmnet_quick.sbatch

# 5. Check results
tail -f logs/train_dcmnet_quick_*.out
```

### Scenario 2: Production Training

```bash
# 1. Edit 02_train_dcmnet_full.sbatch with your data paths

# 2. Submit job
sbatch 02_train_dcmnet_full.sbatch

# 3. Monitor
squeue -u $USER

# 4. After completion, check checkpoint
ls -lh checkpoints/dcmnet_full_*/
```

### Scenario 3: Model Comparison for Paper

```bash
# 1. Run comparison
sbatch 04_compare_models.sbatch

# 2. Wait for completion (~12 hours)

# 3. Generate publication figures
python plot_comparison_results.py \
    comparisons/model_comparison_*/comparison_results.json \
    --format pdf --dpi 300 --output-dir paper_figures

# 4. Download figures
# On local machine:
# scp -r scicore:/path/to/paper_figures ./
```

### Scenario 4: Hyperparameter Search

```bash
# 1. Edit 06_hyperparameter_array.sbatch
#    Customize learning rates and batch sizes

# 2. Submit array job (9 parallel jobs)
sbatch 06_hyperparameter_array.sbatch

# 3. Monitor all jobs
watch -n 60 "squeue -u $USER"

# 4. After all complete, compare
python plot_comparison_results.py \
    comparisons/hparam_*/comparison_results.json \
    --compare-multiple --metric dipole_mae \
    --output-dir hparam_analysis

# 5. Review and select best
ls -lh hparam_analysis/
```

---

## ğŸ› Troubleshooting

### Problem: GPU test fails

**Check:**
```bash
# View error log
cat logs/test_gpu_*.err

# Check GPU partition
sinfo -p titan

# Verify modules
module list
```

**Solution:**
```bash
# Reload modules
module purge
module load Python/3.11
module load CUDA/12.0  # if needed
```

### Problem: Data files not found

**Error:**
```
âŒ Error: Train EFD file not found: train.npz
```

**Solution:**
1. Use absolute paths
2. Verify files exist:
   ```bash
   ls -lh /path/to/train.npz
   ```
3. Update paths in sbatch script

### Problem: Out of memory

**Error:**
```
slurmstepd: error: Exceeded job memory limit
```

**Solution:**
Edit sbatch script:
```bash
#SBATCH --mem=128G    # Increase from 64G
```
And/or reduce batch size:
```bash
BATCH_SIZE=2          # Reduce from 4 or 8
```

### Problem: Job exceeds time limit

**Solution:**
Request more time:
```bash
#SBATCH --time=48:00:00    # Instead of 24:00:00
#SBATCH --qos=gpu48hours   # If available
```

Or reduce epochs:
```bash
EPOCHS=100                  # Instead of 200
```

### Problem: Environment not found

**Error:**
```
conda: command not found
```

**Solution:**
```bash
module load Anaconda3
source activate mmml
```

### Problem: Plots look bad

**Solutions:**
```bash
# Increase DPI
--dpi 300

# Increase figure size
--figsize 16,12

# Try different colors
--colors "#FF6B6B,#4ECDC4"
```

---

## ğŸ“š Documentation Index

| Document | Purpose |
|----------|---------|
| `SCICORE_COMPLETE_GUIDE.md` | **This file** - Complete workflow |
| `sbatch/README_SBATCH.md` | Complete sbatch script documentation |
| `sbatch/QUICK_START.md` | Quick reference for sbatch scripts |
| `PLOTTING_CLI_GUIDE.md` | Complete plotting tool documentation |
| `PLOTTING_CLI_EXAMPLES.md` | Quick plotting examples |
| `COMPARISON_GUIDE.md` | Model comparison details |
| `MODEL_OPTIONS.md` | Model architecture options |
| `OPTIMIZER_GUIDE.md` | Optimizer selection guide |
| `QUICK_REFERENCE.md` | One-page cheat sheet |

---

## âœ… Checklist

### Before First Run:
- [ ] Environment created (`bash setup_environment.sh`)
- [ ] GPU test passed (`sbatch 05_gpu_test.sbatch`)
- [ ] Data files verified to exist
- [ ] Data paths updated in sbatch scripts
- [ ] `logs/` directory created
- [ ] Reviewed resource requests (memory, time)

### Before Production Run:
- [ ] Quick test successful
- [ ] Checkpoints saving correctly
- [ ] Output looks reasonable
- [ ] Sufficient time allocated
- [ ] Sufficient memory allocated

### After Run Completes:
- [ ] Check exit code (should be 0)
- [ ] Verify checkpoint exists
- [ ] Generate plots
- [ ] Save results

---

## ğŸ“ Learning Path

1. **Beginner:** Start with `sbatch/QUICK_START.md`
2. **Intermediate:** Read `COMPARISON_GUIDE.md` and `PLOTTING_CLI_EXAMPLES.md`
3. **Advanced:** Explore `MODEL_OPTIONS.md` and `OPTIMIZER_GUIDE.md`
4. **Expert:** Customize sbatch scripts and create your own workflows

---

## ğŸ’¡ Tips for Success

1. **Always test first** - Use `05_gpu_test.sbatch` before long runs
2. **Use absolute paths** - Avoid relative paths on HPC
3. **Monitor jobs** - Check logs regularly
4. **Save checkpoints** - Verify they're being created
5. **Start small** - Quick test before full training
6. **Document runs** - Keep notes on what works
7. **Backup results** - Download important checkpoints/plots
8. **Check quotas** - Monitor disk space usage

---

## ğŸš€ Next Steps

After successful training:

1. **Evaluate model:**
   - Use evaluation scripts in project
   - Run dynamics simulations
   - Calculate spectroscopic properties

2. **Refine model:**
   - Try different hyperparameters
   - Adjust architecture
   - Add more training data

3. **Publish results:**
   - Generate high-res figures
   - Write up findings
   - Share code/models

---

## ğŸ“ Getting Help

1. **Check logs:** Always look at `.out` and `.err` files first
2. **Test script:** Run `05_gpu_test.sbatch` to verify environment
3. **Documentation:** See index above for relevant docs
4. **Scicore wiki:** https://wiki.scicore.unibas.ch/

---

**You're all set! Start with the Quick Start section above. Good luck! ğŸ‰**

