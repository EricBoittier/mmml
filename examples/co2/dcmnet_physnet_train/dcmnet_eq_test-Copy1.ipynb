{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e266bff-7dd2-4526-aa4a-e33ecf7e62ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook arguments initialized. Ready to run comparison interactively.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Head-to-Head Comparison: Equivariant vs Non-Equivariant Models\n",
    "\n",
    "This notebook cell version:\n",
    "- Allows interactive execution without command-line arguments\n",
    "- Preserves all functionality of compare_models.py\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, Tuple, Any, List\n",
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "# Add mmml to path (adjust if necessary)\n",
    "repo_root = Path(\".\").resolve().parent.parent.parent\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# Import training script components\n",
    "from trainer import (\n",
    "    JointPhysNetDCMNet,\n",
    "    JointPhysNetNonEquivariant,\n",
    "    load_combined_data,\n",
    "    train_model,\n",
    "    create_optimizer,\n",
    "    get_recommended_optimizer_config,\n",
    "    LossTerm,\n",
    ")\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    HAS_MATPLOTLIB = True\n",
    "except ImportError:\n",
    "    HAS_MATPLOTLIB = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelMetrics:\n",
    "    \"\"\"Store metrics for a single model.\"\"\"\n",
    "    name: str\n",
    "    training_time: float\n",
    "    inference_time: float\n",
    "    memory_usage_mb: float\n",
    "    num_parameters: int\n",
    "    val_energy_mae: float\n",
    "    val_forces_mae: float\n",
    "    val_dipole_mae: float\n",
    "    val_esp_mae: float\n",
    "    rotation_error_dipole: float\n",
    "    rotation_error_esp: float\n",
    "    translation_error_dipole: float\n",
    "    translation_error_esp: float\n",
    "\n",
    "\n",
    "def apply_rotation(positions: np.ndarray, rotation_matrix: np.ndarray) -> np.ndarray:\n",
    "    return np.einsum('ij,snj->sni', rotation_matrix, positions)\n",
    "\n",
    "\n",
    "def apply_translation(positions: np.ndarray, translation: np.ndarray) -> np.ndarray:\n",
    "    return positions + translation[None, None, :]\n",
    "\n",
    "\n",
    "def generate_random_rotation() -> np.ndarray:\n",
    "    return Rotation.random().as_matrix()\n",
    "\n",
    "\n",
    "def predict_single(model: Any, params: Any, R: np.ndarray, Z: np.ndarray, N: np.ndarray, vdw_surface: np.ndarray) -> Dict[str, np.ndarray]:\n",
    "    import e3x\n",
    "\n",
    "    natoms = R.shape[1]\n",
    "    batch_size = 1\n",
    "    positions_flat = R.reshape(-1, 3)\n",
    "    atomic_numbers_flat = Z.reshape(-1)\n",
    "\n",
    "    cutoff = 10.0\n",
    "    n_atoms = int(N[0])\n",
    "    dst_idx_list = []\n",
    "    src_idx_list = []\n",
    "    for i in range(n_atoms):\n",
    "        for j in range(n_atoms):\n",
    "            if i != j:\n",
    "                dist = np.linalg.norm(R[0, i] - R[0, j])\n",
    "                if dist < cutoff:\n",
    "                    dst_idx_list.append(i)\n",
    "                    src_idx_list.append(j)\n",
    "\n",
    "    dst_idx = jnp.array(dst_idx_list, dtype=jnp.int32)\n",
    "    src_idx = jnp.array(src_idx_list, dtype=jnp.int32)\n",
    "\n",
    "    batch_segments = jnp.zeros(natoms, dtype=jnp.int32)\n",
    "    batch_mask = jnp.ones(batch_size)\n",
    "    atom_mask = (jnp.arange(natoms) < n_atoms).astype(jnp.float32)\n",
    "\n",
    "    output = model.apply(\n",
    "        params,\n",
    "        atomic_numbers=jnp.array(atomic_numbers_flat),\n",
    "        positions=jnp.array(positions_flat),\n",
    "        dst_idx=dst_idx,\n",
    "        src_idx=src_idx,\n",
    "        batch_segments=batch_segments,\n",
    "        batch_size=batch_size,\n",
    "        batch_mask=batch_mask,\n",
    "        atom_mask=atom_mask,\n",
    "    )\n",
    "\n",
    "    mono_dist = output['mono_dist'].reshape(batch_size, natoms, -1)\n",
    "    dipo_dist = output['dipo_dist'].reshape(batch_size, natoms, -1, 3)\n",
    "\n",
    "    esp_pred = calculate_esp(\n",
    "        mono_dist[0],\n",
    "        dipo_dist[0],\n",
    "        vdw_surface[0],\n",
    "        atom_mask,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'dipole': np.array(output['dipoles_dcmnet'][0]),\n",
    "        'esp': np.array(esp_pred),\n",
    "        'energy': np.array(output['energy'][0]),\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_esp(charges: jnp.ndarray, positions: jnp.ndarray, grid_points: jnp.ndarray, atom_mask: jnp.ndarray) -> jnp.ndarray:\n",
    "    natoms, n_dcm = charges.shape\n",
    "    ngrid = grid_points.shape[0]\n",
    "\n",
    "    charges_flat = charges.reshape(-1)\n",
    "    positions_flat = positions.reshape(-1, 3)\n",
    "    atom_mask_expanded = jnp.repeat(atom_mask, n_dcm)\n",
    "    charges_masked = charges_flat * atom_mask_expanded\n",
    "\n",
    "    diff = grid_points[:, None, :] - positions_flat[None, :, :]\n",
    "    distances = jnp.linalg.norm(diff, axis=-1)\n",
    "    distances = jnp.where(distances < 1e-6, 1e6, distances)\n",
    "\n",
    "    distances_bohr = distances * 1.88973\n",
    "    esp = jnp.sum(charges_masked[None, :] / distances_bohr, axis=1)\n",
    "    return esp\n",
    "\n",
    "\n",
    "def test_equivariance(model, params, test_data, num_test_samples=10, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n_available = len(test_data['E'])\n",
    "    test_indices = rng.choice(n_available, size=min(num_test_samples, n_available), replace=False)\n",
    "\n",
    "    rotation_errors_dipole = []\n",
    "    rotation_errors_esp = []\n",
    "    translation_errors_dipole = []\n",
    "    translation_errors_esp = []\n",
    "\n",
    "    for idx in test_indices:\n",
    "        R = test_data['R'][idx:idx+1]\n",
    "        Z = test_data['Z'][idx:idx+1]\n",
    "        N = test_data['N'][idx:idx+1]\n",
    "        vdw_surface = test_data['vdw_surface'][idx:idx+1]\n",
    "\n",
    "        output_orig = predict_single(model, params, R, Z, N, vdw_surface)\n",
    "\n",
    "        rot_matrix = generate_random_rotation()\n",
    "        R_rot = apply_rotation(R, rot_matrix)\n",
    "        vdw_rot = apply_rotation(vdw_surface, rot_matrix)\n",
    "        output_rot = predict_single(model, params, R_rot, Z, N, vdw_rot)\n",
    "\n",
    "        dipole_orig = output_orig['dipole']\n",
    "        dipole_rot = output_rot['dipole']\n",
    "        dipole_expected = np.dot(rot_matrix, dipole_orig)\n",
    "        rotation_error_dipole = np.linalg.norm(dipole_rot - dipole_expected)\n",
    "        rotation_errors_dipole.append(rotation_error_dipole)\n",
    "\n",
    "        esp_orig = output_orig['esp']\n",
    "        esp_rot = output_rot['esp']\n",
    "        rotation_error_esp = np.mean(np.abs(esp_rot - esp_orig))\n",
    "        rotation_errors_esp.append(rotation_error_esp)\n",
    "\n",
    "        translation = rng.randn(3) * 5.0\n",
    "        R_trans = apply_translation(R, translation)\n",
    "        vdw_trans = apply_translation(vdw_surface, translation)\n",
    "        output_trans = predict_single(model, params, R_trans, Z, N, vdw_trans)\n",
    "\n",
    "        dipole_trans = output_trans['dipole']\n",
    "        translation_error_dipole = np.linalg.norm(dipole_trans - dipole_orig)\n",
    "        translation_errors_dipole.append(translation_error_dipole)\n",
    "\n",
    "        esp_trans = output_trans['esp']\n",
    "        translation_error_esp = np.mean(np.abs(esp_trans - esp_orig))\n",
    "        translation_errors_esp.append(translation_error_esp)\n",
    "\n",
    "    return {\n",
    "        'rotation_error_dipole': float(np.mean(rotation_errors_dipole)),\n",
    "        'rotation_error_esp': float(np.mean(rotation_errors_esp)),\n",
    "        'translation_error_dipole': float(np.mean(translation_errors_dipole)),\n",
    "        'translation_error_esp': float(np.mean(translation_errors_esp)),\n",
    "    }\n",
    "\n",
    "\n",
    "def measure_inference_time(model, params, test_data, num_samples=50):\n",
    "    indices = np.random.choice(len(test_data['E']), size=min(num_samples, len(test_data['E'])), replace=False)\n",
    "    times = []\n",
    "    for idx in indices:\n",
    "        R = test_data['R'][idx:idx+1]\n",
    "        Z = test_data['Z'][idx:idx+1]\n",
    "        N = test_data['N'][idx:idx+1]\n",
    "        vdw_surface = test_data['vdw_surface'][idx:idx+1]\n",
    "        start = time.time()\n",
    "        _ = predict_single(model, params, R, Z, N, vdw_surface)\n",
    "        times.append(time.time() - start)\n",
    "    return float(np.mean(times))\n",
    "\n",
    "\n",
    "def count_parameters(params):\n",
    "    return sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
    "\n",
    "\n",
    "# ========== Example interactive setup for notebook ==========\n",
    "\n",
    "class Args:\n",
    "    train_efd = Path(\"/scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/energies_forces_dipoles_train.npz\")\n",
    "    train_esp = Path(\"/scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/grids_esp_train.npz\")\n",
    "    valid_efd = Path(\"/scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/energies_forces_dipoles_valid.npz\")\n",
    "    valid_esp = Path(\"/scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/grids_esp_valid.npz\")\n",
    "    epochs = 1000\n",
    "    batch_size = 1000\n",
    "    seed = 42\n",
    "    physnet_features = 128\n",
    "    dcmnet_features = 128\n",
    "    n_dcm = 2\n",
    "    comparison_name = \"interactive_comparison2\"\n",
    "    output_dir = Path(\"comparisons\")\n",
    "    skip_training = True\n",
    "    equivariance_samples = 10\n",
    "\n",
    "args = Args()\n",
    "print(\"Notebook arguments initialized. Ready to run comparison interactively.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddadf124-b8bf-4373-be38-a6c33722ab04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CudaDevice(id=0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b0c7c4-bd11-47f2-adf2-3e43039b7452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Args at 0x14823f84d670>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba1ad23-cac7-423a-af80-ce1fa4b4b70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "get_recommended_optimizer_config(\n",
       "    dataset_size: int,\n",
       "    num_features: int,\n",
       "    num_atoms: int,\n",
       "    optimizer_name: str = \u001b[33m'adamw'\u001b[39m,\n",
       ") -> Dict[str, Any]\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Get recommended optimizer hyperparameters based on dataset properties.\n",
       "\n",
       "Args:\n",
       "    dataset_size: Number of training samples\n",
       "    num_features: Total number of model features (PhysNet + DCMNet)\n",
       "    num_atoms: Maximum number of atoms in molecules\n",
       "    optimizer_name: One of 'adam', 'adamw', 'rmsprop', 'muon'\n",
       "\n",
       "Returns:\n",
       "    Dictionary with recommended hyperparameters\n",
       "\u001b[31mFile:\u001b[39m      ~/mmml/examples/co2/dcmnet_physnet_train/trainer.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from compare_models import *\n",
    "get_recommended_optimizer_config?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb09365e-5626-49b5-9d37-0d6e39b53e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HEAD-TO-HEAD MODEL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Comparison: interactive_comparison2\n",
      "Output directory: comparisons/interactive_comparison2\n",
      "\n",
      "######################################################################\n",
      "# Loading Data\n",
      "######################################################################\n",
      "\n",
      "  Loading EFD: /scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/energies_forces_dipoles_train.npz\n",
      "  Loading ESP: /scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/grids_esp_train.npz\n",
      "  ‚úÖ Subtracted atomic energies (now relative to isolated atoms)\n",
      "  Aligning ESP grids to molecular reference frames...\n",
      "  ‚úÖ Aligned ESP grids to molecular reference frames\n",
      "     Sample 0 - Atom COM: [0.         0.14525378 0.11470596]\n",
      "     Sample 0 - Grid COM before: [3.25342429 3.24367862 3.3973045 ]\n",
      "     Sample 0 - Grid COM after: [2.56091444e-16 1.45253775e-01 1.14705956e-01]\n",
      "     Sample 0 - Offset corrected: [3.25342429 3.09842484 3.28259855] √Ö\n",
      "  Combined data shapes:\n",
      "    R: (8000, 60, 3)\n",
      "    Z: (8000, 60)\n",
      "    N: (8000,)\n",
      "    E: (8000,)\n",
      "    F: (8000, 60, 3)\n",
      "    Dxyz: (8000, 3)\n",
      "    esp: (8000, 3000)\n",
      "    vdw_surface: (8000, 3000, 3)\n",
      "  Data padding: 60 atoms\n",
      "  Max actual atoms: 3\n",
      "  Loading EFD: /scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/energies_forces_dipoles_valid.npz\n",
      "  Loading ESP: /scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/grids_esp_valid.npz\n",
      "  ‚úÖ Subtracted atomic energies (now relative to isolated atoms)\n",
      "  Aligning ESP grids to molecular reference frames...\n",
      "  ‚úÖ Aligned ESP grids to molecular reference frames\n",
      "     Sample 0 - Atom COM: [0.         0.25326187 0.02194556]\n",
      "     Sample 0 - Grid COM before: [3.22872937 3.4025402  3.33670261]\n",
      "     Sample 0 - Grid COM after: [2.56683563e-15 2.53261870e-01 2.19455598e-02]\n",
      "     Sample 0 - Offset corrected: [3.22872937 3.14927833 3.31475705] √Ö\n",
      "  Combined data shapes:\n",
      "    R: (1000, 60, 3)\n",
      "    Z: (1000, 60)\n",
      "    N: (1000,)\n",
      "    E: (1000,)\n",
      "    F: (1000, 60, 3)\n",
      "    Dxyz: (1000, 3)\n",
      "    esp: (1000, 3000)\n",
      "    vdw_surface: (1000, 3000, 3)\n",
      "  Data padding: 60 atoms\n",
      "  Max actual atoms: 3\n",
      "\n",
      "‚úÖ Data loaded:\n",
      "  Training samples: 8000\n",
      "  Validation samples: 1000\n",
      "\n",
      "######################################################################\n",
      "# DCMNet (Equivariant) Model\n",
      "######################################################################\n",
      "\n",
      "‚è© Loading existing checkpoint: comparisons/interactive_comparison2/dcmnet_equivariant/best_params.pkl\n",
      "\n",
      "######################################################################\n",
      "# Non-Equivariant Model\n",
      "######################################################################\n",
      "\n",
      "‚è© Loading existing checkpoint: comparisons/interactive_comparison2/noneq_model/best_params.pkl\n",
      "\n",
      "######################################################################\n",
      "# Equivariance Testing\n",
      "######################################################################\n",
      "\n",
      "--- DCMNet (Equivariant) ---\n",
      "\n",
      "======================================================================\n",
      "Testing Equivariance on 10 samples\n",
      "======================================================================\n",
      "\n",
      "Rotation Equivariance:\n",
      "  Dipole error: 0.000494 ¬± 0.000312 e¬∑√Ö\n",
      "  ESP error:    0.000043 ¬± 0.000033 Ha/e\n",
      "\n",
      "Translation Invariance:\n",
      "  Dipole error: 0.000008 ¬± 0.000024 e¬∑√Ö\n",
      "  ESP error:    0.000000 ¬± 0.000001 Ha/e\n",
      "\n",
      "Reference Property Errors:\n",
      "  Energy MAE: 0.095190 ¬± 0.054172 eV\n",
      "  Forces MAE: 0.151763 ¬± 0.110201 eV/√Ö\n",
      "  Dipole MAE: 0.137116 ¬± 0.036321 e¬∑√Ö\n",
      "  ESP MAE:    0.012803 ¬± 0.001558 Ha/e\n",
      "\n",
      "--- Non-Equivariant ---\n",
      "\n",
      "======================================================================\n",
      "Testing Equivariance on 10 samples\n",
      "======================================================================\n",
      "\n",
      "Rotation Equivariance:\n",
      "  Dipole error: 0.043139 ¬± 0.027889 e¬∑√Ö\n",
      "  ESP error:    0.004409 ¬± 0.000877 Ha/e\n",
      "\n",
      "Translation Invariance:\n",
      "  Dipole error: 0.000018 ¬± 0.000039 e¬∑√Ö\n",
      "  ESP error:    0.000003 ¬± 0.000006 Ha/e\n",
      "\n",
      "Reference Property Errors:\n",
      "  Energy MAE: 0.098163 ¬± 0.050337 eV\n",
      "  Forces MAE: 0.226789 ¬± 0.140536 eV/√Ö\n",
      "  Dipole MAE: 0.139477 ¬± 0.033002 e¬∑√Ö\n",
      "  ESP MAE:    0.013020 ¬± 0.001340 Ha/e\n",
      "\n",
      "######################################################################\n",
      "# Performance Benchmarking\n",
      "######################################################################\n",
      "\n",
      "\n",
      "Parameter counts:\n",
      "  DCMNet:        484,619 parameters\n",
      "  Non-Eq:        315,870 parameters\n",
      "  Reduction:     34.8%\n",
      "\n",
      "######################################################################\n",
      "# Final Comparison Report\n",
      "######################################################################\n",
      "\n",
      "VALIDATION PERFORMANCE:\n",
      "  Energy MAE:  DCMNet=0.0955, Non-Eq=0.0979\n",
      "  Forces MAE:  DCMNet=0.0146, Non-Eq=0.0140\n",
      "  Dipole MAE:  DCMNet=0.0887, Non-Eq=0.0712\n",
      "  ESP MAE:     DCMNet=0.0040, Non-Eq=0.0040\n",
      "\n",
      "EQUIVARIANCE (Rotation):\n",
      "  Dipole:      DCMNet=0.000494, Non-Eq=0.043139\n",
      "  ESP:         DCMNet=0.000043, Non-Eq=0.004409\n",
      "  ‚ö†Ô∏è  DCMNet should have near-zero rotation error (equivariant)\n",
      "  ‚ö†Ô∏è  Non-Eq will have larger error (not equivariant)\n",
      "\n",
      "INVARIANCE (Translation):\n",
      "  Dipole:      DCMNet=0.000008, Non-Eq=0.000018\n",
      "  ESP:         DCMNet=0.000000, Non-Eq=0.000003\n",
      "  ‚úÖ Both should have near-zero translation error\n",
      "\n",
      "‚úÖ Results saved to: comparisons/interactive_comparison2/comparison_results.json\n",
      "\n",
      "######################################################################\n",
      "# Generating Comparison Plots\n",
      "######################################################################\n",
      "\n",
      "  ‚úÖ Saved: comparisons/interactive_comparison2/performance_comparison.png\n",
      "  ‚úÖ Saved: comparisons/interactive_comparison2/efficiency_comparison.png\n",
      "  ‚úÖ Saved: comparisons/interactive_comparison2/equivariance_comparison.png\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPARISON COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "All results saved to: comparisons/interactive_comparison2\n",
      "\n",
      "Generated files:\n",
      "  - comparison_results.json\n",
      "  - performance_comparison.png\n",
      "  - efficiency_comparison.png\n",
      "  - equivariance_comparison.png\n",
      "  - dcmnet_equivariant/ (checkpoint)\n",
      "  - noneq_model/ (checkpoint)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create output directory\n",
    "output_dir = args.output_dir / args.comparison_name\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HEAD-TO-HEAD MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nComparison: {args.comparison_name}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Load data\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Loading Data\")\n",
    "print(f\"{'#'*70}\\n\")\n",
    "\n",
    "train_data = load_combined_data(args.train_efd, args.train_esp, verbose=True)\n",
    "valid_data = load_combined_data(args.valid_efd, args.valid_esp, verbose=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded:\")\n",
    "print(f\"  Training samples: {len(train_data['E'])}\")\n",
    "print(f\"  Validation samples: {len(valid_data['E'])}\")\n",
    "\n",
    "# Get dataset properties\n",
    "natoms = train_data['R'].shape[1]\n",
    "max_atomic_number = int(max(np.max(train_data['Z']), np.max(valid_data['Z'])))\n",
    "\n",
    "# Shared PhysNet config\n",
    "physnet_config = {\n",
    "    'features': args.physnet_features,\n",
    "    'max_degree': 0,\n",
    "    'num_iterations': 3,\n",
    "    'num_basis_functions': 64,\n",
    "    'cutoff': 6.0,\n",
    "    'max_atomic_number': max_atomic_number,\n",
    "    'charges': True,\n",
    "    'natoms': natoms,\n",
    "    'total_charge': 0.0,\n",
    "    'n_res': 3,\n",
    "    'zbl': False,\n",
    "    'use_energy_bias': True,\n",
    "    'debug': False,\n",
    "    'efa': False,\n",
    "}\n",
    "\n",
    "# Get recommended optimizer settings\n",
    "recommended_config = get_recommended_optimizer_config(\n",
    "    dataset_size=len(train_data['E']),\n",
    "    num_features=args.physnet_features + args.dcmnet_features,\n",
    "    num_atoms=natoms,\n",
    "    optimizer_name='adam',\n",
    ")\n",
    "\n",
    "# Model configurations\n",
    "dcmnet_config = {\n",
    "    'features': args.dcmnet_features,\n",
    "    'max_degree': 2,\n",
    "    'num_iterations': 2,\n",
    "    'num_basis_functions': 64,\n",
    "    'cutoff': 10.0,\n",
    "    'max_atomic_number': max_atomic_number,\n",
    "    'n_dcm': args.n_dcm,\n",
    "    'include_pseudotensors': False,\n",
    "}\n",
    "\n",
    "noneq_config = {\n",
    "    'features': args.dcmnet_features ,  \n",
    "    'n_dcm': args.n_dcm,\n",
    "    'max_atomic_number': max_atomic_number,\n",
    "    'num_layers': 5,\n",
    "    'max_displacement': 1.0,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# ==================================================================\n",
    "# Train/Load DCMNet (Equivariant)\n",
    "# ==================================================================\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# DCMNet (Equivariant) Model\")\n",
    "print(f\"{'#'*70}\\n\")\n",
    "\n",
    "dcm_ckpt_dir = output_dir / 'dcmnet_equivariant'\n",
    "dcm_ckpt_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model_dcm = JointPhysNetDCMNet(\n",
    "    physnet_config=physnet_config,\n",
    "    dcmnet_config=dcmnet_config,\n",
    "    mix_coulomb_energy=False,\n",
    ")\n",
    "\n",
    "if args.skip_training and (dcm_ckpt_dir / 'best_params.pkl').exists():\n",
    "    print(f\"‚è© Loading existing checkpoint: {dcm_ckpt_dir / 'best_params.pkl'}\")\n",
    "    with open(dcm_ckpt_dir / 'best_params.pkl', 'rb') as f:\n",
    "        params_dcm = pickle.load(f)\n",
    "    training_time_dcm = 0.0\n",
    "else:\n",
    "    print(\"üèãÔ∏è  Training DCMNet...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create loss terms for training\n",
    "    dipole_terms = (\n",
    "        LossTerm(source='physnet', weight=25.0, metric='l2', name='physnet'),\n",
    "    )\n",
    "    esp_terms = (\n",
    "        LossTerm(source='dcmnet', weight=10000.0, metric='l2', name='dcmnet'),\n",
    "    )\n",
    "    \n",
    "    params_dcm = train_model(\n",
    "        model=model_dcm,\n",
    "        train_data=train_data,\n",
    "        valid_data=valid_data,\n",
    "        num_epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        learning_rate=recommended_config['learning_rate'],\n",
    "        weight_decay=recommended_config['weight_decay'],\n",
    "        energy_w=10.0,\n",
    "        forces_w=50.0,\n",
    "        dipole_w=25.0,\n",
    "        esp_w=10000.0,\n",
    "        mono_w=100.0,\n",
    "        n_dcm=args.n_dcm,\n",
    "        cutoff=10.0,\n",
    "        seed=args.seed,\n",
    "        ckpt_dir=dcm_ckpt_dir.parent,\n",
    "        name=dcm_ckpt_dir.name,\n",
    "        print_freq=5,\n",
    "        dipole_terms=dipole_terms,\n",
    "        esp_terms=esp_terms,\n",
    "        optimizer_name='adam',\n",
    "        optimizer_kwargs={'b1': 0.9, 'b2': 0.999},\n",
    "    )\n",
    "    \n",
    "    training_time_dcm = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ DCMNet training completed in {training_time_dcm/3600:.2f} hours\")\n",
    "\n",
    "# ==================================================================\n",
    "# Train/Load Non-Equivariant\n",
    "# ==================================================================\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Non-Equivariant Model\")\n",
    "print(f\"{'#'*70}\\n\")\n",
    "\n",
    "noneq_ckpt_dir = output_dir / 'noneq_model'\n",
    "noneq_ckpt_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "model_noneq = JointPhysNetNonEquivariant(\n",
    "    physnet_config=physnet_config,\n",
    "    noneq_config=noneq_config,\n",
    "    mix_coulomb_energy=False,\n",
    ")\n",
    "\n",
    "if args.skip_training and (noneq_ckpt_dir / 'best_params.pkl').exists():\n",
    "    print(f\"‚è© Loading existing checkpoint: {noneq_ckpt_dir / 'best_params.pkl'}\")\n",
    "    with open(noneq_ckpt_dir / 'best_params.pkl', 'rb') as f:\n",
    "        params_noneq = pickle.load(f)\n",
    "    training_time_noneq = 0.0\n",
    "else:\n",
    "    print(\"üèãÔ∏è  Training Non-Equivariant model...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create loss terms for training (same as DCMNet for fair comparison)\n",
    "    dipole_terms = (\n",
    "        LossTerm(source='physnet', weight=25.0, metric='l2', name='physnet'),\n",
    "    )\n",
    "    esp_terms = (\n",
    "        LossTerm(source='dcmnet', weight=10000.0, metric='l2', name='dcmnet'),\n",
    "    )\n",
    "    \n",
    "    params_noneq = train_model(\n",
    "        model=model_noneq,\n",
    "        train_data=train_data,\n",
    "        valid_data=valid_data,\n",
    "        num_epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        learning_rate=recommended_config['learning_rate'],\n",
    "        weight_decay=recommended_config['weight_decay'],\n",
    "        energy_w=10.0,\n",
    "        forces_w=50.0,\n",
    "        dipole_w=25.0,\n",
    "        esp_w=10000.0,\n",
    "        mono_w=100.0,\n",
    "        n_dcm=args.n_dcm,\n",
    "        cutoff=10.0,\n",
    "        seed=args.seed,\n",
    "        ckpt_dir=noneq_ckpt_dir.parent,\n",
    "        name=noneq_ckpt_dir.name,\n",
    "        print_freq=5,\n",
    "        dipole_terms=dipole_terms,\n",
    "        esp_terms=esp_terms,\n",
    "        optimizer_name='adam',\n",
    "        optimizer_kwargs={'b1': 0.9, 'b2': 0.999},\n",
    "    )\n",
    "    \n",
    "    training_time_noneq = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ Non-Equivariant training completed in {training_time_noneq/3600:.2f} hours\")\n",
    "\n",
    "# ==================================================================\n",
    "# Run Equivariance Tests\n",
    "# ==================================================================\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Equivariance Testing\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "print(\"\\n--- DCMNet (Equivariant) ---\")\n",
    "equivariance_dcm = test_equivariance(\n",
    "    model_dcm,\n",
    "    params_dcm,\n",
    "    valid_data,\n",
    "    num_test_samples=args.equivariance_samples,\n",
    "    seed=args.seed,\n",
    ")\n",
    "\n",
    "print(\"\\n--- Non-Equivariant ---\")\n",
    "equivariance_noneq = test_equivariance(\n",
    "    model_noneq,\n",
    "    params_noneq,\n",
    "    valid_data,\n",
    "    num_test_samples=args.equivariance_samples,\n",
    "    seed=args.seed,\n",
    ")\n",
    "\n",
    "# ==================================================================\n",
    "# Measure Performance\n",
    "# ==================================================================\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Performance Benchmarking\")\n",
    "print(f\"{'#'*70}\\n\")\n",
    "\n",
    "# print(\"Measuring inference times...\")\n",
    "# inference_time_dcm = measure_inference_time(model_dcm, params_dcm, valid_data, num_samples=50)\n",
    "# inference_time_noneq = measure_inference_time(model_noneq, params_noneq, valid_data, num_samples=50)\n",
    "\n",
    "# print(f\"  DCMNet:        {inference_time_dcm*1000:.2f} ms/sample\")\n",
    "# print(f\"  Non-Eq:        {inference_time_noneq*1000:.2f} ms/sample\")\n",
    "# print(f\"  Speedup:       {inference_time_dcm/inference_time_noneq:.2f}√ó\")\n",
    "\n",
    "num_params_dcm = count_parameters(params_dcm)\n",
    "num_params_noneq = count_parameters(params_noneq)\n",
    "\n",
    "print(f\"\\nParameter counts:\")\n",
    "print(f\"  DCMNet:        {num_params_dcm:,} parameters\")\n",
    "print(f\"  Non-Eq:        {num_params_noneq:,} parameters\")\n",
    "print(f\"  Reduction:     {(1 - num_params_noneq/num_params_dcm)*100:.1f}%\")\n",
    "\n",
    "# Load validation metrics from history (with fallback for missing files)\n",
    "history_dcm_path = dcm_ckpt_dir / 'history.json'\n",
    "history_noneq_path = noneq_ckpt_dir / 'history.json'\n",
    "\n",
    "if history_dcm_path.exists():\n",
    "    with open(history_dcm_path, 'r') as f:\n",
    "        history_dcm = json.load(f)\n",
    "    best_epoch_dcm = np.argmin(history_dcm['val_loss'])\n",
    "    val_energy_mae_dcm = history_dcm['val_energy_mae'][best_epoch_dcm]\n",
    "    val_forces_mae_dcm = history_dcm['val_forces_mae'][best_epoch_dcm]\n",
    "    val_dipole_mae_dcm = history_dcm['val_dipole_mae'][best_epoch_dcm]\n",
    "    val_esp_mae_dcm = history_dcm['val_esp_mae'][best_epoch_dcm]\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Warning: No history file found for DCMNet at {history_dcm_path}\")\n",
    "    print(\"   Using placeholder values (0.0) for validation metrics.\")\n",
    "    print(\"   Rerun comparison to get full metrics.\")\n",
    "    val_energy_mae_dcm = 0.0\n",
    "    val_forces_mae_dcm = 0.0\n",
    "    val_dipole_mae_dcm = 0.0\n",
    "    val_esp_mae_dcm = 0.0\n",
    "\n",
    "if history_noneq_path.exists():\n",
    "    with open(history_noneq_path, 'r') as f:\n",
    "        history_noneq = json.load(f)\n",
    "    best_epoch_noneq = np.argmin(history_noneq['val_loss'])\n",
    "    val_energy_mae_noneq = history_noneq['val_energy_mae'][best_epoch_noneq]\n",
    "    val_forces_mae_noneq = history_noneq['val_forces_mae'][best_epoch_noneq]\n",
    "    val_dipole_mae_noneq = history_noneq['val_dipole_mae'][best_epoch_noneq]\n",
    "    val_esp_mae_noneq = history_noneq['val_esp_mae'][best_epoch_noneq]\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Warning: No history file found for Non-Eq at {history_noneq_path}\")\n",
    "    print(\"   Using placeholder values (0.0) for validation metrics.\")\n",
    "    print(\"   Rerun comparison to get full metrics.\")\n",
    "    val_energy_mae_noneq = 0.0\n",
    "    val_forces_mae_noneq = 0.0\n",
    "    val_dipole_mae_noneq = 0.0\n",
    "    val_esp_mae_noneq = 0.0\n",
    "\n",
    "# Create metrics objects\n",
    "metrics_dcm = ModelMetrics(\n",
    "    name='DCMNet (Equivariant)',\n",
    "    training_time=0,\n",
    "    inference_time=0,\n",
    "    memory_usage_mb=0.0,  # Would need profiling\n",
    "    num_parameters=num_params_dcm,\n",
    "    val_energy_mae=val_energy_mae_dcm,\n",
    "    val_forces_mae=val_forces_mae_dcm,\n",
    "    val_dipole_mae=val_dipole_mae_dcm,\n",
    "    val_esp_mae=val_esp_mae_dcm,\n",
    "    rotation_error_dipole=equivariance_dcm['rotation_error_dipole'],\n",
    "    rotation_error_esp=equivariance_dcm['rotation_error_esp'],\n",
    "    translation_error_dipole=equivariance_dcm['translation_error_dipole'],\n",
    "    translation_error_esp=equivariance_dcm['translation_error_esp'],\n",
    ")\n",
    "\n",
    "metrics_noneq = ModelMetrics(\n",
    "    name='Non-Equivariant',\n",
    "    # training_time=training_time_noneq,\n",
    "    # inference_time=inference_time_noneq,\n",
    "    training_time=0,\n",
    "    inference_time=0,\n",
    "    memory_usage_mb=0.0,\n",
    "    num_parameters=num_params_noneq,\n",
    "    val_energy_mae=val_energy_mae_noneq,\n",
    "    val_forces_mae=val_forces_mae_noneq,\n",
    "    val_dipole_mae=val_dipole_mae_noneq,\n",
    "    val_esp_mae=val_esp_mae_noneq,\n",
    "    rotation_error_dipole=equivariance_noneq['rotation_error_dipole'],\n",
    "    rotation_error_esp=equivariance_noneq['rotation_error_esp'],\n",
    "    translation_error_dipole=equivariance_noneq['translation_error_dipole'],\n",
    "    translation_error_esp=equivariance_noneq['translation_error_esp'],\n",
    ")\n",
    "\n",
    "# ==================================================================\n",
    "# Generate Comparison Report\n",
    "# ==================================================================\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Final Comparison Report\")\n",
    "print(f\"{'#'*70}\\n\")\n",
    "\n",
    "print(\"VALIDATION PERFORMANCE:\")\n",
    "print(f\"  Energy MAE:  DCMNet={metrics_dcm.val_energy_mae:.4f}, Non-Eq={metrics_noneq.val_energy_mae:.4f}\")\n",
    "print(f\"  Forces MAE:  DCMNet={metrics_dcm.val_forces_mae:.4f}, Non-Eq={metrics_noneq.val_forces_mae:.4f}\")\n",
    "print(f\"  Dipole MAE:  DCMNet={metrics_dcm.val_dipole_mae:.4f}, Non-Eq={metrics_noneq.val_dipole_mae:.4f}\")\n",
    "print(f\"  ESP MAE:     DCMNet={metrics_dcm.val_esp_mae:.4f}, Non-Eq={metrics_noneq.val_esp_mae:.4f}\")\n",
    "\n",
    "print(\"\\nEQUIVARIANCE (Rotation):\")\n",
    "print(f\"  Dipole:      DCMNet={metrics_dcm.rotation_error_dipole:.6f}, Non-Eq={metrics_noneq.rotation_error_dipole:.6f}\")\n",
    "print(f\"  ESP:         DCMNet={metrics_dcm.rotation_error_esp:.6f}, Non-Eq={metrics_noneq.rotation_error_esp:.6f}\")\n",
    "print(\"  ‚ö†Ô∏è  DCMNet should have near-zero rotation error (equivariant)\")\n",
    "print(\"  ‚ö†Ô∏è  Non-Eq will have larger error (not equivariant)\")\n",
    "\n",
    "print(\"\\nINVARIANCE (Translation):\")\n",
    "print(f\"  Dipole:      DCMNet={metrics_dcm.translation_error_dipole:.6f}, Non-Eq={metrics_noneq.translation_error_dipole:.6f}\")\n",
    "print(f\"  ESP:         DCMNet={metrics_dcm.translation_error_esp:.6f}, Non-Eq={metrics_noneq.translation_error_esp:.6f}\")\n",
    "print(\"  ‚úÖ Both should have near-zero translation error\")\n",
    "\n",
    "# print(\"\\nCOMPUTATIONAL EFFICIENCY:\")\n",
    "# if training_time_dcm > 0 and training_time_noneq > 0:\n",
    "#     speedup = training_time_dcm / training_time_noneq\n",
    "#     print(f\"  Training:    DCMNet={training_time_dcm/3600:.2f}h, Non-Eq={training_time_noneq/3600:.2f}h ({speedup:.2f}√ó speedup)\")\n",
    "# print(f\"  Inference:   DCMNet={inference_time_dcm*1000:.2f}ms, Non-Eq={inference_time_noneq*1000:.2f}ms ({inference_time_dcm/inference_time_noneq:.2f}√ó speedup)\")\n",
    "# print(f\"  Parameters:  DCMNet={num_params_dcm:,}, Non-Eq={num_params_noneq:,} ({(1-num_params_noneq/num_params_dcm)*100:.1f}% reduction)\")\n",
    "\n",
    "# Save results\n",
    "# Convert Path objects to strings for JSON serialization\n",
    "args_dict = {}\n",
    "for key, value in vars(args).items():\n",
    "    if isinstance(value, Path):\n",
    "        args_dict[key] = str(value)\n",
    "    else:\n",
    "        args_dict[key] = value\n",
    "\n",
    "results = {\n",
    "    'dcmnet': asdict(metrics_dcm),\n",
    "    'noneq': asdict(metrics_noneq),\n",
    "    'args': args_dict,\n",
    "}\n",
    "\n",
    "with open(output_dir / 'comparison_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Results saved to: {output_dir / 'comparison_results.json'}\")\n",
    "\n",
    "# Generate plots\n",
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Generating Comparison Plots\")\n",
    "print(f\"{'#'*70}\\n\")\n",
    "\n",
    "plot_comparison(metrics_dcm, metrics_noneq, output_dir)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ COMPARISON COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nAll results saved to: {output_dir}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(f\"  - comparison_results.json\")\n",
    "print(f\"  - performance_comparison.png\")\n",
    "print(f\"  - efficiency_comparison.png\")\n",
    "print(f\"  - equivariance_comparison.png\")\n",
    "print(f\"  - dcmnet_equivariant/ (checkpoint)\")\n",
    "print(f\"  - noneq_model/ (checkpoint)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6c38a-ba08-4b00-877a-bc9fca6db44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a9a905-e9e1-4ff2-ad03-e5d9bcdab0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_efd = Path(\"/scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/energies_forces_dipoles_test.npz\")\n",
    "test_esp = Path(\"/scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/grids_esp_test.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bcb0675-3094-4761-85c2-77823f3fceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loading EFD: /scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/energies_forces_dipoles_test.npz\n",
      "  Loading ESP: /scicore/home/meuwly/boitti0000/mmml/examples/co2/preclassified_data/grids_esp_test.npz\n",
      "  ‚úÖ Subtracted atomic energies (now relative to isolated atoms)\n",
      "  Aligning ESP grids to molecular reference frames...\n",
      "  ‚úÖ Aligned ESP grids to molecular reference frames\n",
      "     Sample 0 - Atom COM: [0.         0.1790964  0.06964373]\n",
      "     Sample 0 - Grid COM before: [3.25245414 3.3157224  3.30973476]\n",
      "     Sample 0 - Grid COM after: [-2.26877776e-15  1.79096404e-01  6.96437267e-02]\n",
      "     Sample 0 - Offset corrected: [3.25245414 3.13662599 3.24009103] √Ö\n",
      "  Combined data shapes:\n",
      "    R: (1000, 60, 3)\n",
      "    Z: (1000, 60)\n",
      "    N: (1000,)\n",
      "    E: (1000,)\n",
      "    F: (1000, 60, 3)\n",
      "    Dxyz: (1000, 3)\n",
      "    esp: (1000, 3000)\n",
      "    vdw_surface: (1000, 3000, 3)\n",
      "  Data padding: 60 atoms\n",
      "  Max actual atoms: 3\n"
     ]
    }
   ],
   "source": [
    "test_data = load_combined_data(test_efd, test_esp, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a620e3-17b6-4089-b434-d29d256bced3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# Equivariance Testing\n",
      "######################################################################\n",
      "\n",
      "--- DCMNet (Equivariant) ---\n",
      "\n",
      "======================================================================\n",
      "Testing Equivariance on 10 samples\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'#'*70}\")\n",
    "print(\"# Equivariance Testing\")\n",
    "print(f\"{'#'*70}\")\n",
    "NTEST = 10\n",
    "print(\"\\n--- DCMNet (Equivariant) ---\")\n",
    "equivariance_dcm = test_equivariance(\n",
    "    model_dcm,\n",
    "    params_dcm,\n",
    "    test_data,\n",
    "    num_test_samples=NTEST,\n",
    "    seed=args.seed,\n",
    ")\n",
    "\n",
    "print(\"\\n--- Non-Equivariant ---\")\n",
    "equivariance_noneq = test_equivariance(\n",
    "    model_noneq,\n",
    "    params_noneq,\n",
    "    test_data,\n",
    "    num_test_samples=NTEST,\n",
    "    seed=args.seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe27133-432b-4613-8f9d-12c0095a9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([equivariance_dcm, equivariance_noneq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379db5a-f27a-4886-a7de-122d2246cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([equivariance_dcm, equivariance_noneq], index=[\"EQV\", \"NEQV\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c8246-4a74-492f-b98d-dddf0e144511",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_to_see = ['rotation_error_dipole', 'rotation_error_esp',\n",
    "       'translation_error_dipole', 'translation_error_esp',\n",
    "       'rotation_error_dipole_std', 'rotation_error_esp_std',\n",
    "       'translation_error_dipole_std', 'translation_error_esp_std',\n",
    "       'energy_mae', 'forces_mae', 'dipole_mae', 'energy_mae_std',\n",
    "       'forces_mae_std', 'dipole_mae_std', 'all_output_orig',\n",
    "       'all_output_rot', 'all_output_trans']\n",
    "\n",
    "\n",
    "df  = df[keys_to_see]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6682e4f6-0da7-48b1-9329-8eca23e1b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# ---- Assume your raw dataframe is named `df` ----\n",
    "# (If not, just assign: df = your_dataframe)\n",
    "\n",
    "# Column groups (auto-pick only those that exist)\n",
    "sym_core = [c for c in [\n",
    "    \"rotation_error_dipole\",\"rotation_error_esp\",\n",
    "    \"translation_error_dipole\",\"translation_error_esp\"\n",
    "] if c in df.columns]\n",
    "\n",
    "sym_std = [c for c in [\n",
    "    \"rotation_error_dipole_std\",\"rotation_error_esp_std\",\n",
    "    \"translation_error_dipole_std\",\"translation_error_esp_std\"\n",
    "] if c in df.columns]\n",
    "\n",
    "mae_core = [c for c in [\n",
    "    \"energy_mae\",\"forces_mae\",\"dipole_mae\",\"esp_mae\"\n",
    "] if c in df.columns]\n",
    "\n",
    "mae_std = [c for c in [\n",
    "    \"energy_mae_std\",\"forces_mae_std\",\"dipole_mae_std\",\"esp_mae_std\"\n",
    "] if c in df.columns]\n",
    "\n",
    "# Big nested columns (hide by default, but keep at end in case you want them)\n",
    "big_cols = [c for c in [\"all_output_orig\",\"all_output_rot\",\"all_output_trans\"] if c in df.columns]\n",
    "\n",
    "# Order columns logically\n",
    "ordered_cols = sym_core + sym_std + mae_core + mae_std + big_cols\n",
    "show_cols = [c for c in ordered_cols if c not in big_cols]  # visible in the styled table\n",
    "\n",
    "# Display names (pretty headers)\n",
    "pretty = {\n",
    "    \"rotation_error_dipole\": \"ŒîD(rot)\",\n",
    "    \"rotation_error_dipole_std\": \"œÉ ŒîD(rot)\",\n",
    "\n",
    "    \"rotation_error_esp\":    \"ŒîESP(rot)\",\n",
    "    \"rotation_error_esp_std\":    \"œÉ ŒîESP(rot)\",\n",
    "    \"translation_error_dipole\": \"Œî D(trans)\",\n",
    "    \"translation_error_dipole_std\": \"œÉ ŒîD(trans)\",\n",
    "    \"translation_error_esp\":    \"ŒîESP(trans)\",\n",
    "    \"translation_error_esp_std\":    \"œÉ ŒîESP(trans)\",\n",
    "    # \"energy_mae\":  \"Energy MAE\",\n",
    "    # \"forces_mae\":  \"Forces MAE\",\n",
    "    \"dipole_mae\":  \"D MAE\",\n",
    "    \"esp_mae\":     \"E MAE\",\n",
    "    \"energy_mae_std\":  \"œÉ E(MAE)\",\n",
    "    \"forces_mae_std\":  \"œÉ F(MAE)\",\n",
    "    \"dipole_mae_std\":  \"œÉ D(MAE)\",\n",
    "    # \"esp_mae_std\":     \"œÉ E MAE\",\n",
    "}\n",
    "\n",
    "# Build a MultiIndex for top-level grouping\n",
    "def group_of(col):\n",
    "    if col in sym_core: return \"Symmetry errors\"\n",
    "    if col in sym_std:  return \"œÉ\"\n",
    "    if col in mae_core: return \"Validation MAE\"\n",
    "    if col in mae_std:  return \"œÉ\"\n",
    "    return \"Other\"\n",
    "\n",
    "cols = pd.MultiIndex.from_tuples([(group_of(c), pretty.get(c, c)) for c in show_cols])\n",
    "\n",
    "df_view = df[show_cols].copy()\n",
    "df_view.columns = cols\n",
    "\n",
    "# ====== Color maps (Okabe‚ÄìIto inspired single-hue gradients) ======\n",
    "oi_green  = LinearSegmentedColormap.from_list(\"oi_green\",  [\"#ffffff\", \"#009E73\"])\n",
    "oi_purple = LinearSegmentedColormap.from_list(\"oi_purple\", [\"#ffffff\", \"#CC79A7\"])\n",
    "oi_orange = LinearSegmentedColormap.from_list(\"oi_orange\", [\"#ffffff\", \"#E69F00\"])\n",
    "\n",
    "# Which cmap to use per group (errors low=good ‚Üí invert gradient by swapping vmin/vmax later)\n",
    "cmap_for_group = {\n",
    "    \"Symmetry errors\": oi_green,\n",
    "    \"Validation MAE\":  oi_green,\n",
    "    \"œÉ\": oi_purple,\n",
    "    \"œÉ\":  oi_orange,\n",
    "}\n",
    "\n",
    "# Formatter: compact numbers, scientific for very small\n",
    "def fmt_val(x):\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    ax = float(x)\n",
    "    if ax != 0 and (abs(ax) < 1e-1 or abs(ax) >= 1e1):\n",
    "        return f\"{ax:.2e}\"\n",
    "    # show up to 6 significant-ish digits\n",
    "    return f\"{ax:.6g}\"\n",
    "\n",
    "# Helper to apply background gradient per column with ‚Äúlower is better‚Äù\n",
    "def style_groupwise(s: pd.Series):\n",
    "    # s.name is a tuple (group, pretty_col)\n",
    "    group = s.name[0]\n",
    "    cmap  = cmap_for_group.get(group, oi_green)\n",
    "    # lower=better ‚Üí use full range but invert by swapping vmin/vmax\n",
    "    vmin, vmax = s.min(skipna=True), s.max(skipna=True)\n",
    "    if pd.isna(vmin) or pd.isna(vmax) or vmin == vmax:\n",
    "        # uniform column, no gradient\n",
    "        return [\"background-color:\"] * len(s)\n",
    "    # Build colors by normalizing to reversed scale\n",
    "    vals = (s - vmin) / (vmax - vmin)\n",
    "    vals = 1 - vals  # invert so lower‚Üíhigher color intensity\n",
    "    rgba = (cmap(vals) * 255).astype(int)\n",
    "    return [f\"background-color: rgba({r},{g},{b}, {a/255:.3f})\"\n",
    "            for r, g, b, a in rgba]\n",
    "\n",
    "# Build the Styler\n",
    "styler = (\n",
    "    df_view.style\n",
    "      .format(fmt_val)\n",
    "      .apply(style_groupwise, axis=0)\n",
    "      .set_table_styles([\n",
    "          # Cleaner header look\n",
    "          {\"selector\": \"th.col_heading.level0\",\n",
    "           \"props\": [(\"font-weight\", \"600\"), (\"border-bottom\", \"1px solid #ddd\")]},\n",
    "          {\"selector\": \"th.col_heading.level1\",\n",
    "           \"props\": [(\"font-weight\", \"400\"), (\"border-bottom\", \"1px solid #eee\")]},\n",
    "          {\"selector\": \"th.row_heading\",\n",
    "           \"props\": [(\"font-weight\", \"600\")]},\n",
    "          {\"selector\": \"table\",\n",
    "           \"props\": [(\"border-collapse\", \"separate\"), (\"border-spacing\", \"0 6px\")]}\n",
    "      ])\n",
    "      .set_properties(**{\n",
    "          \"text-align\": \"right\",\n",
    "          \"padding\": \"6px 8px\",\n",
    "          \"border\": \"1px solid #f3f3f3\"\n",
    "      })\n",
    "      .set_caption(\"Model Symmetry Checks & Validation Errors (lower is better)\")\n",
    ")\n",
    "\n",
    "# If you want to sort rows by a metric (e.g., ESP MAE ascending):\n",
    "# df_sorted = df.sort_values((\"Validation MAE\", \"ESP MAE\"))\n",
    "# styler = df_sorted.style ... (rebuild with same steps)  # or reassign df_view = df_sorted[show_cols]; then re-apply\n",
    "\n",
    "# Display in notebook\n",
    "styler\n",
    "\n",
    "# # Optionally, export to HTML:\n",
    "# html = styler.to_html()\n",
    "# with open(\"metrics_table.html\", \"w\") as f:\n",
    "#     f.write(html)\n",
    "# print(\"Saved: metrics_table.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab3f2bc-8a58-4816-b0d2-c8653d9f6814",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_long = styler.to_latex(\n",
    "    convert_css=True,\n",
    "    hrules=True,\n",
    "    caption=\"Model Symmetry Checks & Validation Errors (lower is better)\",\n",
    "    label=\"tab:metrics\",\n",
    "    environment=\"longtable\"  # produce a longtable (no float)\n",
    ")\n",
    "\n",
    "with open(\"metrics_table_long.tex\", \"w\") as f:\n",
    "    f.write(latex_long)\n",
    "\n",
    "print(\"Saved LaTeX to metrics_table_long.tex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557615f-df72-4bb9-86ad-9c2f8b15092b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fb6c0-987c-4866-9683-50894ee84b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(equivariance_noneq[\"all_output_trans\"][0][\"esp\"]).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c765a-ae1a-49a6-948e-ebaffd856452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import *\n",
    "%matplotlib inline\n",
    "plt.scatter(equivariance_noneq[\"all_output_orig\"][0][\"esp\"], equivariance_noneq[\"all_output_trans\"][0][\"esp\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcec2f5-164c-4a27-8122-810b52983d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ed448-851b-4f6f-a93c-bb2fb9597d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n--- DCMNet (Equivariant) ---\")\n",
    "# equivariance_dcm = test_equivariance(\n",
    "#     model_dcm,\n",
    "#     params_dcm,\n",
    "#     valid_data,\n",
    "#     num_test_samples=args.equivariance_samples,\n",
    "#     seed=args.seed,\n",
    "# )\n",
    "\n",
    "# print(\"\\n--- Non-Equivariant ---\")\n",
    "# equivariance_noneq = test_equivariance(\n",
    "#     model_noneq,\n",
    "#     params_noneq,\n",
    "#     valid_data,\n",
    "#     num_test_samples=args.equivariance_samples,\n",
    "#     seed=args.seed,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b718c094-0df8-4ead-8789-5136aa258381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_models import predict_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3de44-ce37-4608-a02c-d63563ad8598",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316bdde9-741c-41b5-83c1-63634884c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_dcm\n",
    "params = params_dcm\n",
    "seed = 42\n",
    "rng = np.random.RandomState(seed)\n",
    "jax_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "\n",
    "R = test_data['R'][idx:idx+1]  # (1, natoms, 3)\n",
    "Z = test_data['Z'][idx:idx+1]  # (1, natoms)\n",
    "N = test_data['N'][idx:idx+1]  # (1,)\n",
    "vdw_surface = test_data['vdw_surface'][idx:idx+1]  # (1, ngrid, 3)\n",
    "TESTESP =  test_data['esp'][idx:idx+1]  # (1, ngrid, 3)\n",
    "n_atoms = int(N[0])\n",
    "\n",
    "graph = build_neighbor_graph(R, N)\n",
    "\n",
    "# Original prediction\n",
    "output_orig = predict_single(model, params, R, Z, N, vdw_surface, graph=graph)\n",
    "\n",
    "# Test rotation\n",
    "jax_key, rot_key, trans_key = jax.random.split(jax_key, 3)\n",
    "rot_matrix = generate_random_rotation(rot_key)\n",
    "R_rot = apply_rotation(R, rot_matrix)\n",
    "vdw_rot = apply_rotation(vdw_surface, rot_matrix)\n",
    "\n",
    "output_rot = predict_single(model, params, R_rot, Z, N, vdw_rot, graph=graph)\n",
    "\n",
    "# For equivariant model: rotated output should equal rotation of original output\n",
    "# Dipole should rotate\n",
    "dipole_orig = jnp.asarray(output_orig['dipole'])\n",
    "dipole_rot = jnp.asarray(output_rot['dipole'])\n",
    "dipole_expected = jnp.einsum('ij,j->i', rot_matrix, dipole_orig)\n",
    "rotation_error_dipole = jnp.linalg.norm(dipole_rot - dipole_expected)\n",
    "\n",
    "\n",
    "# ESP should be identical at rotated grid points\n",
    "esp_orig = jnp.asarray(output_orig['esp'])\n",
    "esp_rot = jnp.asarray(output_rot['esp'])\n",
    "rotation_error_esp = jnp.mean(jnp.abs(esp_rot - esp_orig))\n",
    "\n",
    "\n",
    "# Test translation (both models should be translation invariant)\n",
    "translation = 5.0 * jax.random.normal(trans_key, (3,), dtype=rot_matrix.dtype)\n",
    "R_trans = apply_translation(R, translation)\n",
    "vdw_trans = apply_translation(vdw_surface, translation)\n",
    "\n",
    "output_trans = predict_single(model, params, R_trans, Z, N, vdw_trans, graph=graph)\n",
    "\n",
    "# Dipole should be identical (molecule-centered)\n",
    "dipole_trans = jnp.asarray(output_trans['dipole'])\n",
    "translation_error_dipole = jnp.linalg.norm(dipole_trans - dipole_orig)\n",
    "\n",
    "\n",
    "# ESP should be identical\n",
    "esp_trans = jnp.asarray(output_trans['esp'])\n",
    "translation_error_esp = jnp.mean(jnp.abs(esp_trans - esp_orig))\n",
    "\n",
    "\n",
    "# Compare against reference quantities\n",
    "true_energy = jnp.asarray(test_data['E'][idx])\n",
    "energy_error = jnp.abs(jnp.asarray(output_orig['energy']) - true_energy)\n",
    "\n",
    "\n",
    "true_dipole = jnp.asarray(test_data['Dxyz'][idx])\n",
    "dipole_mae = jnp.mean(jnp.abs(dipole_orig - true_dipole))\n",
    "\n",
    "\n",
    "true_forces = jnp.asarray(test_data['F'][idx])\n",
    "if true_forces.ndim == 1:\n",
    "    true_forces = true_forces.reshape(-1, 3)\n",
    "forces_pred = jnp.asarray(output_orig['forces'])\n",
    "forces_mae = jnp.mean(\n",
    "    jnp.abs(forces_pred[:n_atoms] - true_forces[:n_atoms])\n",
    ")\n",
    "plt.scatter(output_orig['esp'], TESTESP, alpha=0.01)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "plt.scatter(output_trans['esp'], TESTESP, alpha=0.01)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.plot([0,1],[0,1], transform=ax.transAxes, color=\"k\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.scatter(output_orig['esp'], output_rot['esp'], alpha=0.1)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "ax.plot([0,1],[0,1], transform=ax.transAxes, color=\"k\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd780b04-a143-4c59-98f5-2e16888d5c45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# =========================\n",
    "# CONFIG (no magic numbers)\n",
    "# =========================\n",
    "CFG = {\n",
    "    \"bounds_percentile\": 75,            # symmetric axis limits from |values|\n",
    "    \"min_bins\": 20,                       # FD lower clamp\n",
    "    \"max_bins\": 200,                      # FD upper clamp\n",
    "    \"contour_percentiles\": [70, 85, 93, 98],  # exactly 4 contour levels\n",
    "    \"line_width\": 1.2,                    # contour line width\n",
    "    \"diag_width\": 0.8,                    # diagonal line width\n",
    "    \"hist_alpha\": 0.8,                    # marginal histogram alpha\n",
    "    \"hist_size_fraction\": 0.25,           # tomography axes size as fraction of main axes\n",
    "    \"hist_pad_fraction\": 0.02,            # padding as fraction of main axes\n",
    "    \"line_colors\": {                      # Okabe‚ÄìIto-ish colors for lines\n",
    "        \"orig_vs_true\":  \"#0072B2\",       # blue\n",
    "        \"trans_vs_true\": \"#E69F00\",       # orange\n",
    "        \"rot_vs_orig\":   \"#009E73\",       # green\n",
    "    },\n",
    "    \"figsize\": (12, 4.2),\n",
    "    \"title_size\": 11,\n",
    "    \"label_size\": 10,\n",
    "    \"tick_size\": 9,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def _finite(a):\n",
    "    a = np.asarray(a).ravel()\n",
    "    return a[np.isfinite(a)]\n",
    "\n",
    "def _symmetric_limits(*arrays, p=99.5):\n",
    "    vals = np.concatenate([_finite(a) for a in arrays]) if arrays else np.array([0.0])\n",
    "    if vals.size == 0:\n",
    "        return (-1.0, 1.0)\n",
    "    L = np.nanpercentile(np.abs(vals), p)\n",
    "    if not np.isfinite(L) or L == 0:\n",
    "        L = np.max(np.abs(vals)) or 1.0\n",
    "    return (-float(L), float(L))\n",
    "\n",
    "def _fd_bins(x, min_bins, max_bins):\n",
    "    x = _finite(x); n = x.size\n",
    "    if n < 2:\n",
    "        return min_bins\n",
    "    q75, q25 = np.percentile(x, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    if iqr <= 0:\n",
    "        bins = int(np.sqrt(max(n, 1)))\n",
    "    else:\n",
    "        h = 2 * iqr * n ** (-1/3)\n",
    "        data_range = x.max() - x.min()\n",
    "        bins = int(np.ceil(data_range / h)) if h > 0 else int(np.sqrt(max(n, 1)))\n",
    "    return int(np.clip(bins, min_bins, max_bins))\n",
    "\n",
    "def _hist2d_density(x, y, bins_x, bins_y, xlim, ylim):\n",
    "    H, xedges, yedges = np.histogram2d(\n",
    "        x, y, bins=[bins_x, bins_y], range=[xlim, ylim], density=True\n",
    "    )\n",
    "    return H.T, xedges, yedges\n",
    "\n",
    "def _contour_levels_from_percentiles(density, percentiles):\n",
    "    flat = density.ravel()\n",
    "    flat = flat[(flat > 0) & np.isfinite(flat)]\n",
    "    if flat.size == 0:\n",
    "        # degenerate fallback\n",
    "        return np.array([1e-12, 1e-10, 1e-8, 1e-6])\n",
    "    levels = np.percentile(flat, percentiles)\n",
    "    levels = np.unique(levels)\n",
    "    if levels.size < 4:\n",
    "        mn, mx = float(flat.min()), float(flat.max())\n",
    "        if mx == mn:\n",
    "            levels = mn * (1.0 + 1e-6 * np.arange(1, 5))\n",
    "        else:\n",
    "            levels = np.linspace(mn + 1e-12, mx, 4)\n",
    "    return levels[:4]\n",
    "\n",
    "def _rmse_in_limits(x, y, limits):\n",
    "    x = _finite(x); y = _finite(y)\n",
    "    m = (x >= limits[0]) & (x <= limits[1]) & (y >= limits[0]) & (y <= limits[1])\n",
    "    if not np.any(m):\n",
    "        return np.nan\n",
    "    d = x[m] - y[m]\n",
    "    return float(np.sqrt(np.mean(d * d)))\n",
    "\n",
    "def plot_panel(ax_main, x, y, *, line_color, limits, cfg, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Unfilled 2D density contours (4 levels) + diagonal + marginal tomograms + RMSE annotation.\n",
    "    \"\"\"\n",
    "    x = _finite(x); y = _finite(y)\n",
    "    xlim = ylim = limits\n",
    "\n",
    "    # Bins via FD\n",
    "    bx = _fd_bins(x, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    by = _fd_bins(y, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "\n",
    "    # Density grid\n",
    "    H, xedges, yedges = _hist2d_density(x, y, bx, by, xlim, ylim)\n",
    "\n",
    "    # Centers for contours\n",
    "    Xc = 0.5 * (xedges[:-1] + xedges[1:])\n",
    "    Yc = 0.5 * (yedges[:-1] + yedges[1:])\n",
    "    X, Y = np.meshgrid(Xc, Yc)\n",
    "\n",
    "    # Exactly 4 contour levels\n",
    "    levels = _contour_levels_from_percentiles(H, cfg[\"contour_percentiles\"])\n",
    "\n",
    "    # Unfilled contour lines\n",
    "    ax_main.contour(X, Y, H, levels=levels, colors=line_color, linewidths=cfg[\"line_width\"])\n",
    "\n",
    "    # Identity diagonal\n",
    "    ax_main.plot([limits[0], limits[1]], [limits[0], limits[1]],\n",
    "                 '--', color='k', linewidth=cfg[\"diag_width\"])\n",
    "\n",
    "    ax_main.set_xlim(limits); ax_main.set_ylim(limits); ax_main.set_aspect(\"equal\")\n",
    "    ax_main.set_title(title, fontsize=cfg[\"title_size\"])\n",
    "    ax_main.set_xlabel(xlabel, fontsize=cfg[\"label_size\"])\n",
    "    ax_main.set_ylabel(ylabel, fontsize=cfg[\"label_size\"])\n",
    "    ax_main.tick_params(labelsize=cfg[\"tick_size\"])\n",
    "\n",
    "    # RMSE (in-range)\n",
    "    rmse = _rmse_in_limits(x, y, limits)\n",
    "    ax_main.text(0.02, 0.98, f\"RMSE (in-range): {rmse*627.5:.4g}\",\n",
    "                 transform=ax_main.transAxes, ha='left', va='top',\n",
    "                 fontsize=cfg[\"label_size\"])\n",
    "\n",
    "    # ---- Tomography (marginal histograms) with FRACTION sizes ----\n",
    "    divider = make_axes_locatable(ax_main)\n",
    "    size_str = f\"{cfg['hist_size_fraction']*100:.1f}%\"   # e.g., \"25.0%\"\n",
    "    pad_str  = f\"{cfg['hist_pad_fraction']*100:.2f}%\"\n",
    "\n",
    "    ax_top   = divider.append_axes(\"top\",  size=size_str, pad=pad_str, sharex=ax_main)\n",
    "    ax_right = divider.append_axes(\"right\", size=size_str, pad=pad_str, sharey=ax_main)\n",
    "\n",
    "    # X projection\n",
    "    bins_x = _fd_bins(x, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    ax_top.hist(x[(x>=limits[0]) & (x<=limits[1])], bins=bins_x, range=limits,\n",
    "                color=line_color, alpha=cfg[\"hist_alpha\"], density=True)\n",
    "    ax_top.tick_params(labelbottom=False, labelsize=cfg[\"tick_size\"])\n",
    "    ax_top.set_xlim(limits)\n",
    "\n",
    "    # Y projection\n",
    "    bins_y = _fd_bins(y, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    ax_right.hist(y[(y>=limits[0]) & (y<=limits[1])], bins=bins_y, range=limits,\n",
    "                  color=line_color, alpha=cfg[\"hist_alpha\"], density=True, orientation='horizontal')\n",
    "    ax_right.tick_params(labelleft=False, labelsize=cfg[\"tick_size\"])\n",
    "    ax_right.set_ylim(limits)\n",
    "\n",
    "# =========================\n",
    "# DATA EXTRACT (ESP arrays)\n",
    "# =========================\n",
    "esp_pred_orig  = np.asarray(output_orig['esp']).ravel()\n",
    "esp_pred_rot   = np.asarray(output_rot['esp']).ravel()\n",
    "esp_pred_trans = np.asarray(output_trans['esp']).ravel()\n",
    "esp_true       = np.asarray(TESTESP).ravel()\n",
    "\n",
    "# Shared robust symmetric limits across all panels\n",
    "limits = _symmetric_limits(esp_pred_orig, esp_pred_rot, esp_pred_trans, esp_true,\n",
    "                           p=CFG[\"bounds_percentile\"])\n",
    "\n",
    "# =========================\n",
    "# PLOT (3 panels)\n",
    "# =========================\n",
    "fig, axes = plt.subplots(1, 4, figsize=CFG[\"figsize\"], constrained_layout=True, sharex=True, sharey=True)\n",
    "\n",
    "plot_panel(\n",
    "    axes[0],\n",
    "    esp_pred_orig, esp_true,\n",
    "    line_color=CFG[\"line_colors\"][\"orig_vs_true\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Original vs True ESP\",\n",
    "    xlabel=\"Predicted ESP\", ylabel=\"True ESP\"\n",
    ")\n",
    "\n",
    "plot_panel(\n",
    "    axes[1],\n",
    "    esp_pred_trans, esp_true,\n",
    "    line_color=CFG[\"line_colors\"][\"trans_vs_true\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Translated vs True ESP\",\n",
    "    xlabel=\"Translated ESP\", ylabel=\"True ESP\"\n",
    ")\n",
    "\n",
    "plot_panel(\n",
    "    axes[2],\n",
    "    esp_pred_rot, esp_true,\n",
    "    line_color=CFG[\"line_colors\"][\"rot_vs_orig\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Rotated vs True ESP\",\n",
    "    xlabel=\"Rotated ESP\", ylabel=\"True ESP\"\n",
    ")\n",
    "\n",
    "\n",
    "plot_panel(\n",
    "    axes[3],\n",
    "    esp_pred_rot, esp_pred_orig,\n",
    "    line_color=CFG[\"line_colors\"][\"rot_vs_orig\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Rotated vs Original ESP\",\n",
    "    xlabel=\"Rotated ESP\", ylabel=\"Original ESP\"\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3fc74-33fc-413c-a7ef-78330ed5b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(TESTESP).T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca56cb-0b93-4c73-b137-892fe6427440",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((output_trans['esp'] - TESTESP)**2)) * 627.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952dd2fb-1304-4a07-8d0d-60dc42692e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((output_trans['esp'] - output_orig['esp'])**2)) * 627.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b650d-e333-47a0-bf68-70e8965c8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_models import predict_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c61301-54cc-4b5f-890f-5b1338a6289f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd8059-d1f2-4124-bf74-a3b12bf52ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "model = model_noneq\n",
    "params = params_noneq\n",
    "seed = 42\n",
    "rng = np.random.RandomState(seed)\n",
    "jax_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "R = test_data['R'][idx:idx+1]  # (1, natoms, 3)\n",
    "Z = test_data['Z'][idx:idx+1]  # (1, natoms)\n",
    "N = test_data['N'][idx:idx+1]  # (1,)\n",
    "vdw_surface = test_data['vdw_surface'][idx:idx+1]  # (1, ngrid, 3)\n",
    "TESTESP =  test_data['esp'][idx:idx+1]  # (1, ngrid, 3)\n",
    "n_atoms = int(N[0])\n",
    "\n",
    "graph = build_neighbor_graph(R, N)\n",
    "\n",
    "# Original prediction\n",
    "output_orig = predict_single(model, params, R, Z, N, vdw_surface, graph=graph)\n",
    "\n",
    "# Test rotation\n",
    "jax_key, rot_key, trans_key = jax.random.split(jax_key, 3)\n",
    "rot_matrix = generate_random_rotation(rot_key)\n",
    "R_rot = apply_rotation(R, rot_matrix)\n",
    "vdw_rot = apply_rotation(vdw_surface, rot_matrix)\n",
    "\n",
    "output_rot = predict_single(model, params, R_rot, Z, N, vdw_rot, graph=graph)\n",
    "\n",
    "# For equivariant model: rotated output should equal rotation of original output\n",
    "# Dipole should rotate\n",
    "dipole_orig = jnp.asarray(output_orig['dipole'])\n",
    "dipole_rot = jnp.asarray(output_rot['dipole'])\n",
    "dipole_expected = jnp.einsum('ij,j->i', rot_matrix, dipole_orig)\n",
    "rotation_error_dipole = jnp.linalg.norm(dipole_rot - dipole_expected)\n",
    "\n",
    "\n",
    "# ESP should be identical at rotated grid points\n",
    "esp_orig = jnp.asarray(output_orig['esp'])\n",
    "esp_rot = jnp.asarray(output_rot['esp'])\n",
    "rotation_error_esp = jnp.mean(jnp.abs(esp_rot - esp_orig))\n",
    "\n",
    "\n",
    "# Test translation (both models should be translation invariant)\n",
    "translation = 5.0 * jax.random.normal(trans_key, (3,), dtype=rot_matrix.dtype)\n",
    "R_trans = apply_translation(R, translation)\n",
    "vdw_trans = apply_translation(vdw_surface, translation)\n",
    "\n",
    "output_trans = predict_single(model, params, R_trans, Z, N, vdw_trans, graph=graph)\n",
    "\n",
    "# Dipole should be identical (molecule-centered)\n",
    "dipole_trans = jnp.asarray(output_trans['dipole'])\n",
    "translation_error_dipole = jnp.linalg.norm(dipole_trans - dipole_orig)\n",
    "\n",
    "\n",
    "# ESP should be identical\n",
    "esp_trans = jnp.asarray(output_trans['esp'])\n",
    "translation_error_esp = jnp.mean(jnp.abs(esp_trans - esp_orig))\n",
    "\n",
    "\n",
    "# Compare against reference quantities\n",
    "true_energy = jnp.asarray(test_data['E'][idx])\n",
    "energy_error = jnp.abs(jnp.asarray(output_orig['energy']) - true_energy)\n",
    "\n",
    "\n",
    "true_dipole = jnp.asarray(test_data['Dxyz'][idx])\n",
    "dipole_mae = jnp.mean(jnp.abs(dipole_orig - true_dipole))\n",
    "\n",
    "\n",
    "true_forces = jnp.asarray(test_data['F'][idx])\n",
    "if true_forces.ndim == 1:\n",
    "    true_forces = true_forces.reshape(-1, 3)\n",
    "forces_pred = jnp.asarray(output_orig['forces'])\n",
    "forces_mae = jnp.mean(\n",
    "    jnp.abs(forces_pred[:n_atoms] - true_forces[:n_atoms])\n",
    ")\n",
    "plt.scatter(output_orig['esp'], TESTESP, alpha=0.01)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "plt.scatter(output_trans['esp'], TESTESP, alpha=0.01)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.plot([0,1],[0,1], transform=ax.transAxes, color=\"k\", linestyle=\"--\")\n",
    "\n",
    "plt.scatter(output_orig['esp'], output_rot['esp'], alpha=0.1)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "ax.plot([0,1],[0,1], transform=ax.transAxes, color=\"k\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed22259-f191-4738-a0d3-29a3192cc8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cf4bdf-9bd0-451a-aaa1-e85025a8309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((output_rot['esp'] - TESTESP)**2)) * 627.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6ce42-bf5f-4c5e-b5b4-3f5629cdd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((output_trans['esp'] - output_orig['esp'])**2)) * 627.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc86822-73d6-4d98-9058-d2558f4275d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92101530-e7c3-4098-9122-4c8d1ef7b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# =========================\n",
    "# CONFIG (no magic numbers)\n",
    "# =========================\n",
    "CFG = {\n",
    "    \"bounds_percentile\": 75,            # symmetric axis limits from |values|\n",
    "    \"min_bins\": 20,                       # FD lower clamp\n",
    "    \"max_bins\": 200,                      # FD upper clamp\n",
    "    \"contour_percentiles\": [70, 85, 93, 98],  # exactly 4 contour levels\n",
    "    \"line_width\": 1.2,                    # contour line width\n",
    "    \"diag_width\": 0.8,                    # diagonal line width\n",
    "    \"hist_alpha\": 0.8,                    # marginal histogram alpha\n",
    "    \"hist_size_fraction\": 0.25,           # tomography axes size as fraction of main axes\n",
    "    \"hist_pad_fraction\": 0.02,            # padding as fraction of main axes\n",
    "    \"line_colors\": {                      # Okabe‚ÄìIto-ish colors for lines\n",
    "        \"orig_vs_true\":  \"#0072B2\",       # blue\n",
    "        \"trans_vs_true\": \"#E69F00\",       # orange\n",
    "        \"rot_vs_orig\":   \"#009E73\",       # green\n",
    "    },\n",
    "    \"figsize\": (12, 4.2),\n",
    "    \"title_size\": 11,\n",
    "    \"label_size\": 10,\n",
    "    \"tick_size\": 9,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def _finite(a):\n",
    "    a = np.asarray(a).ravel()\n",
    "    return a[np.isfinite(a)]\n",
    "\n",
    "def _symmetric_limits(*arrays, p=99.5):\n",
    "    vals = np.concatenate([_finite(a) for a in arrays]) if arrays else np.array([0.0])\n",
    "    if vals.size == 0:\n",
    "        return (-1.0, 1.0)\n",
    "    L = np.nanpercentile(np.abs(vals), p)\n",
    "    if not np.isfinite(L) or L == 0:\n",
    "        L = np.max(np.abs(vals)) or 1.0\n",
    "    return (-float(L), float(L))\n",
    "\n",
    "def _fd_bins(x, min_bins, max_bins):\n",
    "    x = _finite(x); n = x.size\n",
    "    if n < 2:\n",
    "        return min_bins\n",
    "    q75, q25 = np.percentile(x, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    if iqr <= 0:\n",
    "        bins = int(np.sqrt(max(n, 1)))\n",
    "    else:\n",
    "        h = 2 * iqr * n ** (-1/3)\n",
    "        data_range = x.max() - x.min()\n",
    "        bins = int(np.ceil(data_range / h)) if h > 0 else int(np.sqrt(max(n, 1)))\n",
    "    return int(np.clip(bins, min_bins, max_bins))\n",
    "\n",
    "def _hist2d_density(x, y, bins_x, bins_y, xlim, ylim):\n",
    "    H, xedges, yedges = np.histogram2d(\n",
    "        x, y, bins=[bins_x, bins_y], range=[xlim, ylim], density=True\n",
    "    )\n",
    "    return H.T, xedges, yedges\n",
    "\n",
    "def _contour_levels_from_percentiles(density, percentiles):\n",
    "    flat = density.ravel()\n",
    "    flat = flat[(flat > 0) & np.isfinite(flat)]\n",
    "    if flat.size == 0:\n",
    "        # degenerate fallback\n",
    "        return np.array([1e-12, 1e-10, 1e-8, 1e-6])\n",
    "    levels = np.percentile(flat, percentiles)\n",
    "    levels = np.unique(levels)\n",
    "    if levels.size < 4:\n",
    "        mn, mx = float(flat.min()), float(flat.max())\n",
    "        if mx == mn:\n",
    "            levels = mn * (1.0 + 1e-6 * np.arange(1, 5))\n",
    "        else:\n",
    "            levels = np.linspace(mn + 1e-12, mx, 4)\n",
    "    return levels[:4]\n",
    "\n",
    "def _rmse_in_limits(x, y, limits):\n",
    "    x = _finite(x); y = _finite(y)\n",
    "    m = (x >= limits[0]) & (x <= limits[1]) & (y >= limits[0]) & (y <= limits[1])\n",
    "    if not np.any(m):\n",
    "        return np.nan\n",
    "    d = x[m] - y[m]\n",
    "    return float(np.sqrt(np.mean(d * d)))\n",
    "\n",
    "def plot_panel(ax_main, x, y, *, line_color, limits, cfg, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Unfilled 2D density contours (4 levels) + diagonal + marginal tomograms + RMSE annotation.\n",
    "    \"\"\"\n",
    "    x = _finite(x); y = _finite(y)\n",
    "    xlim = ylim = limits\n",
    "\n",
    "    # Bins via FD\n",
    "    bx = _fd_bins(x, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    by = _fd_bins(y, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "\n",
    "    # Density grid\n",
    "    H, xedges, yedges = _hist2d_density(x, y, bx, by, xlim, ylim)\n",
    "\n",
    "    # Centers for contours\n",
    "    Xc = 0.5 * (xedges[:-1] + xedges[1:])\n",
    "    Yc = 0.5 * (yedges[:-1] + yedges[1:])\n",
    "    X, Y = np.meshgrid(Xc, Yc)\n",
    "\n",
    "    # Exactly 4 contour levels\n",
    "    levels = _contour_levels_from_percentiles(H, cfg[\"contour_percentiles\"])\n",
    "\n",
    "    # Unfilled contour lines\n",
    "    ax_main.contour(X, Y, H, levels=levels, colors=line_color, linewidths=cfg[\"line_width\"])\n",
    "\n",
    "    # Identity diagonal\n",
    "    ax_main.plot([limits[0], limits[1]], [limits[0], limits[1]],\n",
    "                 '--', color='k', linewidth=cfg[\"diag_width\"])\n",
    "\n",
    "    ax_main.set_xlim(limits); ax_main.set_ylim(limits); ax_main.set_aspect(\"equal\")\n",
    "    ax_main.set_title(title, fontsize=cfg[\"title_size\"])\n",
    "    ax_main.set_xlabel(xlabel, fontsize=cfg[\"label_size\"])\n",
    "    ax_main.set_ylabel(ylabel, fontsize=cfg[\"label_size\"])\n",
    "    ax_main.tick_params(labelsize=cfg[\"tick_size\"])\n",
    "\n",
    "    # RMSE (in-range)\n",
    "    rmse = _rmse_in_limits(x, y, limits)\n",
    "    ax_main.text(0.02, 0.98, f\"RMSE (in-range): {rmse*627.5:.4g}\",\n",
    "                 transform=ax_main.transAxes, ha='left', va='top',\n",
    "                 fontsize=cfg[\"label_size\"])\n",
    "\n",
    "    # ---- Tomography (marginal histograms) with FRACTION sizes ----\n",
    "    divider = make_axes_locatable(ax_main)\n",
    "    size_str = f\"{cfg['hist_size_fraction']*100:.1f}%\"   # e.g., \"25.0%\"\n",
    "    pad_str  = f\"{cfg['hist_pad_fraction']*100:.2f}%\"\n",
    "\n",
    "    ax_top   = divider.append_axes(\"top\",  size=size_str, pad=pad_str, sharex=ax_main)\n",
    "    ax_right = divider.append_axes(\"right\", size=size_str, pad=pad_str, sharey=ax_main)\n",
    "\n",
    "    # X projection\n",
    "    bins_x = _fd_bins(x, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    ax_top.hist(x[(x>=limits[0]) & (x<=limits[1])], bins=bins_x, range=limits,\n",
    "                color=line_color, alpha=cfg[\"hist_alpha\"], density=True)\n",
    "    ax_top.tick_params(labelbottom=False, labelsize=cfg[\"tick_size\"])\n",
    "    ax_top.set_xlim(limits)\n",
    "\n",
    "    # Y projection\n",
    "    bins_y = _fd_bins(y, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    ax_right.hist(y[(y>=limits[0]) & (y<=limits[1])], bins=bins_y, range=limits,\n",
    "                  color=line_color, alpha=cfg[\"hist_alpha\"], density=True, orientation='horizontal')\n",
    "    ax_right.tick_params(labelleft=False, labelsize=cfg[\"tick_size\"])\n",
    "    ax_right.set_ylim(limits)\n",
    "\n",
    "# =========================\n",
    "# DATA EXTRACT (ESP arrays)\n",
    "# =========================\n",
    "esp_pred_orig  = np.asarray(output_orig['esp']).ravel()\n",
    "esp_pred_rot   = np.asarray(output_rot['esp']).ravel()\n",
    "esp_pred_trans = np.asarray(output_trans['esp']).ravel()\n",
    "esp_true       = np.asarray(TESTESP).ravel()\n",
    "\n",
    "# Shared robust symmetric limits across all panels\n",
    "limits = _symmetric_limits(esp_pred_orig, esp_pred_rot, esp_pred_trans, esp_true,\n",
    "                           p=CFG[\"bounds_percentile\"])\n",
    "\n",
    "# =========================\n",
    "# PLOT (3 panels)\n",
    "# =========================\n",
    "fig, axes = plt.subplots(1, 4, figsize=CFG[\"figsize\"], constrained_layout=True, sharex=True, sharey=True)\n",
    "\n",
    "plot_panel(\n",
    "    axes[0],\n",
    "    esp_pred_orig, esp_true,\n",
    "    line_color=CFG[\"line_colors\"][\"orig_vs_true\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Original vs True ESP\",\n",
    "    xlabel=\"Predicted ESP\", ylabel=\"True ESP\"\n",
    ")\n",
    "\n",
    "plot_panel(\n",
    "    axes[1],\n",
    "    esp_pred_trans, esp_true,\n",
    "    line_color=CFG[\"line_colors\"][\"trans_vs_true\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Translated vs True ESP\",\n",
    "    xlabel=\"Translated ESP\", ylabel=\"True ESP\"\n",
    ")\n",
    "\n",
    "plot_panel(\n",
    "    axes[2],\n",
    "    esp_pred_rot, esp_true,\n",
    "    line_color=CFG[\"line_colors\"][\"rot_vs_orig\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Rotated vs True ESP\",\n",
    "    xlabel=\"Rotated ESP\", ylabel=\"True ESP\"\n",
    ")\n",
    "\n",
    "\n",
    "plot_panel(\n",
    "    axes[3],\n",
    "    esp_pred_rot, esp_pred_orig,\n",
    "    line_color=CFG[\"line_colors\"][\"rot_vs_orig\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Rotated vs Original ESP\",\n",
    "    xlabel=\"Rotated ESP\", ylabel=\"Original ESP\"\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf88b7-d646-4948-9f4f-7a1867cbdead",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.002085 * 0627.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784dbfba-469f-4afa-9afa-1b2db0ebf595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2c7526-6b38-48b5-bb61-ea565783cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "equivariance_dcm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f436f12-08b1-4df9-81eb-c81d59bf6379",
   "metadata": {},
   "outputs": [],
   "source": [
    "equivariance_dcm[\"all_output_orig\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a8061-4da7-4c32-9a55-c03ead367f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f973b6b6-8d0e-42b8-8d53-933b60d6eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(equivariance_noneq[\"all_output_orig\"][0][\"esp\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d947c9a-9484-4bb6-bc95-9e5be04bbb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad83245-30c5-4d95-8af4-5fa51cddd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n--- DCMNet (Equivariant) ---\")\n",
    "# equivariance_dcm = test_equivariance(\n",
    "#     model_dcm,\n",
    "#     params_dcm,\n",
    "#     valid_data,\n",
    "#     num_test_samples=args.equivariance_samples,\n",
    "#     seed=args.seed,\n",
    "# )\n",
    "\n",
    "# print(\"\\n--- Non-Equivariant ---\")\n",
    "# equivariance_noneq = test_equivariance(\n",
    "#     model_noneq,\n",
    "#     params_noneq,\n",
    "#     valid_data,\n",
    "#     num_test_samples=args.equivariance_samples,\n",
    "#     seed=args.seed,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afa7afc-1504-4533-a14b-24a617ed4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_models import predict_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae02b84-da11-4f61-b350-a5d894f5f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff9b82-1d5a-4dea-a5ed-bc0a80d7872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "model = model_dcm\n",
    "params = params_dcm\n",
    "seed = 42\n",
    "rng = np.random.RandomState(seed)\n",
    "jax_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "\n",
    "R = test_data['R'][idx:idx+1]  # (1, natoms, 3)\n",
    "Z = test_data['Z'][idx:idx+1]  # (1, natoms)\n",
    "N = test_data['N'][idx:idx+1]  # (1,)\n",
    "vdw_surface = test_data['vdw_surface'][idx:idx+1]  # (1, ngrid, 3)\n",
    "TESTESP =  test_data['esp'][idx:idx+1]  # (1, ngrid, 3)\n",
    "n_atoms = int(N[0])\n",
    "\n",
    "graph = build_neighbor_graph(R, N)\n",
    "\n",
    "# Original prediction\n",
    "output_orig = predict_single(model, params, R, Z, N, vdw_surface, graph=graph)\n",
    "\n",
    "# Test rotation\n",
    "jax_key, rot_key, trans_key = jax.random.split(jax_key, 3)\n",
    "rot_matrix = generate_random_rotation(rot_key)\n",
    "R_rot = apply_rotation(R, rot_matrix)\n",
    "vdw_rot = apply_rotation(vdw_surface, rot_matrix)\n",
    "\n",
    "output_rot = predict_single(model, params, R_rot, Z, N, vdw_rot, graph=graph)\n",
    "\n",
    "# For equivariant model: rotated output should equal rotation of original output\n",
    "# Dipole should rotate\n",
    "dipole_orig = jnp.asarray(output_orig['dipole'])\n",
    "dipole_rot = jnp.asarray(output_rot['dipole'])\n",
    "dipole_expected = jnp.einsum('ij,j->i', rot_matrix, dipole_orig)\n",
    "rotation_error_dipole = jnp.linalg.norm(dipole_rot - dipole_expected)\n",
    "\n",
    "\n",
    "# ESP should be identical at rotated grid points\n",
    "esp_orig = jnp.asarray(output_orig['esp'])\n",
    "esp_rot = jnp.asarray(output_rot['esp'])\n",
    "rotation_error_esp = jnp.mean(jnp.abs(esp_rot - esp_orig))\n",
    "\n",
    "\n",
    "# Test translation (both models should be translation invariant)\n",
    "translation = 5.0 * jax.random.normal(trans_key, (3,), dtype=rot_matrix.dtype)\n",
    "R_trans = apply_translation(R, translation)\n",
    "vdw_trans = apply_translation(vdw_surface, translation)\n",
    "\n",
    "output_trans = predict_single(model, params, R_trans, Z, N, vdw_trans, graph=graph)\n",
    "\n",
    "# Dipole should be identical (molecule-centered)\n",
    "dipole_trans = jnp.asarray(output_trans['dipole'])\n",
    "translation_error_dipole = jnp.linalg.norm(dipole_trans - dipole_orig)\n",
    "\n",
    "\n",
    "# ESP should be identical\n",
    "esp_trans = jnp.asarray(output_trans['esp'])\n",
    "translation_error_esp = jnp.mean(jnp.abs(esp_trans - esp_orig))\n",
    "\n",
    "\n",
    "# Compare against reference quantities\n",
    "true_energy = jnp.asarray(test_data['E'][idx])\n",
    "energy_error = jnp.abs(jnp.asarray(output_orig['energy']) - true_energy)\n",
    "\n",
    "\n",
    "true_dipole = jnp.asarray(test_data['Dxyz'][idx])\n",
    "dipole_mae = jnp.mean(jnp.abs(dipole_orig - true_dipole))\n",
    "\n",
    "\n",
    "true_forces = jnp.asarray(test_data['F'][idx])\n",
    "if true_forces.ndim == 1:\n",
    "    true_forces = true_forces.reshape(-1, 3)\n",
    "forces_pred = jnp.asarray(output_orig['forces'])\n",
    "forces_mae = jnp.mean(\n",
    "    jnp.abs(forces_pred[:n_atoms] - true_forces[:n_atoms])\n",
    ")\n",
    "plt.scatter(output_orig['esp'], TESTESP, alpha=0.01)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "plt.scatter(output_trans['esp'], TESTESP, alpha=0.01)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.plot([0,1],[0,1], transform=ax.transAxes, color=\"k\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "plt.scatter(output_orig['esp'], output_rot['esp'], alpha=0.1)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "ax.plot([0,1],[0,1], transform=ax.transAxes, color=\"k\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9e083-0696-4b7a-9853-cf47c3eb308f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# =========================\n",
    "# CONFIG (no magic numbers)\n",
    "# =========================\n",
    "CFG = {\n",
    "    \"bounds_percentile\": 99.5,            # symmetric axis limits from |values|\n",
    "    \"min_bins\": 20,                       # FD lower clamp\n",
    "    \"max_bins\": 200,                      # FD upper clamp\n",
    "    \"contour_percentiles\": [70, 85, 93, 98],  # exactly 4 contour levels\n",
    "    \"line_width\": 1.2,                    # contour line width\n",
    "    \"diag_width\": 0.8,                    # diagonal line width\n",
    "    \"hist_alpha\": 0.8,                    # marginal histogram alpha\n",
    "    \"hist_size_fraction\": 0.25,           # tomography axes size as fraction of main axes\n",
    "    \"hist_pad_fraction\": 0.02,            # padding as fraction of main axes\n",
    "    \"line_colors\": {                      # Okabe‚ÄìIto-ish colors for lines\n",
    "        \"orig_vs_true\":  \"#0072B2\",       # blue\n",
    "        \"trans_vs_true\": \"#E69F00\",       # orange\n",
    "        \"rot_vs_orig\":   \"#009E73\",       # green\n",
    "    },\n",
    "    \"figsize\": (12, 4.2),\n",
    "    \"title_size\": 11,\n",
    "    \"label_size\": 10,\n",
    "    \"tick_size\": 9,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def _finite(a):\n",
    "    a = np.asarray(a).ravel()\n",
    "    return a[np.isfinite(a)]\n",
    "\n",
    "def _symmetric_limits(*arrays, p=99.5):\n",
    "    vals = np.concatenate([_finite(a) for a in arrays]) if arrays else np.array([0.0])\n",
    "    if vals.size == 0:\n",
    "        return (-1.0, 1.0)\n",
    "    L = np.nanpercentile(np.abs(vals), p)\n",
    "    if not np.isfinite(L) or L == 0:\n",
    "        L = np.max(np.abs(vals)) or 1.0\n",
    "    return (-float(L), float(L))\n",
    "\n",
    "def _fd_bins(x, min_bins, max_bins):\n",
    "    x = _finite(x); n = x.size\n",
    "    if n < 2:\n",
    "        return min_bins\n",
    "    q75, q25 = np.percentile(x, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    if iqr <= 0:\n",
    "        bins = int(np.sqrt(max(n, 1)))\n",
    "    else:\n",
    "        h = 2 * iqr * n ** (-1/3)\n",
    "        data_range = x.max() - x.min()\n",
    "        bins = int(np.ceil(data_range / h)) if h > 0 else int(np.sqrt(max(n, 1)))\n",
    "    return int(np.clip(bins, min_bins, max_bins))\n",
    "\n",
    "def _hist2d_density(x, y, bins_x, bins_y, xlim, ylim):\n",
    "    H, xedges, yedges = np.histogram2d(\n",
    "        x, y, bins=[bins_x, bins_y], range=[xlim, ylim], density=True\n",
    "    )\n",
    "    return H.T, xedges, yedges\n",
    "\n",
    "def _contour_levels_from_percentiles(density, percentiles):\n",
    "    flat = density.ravel()\n",
    "    flat = flat[(flat > 0) & np.isfinite(flat)]\n",
    "    if flat.size == 0:\n",
    "        # degenerate fallback\n",
    "        return np.array([1e-12, 1e-10, 1e-8, 1e-6])\n",
    "    levels = np.percentile(flat, percentiles)\n",
    "    levels = np.unique(levels)\n",
    "    if levels.size < 4:\n",
    "        mn, mx = float(flat.min()), float(flat.max())\n",
    "        if mx == mn:\n",
    "            levels = mn * (1.0 + 1e-6 * np.arange(1, 5))\n",
    "        else:\n",
    "            levels = np.linspace(mn + 1e-12, mx, 4)\n",
    "    return levels[:4]\n",
    "\n",
    "def _rmse_in_limits(x, y, limits):\n",
    "    x = _finite(x); y = _finite(y)\n",
    "    m = (x >= limits[0]) & (x <= limits[1]) & (y >= limits[0]) & (y <= limits[1])\n",
    "    if not np.any(m):\n",
    "        return np.nan\n",
    "    d = x[m] - y[m]\n",
    "    return float(np.sqrt(np.mean(d * d)))\n",
    "\n",
    "def plot_panel(ax_main, x, y, *, line_color, limits, cfg, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Unfilled 2D density contours (4 levels) + diagonal + marginal tomograms + RMSE annotation.\n",
    "    \"\"\"\n",
    "    x = _finite(x); y = _finite(y)\n",
    "    xlim = ylim = limits\n",
    "\n",
    "    # Bins via FD\n",
    "    bx = _fd_bins(x, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    by = _fd_bins(y, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "\n",
    "    # Density grid\n",
    "    H, xedges, yedges = _hist2d_density(x, y, bx, by, xlim, ylim)\n",
    "\n",
    "    # Centers for contours\n",
    "    Xc = 0.5 * (xedges[:-1] + xedges[1:])\n",
    "    Yc = 0.5 * (yedges[:-1] + yedges[1:])\n",
    "    X, Y = np.meshgrid(Xc, Yc)\n",
    "\n",
    "    # Exactly 4 contour levels\n",
    "    levels = _contour_levels_from_percentiles(H, cfg[\"contour_percentiles\"])\n",
    "\n",
    "    # Unfilled contour lines\n",
    "    ax_main.contour(X, Y, H, levels=levels, colors=line_color, linewidths=cfg[\"line_width\"])\n",
    "\n",
    "    # Identity diagonal\n",
    "    ax_main.plot([limits[0], limits[1]], [limits[0], limits[1]],\n",
    "                 '--', color='k', linewidth=cfg[\"diag_width\"])\n",
    "\n",
    "    ax_main.set_xlim(limits); ax_main.set_ylim(limits); ax_main.set_aspect(\"equal\")\n",
    "    ax_main.set_title(title, fontsize=cfg[\"title_size\"])\n",
    "    ax_main.set_xlabel(xlabel, fontsize=cfg[\"label_size\"])\n",
    "    ax_main.set_ylabel(ylabel, fontsize=cfg[\"label_size\"])\n",
    "    ax_main.tick_params(labelsize=cfg[\"tick_size\"])\n",
    "\n",
    "    # RMSE (in-range)\n",
    "    rmse = _rmse_in_limits(x, y, limits)\n",
    "    ax_main.text(0.02, 0.98, f\"RMSE (in-range): {rmse:.4g}\",\n",
    "                 transform=ax_main.transAxes, ha='left', va='top',\n",
    "                 fontsize=cfg[\"label_size\"])\n",
    "\n",
    "    # ---- Tomography (marginal histograms) with FRACTION sizes ----\n",
    "    divider = make_axes_locatable(ax_main)\n",
    "    size_str = f\"{cfg['hist_size_fraction']*100:.1f}%\"   # e.g., \"25.0%\"\n",
    "    pad_str  = f\"{cfg['hist_pad_fraction']*100:.2f}%\"\n",
    "\n",
    "    ax_top   = divider.append_axes(\"top\",  size=size_str, pad=pad_str, sharex=ax_main)\n",
    "    ax_right = divider.append_axes(\"right\", size=size_str, pad=pad_str, sharey=ax_main)\n",
    "\n",
    "    # X projection\n",
    "    bins_x = _fd_bins(x, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    ax_top.hist(x[(x>=limits[0]) & (x<=limits[1])], bins=bins_x, range=limits,\n",
    "                color=line_color, alpha=cfg[\"hist_alpha\"], density=True)\n",
    "    ax_top.tick_params(labelbottom=False, labelsize=cfg[\"tick_size\"])\n",
    "    ax_top.set_xlim(limits)\n",
    "\n",
    "    # Y projection\n",
    "    bins_y = _fd_bins(y, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    ax_right.hist(y[(y>=limits[0]) & (y<=limits[1])], bins=bins_y, range=limits,\n",
    "                  color=line_color, alpha=cfg[\"hist_alpha\"], density=True, orientation='horizontal')\n",
    "    ax_right.tick_params(labelleft=False, labelsize=cfg[\"tick_size\"])\n",
    "    ax_right.set_ylim(limits)\n",
    "\n",
    "# =========================\n",
    "# DATA EXTRACT (ESP arrays)\n",
    "# =========================\n",
    "esp_pred_orig  = np.asarray(output_orig['esp']).ravel()\n",
    "esp_pred_rot   = np.asarray(output_rot['esp']).ravel()\n",
    "esp_pred_trans = np.asarray(output_trans['esp']).ravel()\n",
    "esp_true       = np.asarray(TESTESP).ravel()\n",
    "\n",
    "# Shared robust symmetric limits across all panels\n",
    "limits = _symmetric_limits(esp_pred_orig, esp_pred_rot, esp_pred_trans, esp_true,\n",
    "                           p=CFG[\"bounds_percentile\"])\n",
    "\n",
    "# =========================\n",
    "# PLOT (3 panels)\n",
    "# =========================\n",
    "fig, axes = plt.subplots(1, 3, figsize=CFG[\"figsize\"], constrained_layout=True, sharex=True, sharey=True)\n",
    "\n",
    "plot_panel(\n",
    "    axes[0],\n",
    "    esp_pred_orig, esp_true,\n",
    "    line_color=CFG[\"line_colors\"][\"orig_vs_true\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Original vs True ESP\",\n",
    "    xlabel=\"Predicted ESP\", ylabel=\"Reference ESP\"\n",
    ")\n",
    "\n",
    "plot_panel(\n",
    "    axes[1],\n",
    "    esp_pred_trans, esp_true,\n",
    "    line_color=CFG[\"line_colors\"][\"trans_vs_true\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Translated vs True ESP\",\n",
    "    xlabel=\"Predicted ESP\", ylabel=\"Reference ESP\"\n",
    ")\n",
    "\n",
    "plot_panel(\n",
    "    axes[2],\n",
    "    esp_pred_orig, esp_pred_rot,\n",
    "    line_color=CFG[\"line_colors\"][\"rot_vs_orig\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Rotated vs Original ESP\",\n",
    "    xlabel=\"Original ESP\", ylabel=\"Rotated ESP\"\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66639afe-4b33-4b7f-9f76-24ec573b2796",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(TESTESP).T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01275312-8d77-44e6-8369-f1549a3056ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((output_trans['esp'] - TESTESP)**2)) * 627.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956740b-33ad-4308-bf75-35fe9a37baef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((output_trans['esp'] - output_orig['esp'])**2)) * 627.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3904c9-3c5d-4794-bf21-d058d65c4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_models import predict_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd0f380-602d-4d5c-bf41-89b619636733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1293b6-b6a9-4816-8601-aab16a4f8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "model = model_noneq\n",
    "params = params_noneq\n",
    "seed = 42\n",
    "rng = np.random.RandomState(seed)\n",
    "jax_key = jax.random.PRNGKey(seed)\n",
    "\n",
    "R = test_data['R'][idx:idx+1]  # (1, natoms, 3)\n",
    "Z = test_data['Z'][idx:idx+1]  # (1, natoms)\n",
    "N = test_data['N'][idx:idx+1]  # (1,)\n",
    "vdw_surface = test_data['vdw_surface'][idx:idx+1]  # (1, ngrid, 3)\n",
    "TESTESP =  test_data['esp'][idx:idx+1]  # (1, ngrid, 3)\n",
    "n_atoms = int(N[0])\n",
    "\n",
    "graph = build_neighbor_graph(R, N)\n",
    "\n",
    "# Original prediction\n",
    "output_orig = predict_single(model, params, R, Z, N, vdw_surface, graph=graph)\n",
    "\n",
    "# Test rotation\n",
    "jax_key, rot_key, trans_key = jax.random.split(jax_key, 3)\n",
    "rot_matrix = generate_random_rotation(rot_key)\n",
    "R_rot = apply_rotation(R, rot_matrix)\n",
    "vdw_rot = apply_rotation(vdw_surface, rot_matrix)\n",
    "\n",
    "output_rot = predict_single(model, params, R_rot, Z, N, vdw_rot, graph=graph)\n",
    "\n",
    "# For equivariant model: rotated output should equal rotation of original output\n",
    "# Dipole should rotate\n",
    "dipole_orig = jnp.asarray(output_orig['dipole'])\n",
    "dipole_rot = jnp.asarray(output_rot['dipole'])\n",
    "dipole_expected = jnp.einsum('ij,j->i', rot_matrix, dipole_orig)\n",
    "rotation_error_dipole = jnp.linalg.norm(dipole_rot - dipole_expected)\n",
    "\n",
    "\n",
    "# ESP should be identical at rotated grid points\n",
    "esp_orig = jnp.asarray(output_orig['esp'])\n",
    "esp_rot = jnp.asarray(output_rot['esp'])\n",
    "rotation_error_esp = jnp.mean(jnp.abs(esp_rot - esp_orig))\n",
    "\n",
    "\n",
    "# Test translation (both models should be translation invariant)\n",
    "translation = 5.0 * jax.random.normal(trans_key, (3,), dtype=rot_matrix.dtype)\n",
    "R_trans = apply_translation(R, translation)\n",
    "vdw_trans = apply_translation(vdw_surface, translation)\n",
    "\n",
    "output_trans = predict_single(model, params, R_trans, Z, N, vdw_trans, graph=graph)\n",
    "\n",
    "# Dipole should be identical (molecule-centered)\n",
    "dipole_trans = jnp.asarray(output_trans['dipole'])\n",
    "translation_error_dipole = jnp.linalg.norm(dipole_trans - dipole_orig)\n",
    "\n",
    "\n",
    "# ESP should be identical\n",
    "esp_trans = jnp.asarray(output_trans['esp'])\n",
    "translation_error_esp = jnp.mean(jnp.abs(esp_trans - esp_orig))\n",
    "\n",
    "\n",
    "# Compare against reference quantities\n",
    "true_energy = jnp.asarray(test_data['E'][idx])\n",
    "energy_error = jnp.abs(jnp.asarray(output_orig['energy']) - true_energy)\n",
    "\n",
    "\n",
    "true_dipole = jnp.asarray(test_data['Dxyz'][idx])\n",
    "dipole_mae = jnp.mean(jnp.abs(dipole_orig - true_dipole))\n",
    "\n",
    "\n",
    "true_forces = jnp.asarray(test_data['F'][idx])\n",
    "if true_forces.ndim == 1:\n",
    "    true_forces = true_forces.reshape(-1, 3)\n",
    "forces_pred = jnp.asarray(output_orig['forces'])\n",
    "forces_mae = jnp.mean(\n",
    "    jnp.abs(forces_pred[:n_atoms] - true_forces[:n_atoms])\n",
    ")\n",
    "plt.scatter(output_orig['esp'], TESTESP, alpha=0.01)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "plt.scatter(output_trans['esp'], TESTESP, alpha=0.01)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.plot([0,1],[0,1], transform=ax.transAxes, color=\"k\", linestyle=\"--\")\n",
    "\n",
    "plt.scatter(output_orig['esp'], output_rot['esp'], alpha=0.1)\n",
    "for _ in [plt.ylim, plt.xlim]:\n",
    "    _(-0.04, 0.04)\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "ax.plot([0,1],[0,1], transform=ax.transAxes, color=\"k\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9b232-3b31-4106-8981-fc43b7b32972",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc892e-372c-4ddc-bb9a-140575fa8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((output_rot['esp'] - TESTESP)**2)) * 627.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbcb8d7-e596-4ed7-b4b7-12f8c1ddec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((output_trans['esp'] - output_orig['esp'])**2)) * 627.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a7b94-d412-43b1-a355-f966aeb00193",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9a24e2-4db8-48b8-9cfc-b0758bd02208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# =========================\n",
    "# CONFIG (no magic numbers)\n",
    "# =========================\n",
    "CFG = {\n",
    "    \"bounds_percentile\": 99.5,            # symmetric axis limits from |values|\n",
    "    \"min_bins\": 20,                       # FD lower clamp\n",
    "    \"max_bins\": 200,                      # FD upper clamp\n",
    "    \"contour_percentiles\": [70, 85, 93, 98],  # exactly 4 contour levels\n",
    "    \"line_width\": 1.2,                    # contour line width\n",
    "    \"diag_width\": 0.8,                    # diagonal line width\n",
    "    \"hist_alpha\": 0.8,                    # marginal histogram alpha\n",
    "    \"hist_size_fraction\": 0.25,           # tomography axes size as fraction of main axes\n",
    "    \"hist_pad_fraction\": 0.02,            # padding as fraction of main axes\n",
    "    \"line_colors\": {                      # Okabe‚ÄìIto-ish colors for lines\n",
    "        \"orig_vs_true\":  \"#0072B2\",       # blue\n",
    "        \"trans_vs_true\": \"#E69F00\",       # orange\n",
    "        \"rot_vs_orig\":   \"#009E73\",       # green\n",
    "    },\n",
    "    \"figsize\": (12, 4.2),\n",
    "    \"title_size\": 11,\n",
    "    \"label_size\": 10,\n",
    "    \"tick_size\": 9,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def _finite(a):\n",
    "    a = np.asarray(a).ravel()\n",
    "    return a[np.isfinite(a)]\n",
    "\n",
    "def _symmetric_limits(*arrays, p=99.5):\n",
    "    vals = np.concatenate([_finite(a) for a in arrays]) if arrays else np.array([0.0])\n",
    "    if vals.size == 0:\n",
    "        return (-1.0, 1.0)\n",
    "    L = np.nanpercentile(np.abs(vals), p)\n",
    "    if not np.isfinite(L) or L == 0:\n",
    "        L = np.max(np.abs(vals)) or 1.0\n",
    "    return (-float(L), float(L))\n",
    "\n",
    "def _fd_bins(x, min_bins, max_bins):\n",
    "    x = _finite(x); n = x.size\n",
    "    if n < 2:\n",
    "        return min_bins\n",
    "    q75, q25 = np.percentile(x, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    if iqr <= 0:\n",
    "        bins = int(np.sqrt(max(n, 1)))\n",
    "    else:\n",
    "        h = 2 * iqr * n ** (-1/3)\n",
    "        data_range = x.max() - x.min()\n",
    "        bins = int(np.ceil(data_range / h)) if h > 0 else int(np.sqrt(max(n, 1)))\n",
    "    return int(np.clip(bins, min_bins, max_bins))\n",
    "\n",
    "def _hist2d_density(x, y, bins_x, bins_y, xlim, ylim):\n",
    "    H, xedges, yedges = np.histogram2d(\n",
    "        x, y, bins=[bins_x, bins_y], range=[xlim, ylim], density=True\n",
    "    )\n",
    "    return H.T, xedges, yedges\n",
    "\n",
    "def _contour_levels_from_percentiles(density, percentiles):\n",
    "    flat = density.ravel()\n",
    "    flat = flat[(flat > 0) & np.isfinite(flat)]\n",
    "    if flat.size == 0:\n",
    "        # degenerate fallback\n",
    "        return np.array([1e-12, 1e-10, 1e-8, 1e-6])\n",
    "    levels = np.percentile(flat, percentiles)\n",
    "    levels = np.unique(levels)\n",
    "    if levels.size < 4:\n",
    "        mn, mx = float(flat.min()), float(flat.max())\n",
    "        if mx == mn:\n",
    "            levels = mn * (1.0 + 1e-6 * np.arange(1, 5))\n",
    "        else:\n",
    "            levels = np.linspace(mn + 1e-12, mx, 4)\n",
    "    return levels[:4]\n",
    "\n",
    "def _rmse_in_limits(x, y, limits):\n",
    "    x = _finite(x); y = _finite(y)\n",
    "    m = (x >= limits[0]) & (x <= limits[1]) & (y >= limits[0]) & (y <= limits[1])\n",
    "    if not np.any(m):\n",
    "        return np.nan\n",
    "    d = x[m] - y[m]\n",
    "    return float(np.sqrt(np.mean(d * d)))\n",
    "\n",
    "def plot_panel(ax_main, x, y, *, line_color, limits, cfg, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Unfilled 2D density contours (4 levels) + diagonal + marginal tomograms + RMSE annotation.\n",
    "    \"\"\"\n",
    "    x = _finite(x); y = _finite(y)\n",
    "    xlim = ylim = limits\n",
    "\n",
    "    # Bins via FD\n",
    "    bx = _fd_bins(x, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    by = _fd_bins(y, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "\n",
    "    # Density grid\n",
    "    H, xedges, yedges = _hist2d_density(x, y, bx, by, xlim, ylim)\n",
    "\n",
    "    # Centers for contours\n",
    "    Xc = 0.5 * (xedges[:-1] + xedges[1:])\n",
    "    Yc = 0.5 * (yedges[:-1] + yedges[1:])\n",
    "    X, Y = np.meshgrid(Xc, Yc)\n",
    "\n",
    "    # Exactly 4 contour levels\n",
    "    levels = _contour_levels_from_percentiles(H, cfg[\"contour_percentiles\"])\n",
    "\n",
    "    # Unfilled contour lines\n",
    "    ax_main.contour(X, Y, H, levels=levels, colors=line_color, linewidths=cfg[\"line_width\"])\n",
    "\n",
    "    # Identity diagonal\n",
    "    ax_main.plot([limits[0], limits[1]], [limits[0], limits[1]],\n",
    "                 '--', color='k', linewidth=cfg[\"diag_width\"])\n",
    "\n",
    "    ax_main.set_xlim(limits); ax_main.set_ylim(limits); ax_main.set_aspect(\"equal\")\n",
    "    ax_main.set_title(title, fontsize=cfg[\"title_size\"])\n",
    "    ax_main.set_xlabel(xlabel, fontsize=cfg[\"label_size\"])\n",
    "    ax_main.set_ylabel(ylabel, fontsize=cfg[\"label_size\"])\n",
    "    ax_main.tick_params(labelsize=cfg[\"tick_size\"])\n",
    "\n",
    "    # RMSE (in-range)\n",
    "    rmse = _rmse_in_limits(x, y, limits)\n",
    "    ax_main.text(0.02, 0.98, f\"RMSE (in-range): {rmse:.4g}\",\n",
    "                 transform=ax_main.transAxes, ha='left', va='top',\n",
    "                 fontsize=cfg[\"label_size\"])\n",
    "\n",
    "    # ---- Tomography (marginal histograms) with FRACTION sizes ----\n",
    "    divider = make_axes_locatable(ax_main)\n",
    "    size_str = f\"{cfg['hist_size_fraction']*100:.1f}%\"   # e.g., \"25.0%\"\n",
    "    pad_str  = f\"{cfg['hist_pad_fraction']*100:.2f}%\"\n",
    "\n",
    "    ax_top   = divider.append_axes(\"top\",  size=size_str, pad=pad_str, sharex=ax_main)\n",
    "    ax_right = divider.append_axes(\"right\", size=size_str, pad=pad_str, sharey=ax_main)\n",
    "\n",
    "    # X projection\n",
    "    bins_x = _fd_bins(x, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    ax_top.hist(x[(x>=limits[0]) & (x<=limits[1])], bins=bins_x, range=limits,\n",
    "                color=line_color, alpha=cfg[\"hist_alpha\"], density=True)\n",
    "    ax_top.tick_params(labelbottom=False, labelsize=cfg[\"tick_size\"])\n",
    "    ax_top.set_xlim(limits)\n",
    "\n",
    "    # Y projection\n",
    "    bins_y = _fd_bins(y, cfg[\"min_bins\"], cfg[\"max_bins\"])\n",
    "    ax_right.hist(y[(y>=limits[0]) & (y<=limits[1])], bins=bins_y, range=limits,\n",
    "                  color=line_color, alpha=cfg[\"hist_alpha\"], density=True, orientation='horizontal')\n",
    "    ax_right.tick_params(labelleft=False, labelsize=cfg[\"tick_size\"])\n",
    "    ax_right.set_ylim(limits)\n",
    "\n",
    "# =========================\n",
    "# DATA EXTRACT (ESP arrays)\n",
    "# =========================\n",
    "esp_pred_orig  = np.asarray(output_orig['esp']).ravel()\n",
    "esp_pred_rot   = np.asarray(output_rot['esp']).ravel()\n",
    "esp_pred_trans = np.asarray(output_trans['esp']).ravel()\n",
    "esp_true       = np.asarray(TESTESP).ravel()\n",
    "\n",
    "# Shared robust symmetric limits across all panels\n",
    "limits = _symmetric_limits(esp_pred_orig, esp_pred_rot, esp_pred_trans, esp_true,\n",
    "                           p=CFG[\"bounds_percentile\"])\n",
    "\n",
    "# =========================\n",
    "# PLOT (3 panels)\n",
    "# =========================\n",
    "fig, axes = plt.subplots(1, 3, figsize=CFG[\"figsize\"], constrained_layout=True, sharex=True, sharey=True)\n",
    "\n",
    "plot_panel(\n",
    "    axes[0],\n",
    "    esp_pred_orig, esp_true,\n",
    "    line_color=CFG[\"line_colors\"][\"orig_vs_true\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Original vs True ESP\",\n",
    "    xlabel=\"Predicted ESP\", ylabel=\"Reference ESP\"\n",
    ")\n",
    "\n",
    "plot_panel(\n",
    "    axes[1],\n",
    "    esp_pred_trans, esp_true,\n",
    "    line_color=CFG[\"line_colors\"][\"trans_vs_true\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Translated vs True ESP\",\n",
    "    xlabel=\"Predicted ESP\", ylabel=\"Reference ESP\"\n",
    ")\n",
    "\n",
    "plot_panel(\n",
    "    axes[2],\n",
    "    esp_pred_orig, esp_pred_rot,\n",
    "    line_color=CFG[\"line_colors\"][\"rot_vs_orig\"],\n",
    "    limits=limits, cfg=CFG,\n",
    "    title=\"Rotated vs Original ESP\",\n",
    "    xlabel=\"Original ESP\", ylabel=\"Rotated ESP\"\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085fd565-887a-4797-89bf-a3fe873c0c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d09f1e-5c39-4232-82ff-51e36c4c5f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf4f2f-60f8-477b-9aac-f15d35bb4fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6e3e4-f1d5-4a24-abc0-c96767839fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb60fe-6724-403c-a986-5293fc7111fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738457b-5f8c-424e-9e22-becc36ffb76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d71755-4a9f-4f6b-b0da-bc8b0b6e0401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e199ac06-eeaa-4bf2-822d-d7800841729f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9eae7-d6bb-41f3-95c0-8104cf4fab4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f937fa-ef7d-4619-9549-0dbe5132f7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c6cb8-0591-4d7a-9e7d-8a4d22c61c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f348235-d137-493e-aa40-351ce71a7bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a9e4d-17c9-4ac7-9343-bab43f22cd76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
