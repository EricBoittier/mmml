{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee91595-b29c-45eb-98f4-556a0d840839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:2025-10-29 20:34:44,206:jax._src.xla_bridge:487: Jax plugin configuration error: Exception when calling jax_plugins.xla_cuda12.initialize()\n",
      "Traceback (most recent call last):\n",
      "  File \"/scicore/home/meuwly/boitti0000/mmml/.venv/lib/python3.12/site-packages/jax/_src/xla_bridge.py\", line 485, in discover_pjrt_plugins\n",
      "    plugin_module.initialize()\n",
      "  File \"/scicore/home/meuwly/boitti0000/mmml/.venv/lib/python3.12/site-packages/jax_plugins/xla_cuda12/__init__.py\", line 328, in initialize\n",
      "    _check_cuda_versions(raise_on_first_error=True)\n",
      "  File \"/scicore/home/meuwly/boitti0000/mmml/.venv/lib/python3.12/site-packages/jax_plugins/xla_cuda12/__init__.py\", line 285, in _check_cuda_versions\n",
      "    local_device_count = cuda_versions.cuda_device_count()\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: jaxlib/cuda/versions_helpers.cc:113: operation cuInit(0) failed: CUDA_ERROR_NOT_INITIALIZED\n",
      "WARNING:2025-10-29 20:34:44,213:jax._src.xla_bridge:864: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CpuDevice(id=0)]\n",
      "cpu\n",
      "[CpuDevice(id=0)]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Data file not found at /pchem-data/meuwly/boittier/home/test.npz",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     40\u001b[39m     data_path_resolved = Path(\u001b[33m'\u001b[39m\u001b[33m/pchem-data/meuwly/boittier/home/test.npz\u001b[39m\u001b[33m'\u001b[39m) \n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_path_resolved.exists():\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mData file not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path_resolved\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m data_loaded = np.load(data_path_resolved, allow_pickle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m data_loaded.keys():\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Data file not found at /pchem-data/meuwly/boittier/home/test.npz"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "import mmml\n",
    "import matplotlib.pyplot as plt\n",
    "import patchworklib as pw\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.95\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import jax\n",
    "devices = jax.local_devices()\n",
    "print(devices)\n",
    "print(jax.default_backend())\n",
    "print(jax.devices())\n",
    "\n",
    "# %%\n",
    "from mmml import dcmnet\n",
    "params = None\n",
    "# %%\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from mmml.dcmnet.dcmnet.data import prepare_datasets\n",
    "from mmml.dcmnet.dcmnet.modules import MessagePassingModel\n",
    "from mmml.dcmnet.dcmnet.training import train_model, train_model_dipo\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "seed = 42\n",
    "# %%\n",
    "NDCM = 4\n",
    "model = MessagePassingModel(\n",
    "    features=128, max_degree=2, num_iterations=2,\n",
    "    num_basis_functions=32, cutoff=8.0, n_dcm=NDCM,\n",
    "    include_pseudotensors=False,\n",
    ")\n",
    "\n",
    "\n",
    "data_path_resolved = Path('/home/ericb/testmmml/test.npz') \n",
    "if not data_path_resolved.exists():\n",
    "    data_path_resolved = Path('/pchem-data/meuwly/boittier/home/test.npz') \n",
    "    if not data_path_resolved.exists():\n",
    "        raise FileNotFoundError(f\"Data file not found at {data_path_resolved}\")\n",
    "\n",
    "data_loaded = np.load(data_path_resolved, allow_pickle=True)\n",
    "\n",
    "for k in data_loaded.keys():\n",
    "    print(k)\n",
    "    shape = data_loaded[k].shape\n",
    "    print(shape\n",
    "    )\n",
    "\n",
    "n_sample = 1000  # Number of points to keep\n",
    "Nboot = 10\n",
    "for i in range(Nboot):\n",
    "    data_key = jax.random.PRNGKey(i*seed)\n",
    "\n",
    "    train_data, valid_data = prepare_datasets(\n",
    "        data_key, num_train=1000, num_valid=100,\n",
    "        filename=[data_path_resolved],\n",
    "        clean=False, esp_mask=False,\n",
    "        natoms=18,\n",
    "        clip_esp=False,\n",
    "    )\n",
    "\n",
    "    def random_sample_esp(esp, esp_grid, n_sample, seed=i*seed):\n",
    "        np.random.seed(seed)\n",
    "        sampled_esp = []\n",
    "        sampled_grid = []\n",
    "        \n",
    "        for i in range(len(esp)):\n",
    "            lessthan = esp[i] < 2\n",
    "            morethan = esp[i] > -2\n",
    "            not_0 = esp[i] != 0.0\n",
    "            condmask = lessthan*morethan*not_0\n",
    "            _shape = esp[i][condmask].shape[0]\n",
    "            # print(_shape)\n",
    "            indices = np.random.choice(_shape, n_sample, replace=False)\n",
    "            #indices = np.sort(indices) \n",
    "            sampled_esp.append(np.take(esp[i], condmask[indices]))\n",
    "            # print(sampled_esp[-1].shape)\n",
    "            sampled_grid.append(np.take(esp_grid[i], condmask[indices], axis=0))\n",
    "            # print(sampled_grid[-1].shape)\n",
    "        \n",
    "        return np.array(sampled_esp), np.array(sampled_grid)\n",
    "\n",
    "    train_data[\"esp\"], train_data[\"esp_grid\"] = random_sample_esp(\n",
    "        train_data[\"esp\"] , train_data[\"esp_grid\"], n_sample\n",
    "    )\n",
    "    valid_data[\"esp\"], valid_data[\"esp_grid\"] = random_sample_esp(\n",
    "        valid_data[\"esp\"] , valid_data[\"esp_grid\"], n_sample\n",
    "    )\n",
    "\n",
    "\n",
    "    valid_data[\"esp\"] = 0.0016 * valid_data[\"esp\"]\n",
    "    train_data[\"esp\"] = 0.0016 * train_data[\"esp\"]\n",
    "\n",
    "    train_data[\"vdw_surface\"] = train_data[\"esp_grid\"] \n",
    "    valid_data[\"vdw_surface\"] = valid_data[\"esp_grid\"] \n",
    "    train_data[\"n_grid\"] = np.full(len(train_data[\"vdw_surface\"]), n_sample)\n",
    "    valid_data[\"n_grid\"] = np.full(len(valid_data[\"vdw_surface\"]), n_sample)\n",
    "\n",
    "\n",
    "    train_data[\"vdw_surface\"] = train_data[\"esp_grid\"]\n",
    "    valid_data[\"vdw_surface\"] = valid_data[\"esp_grid\"]\n",
    "\n",
    "    Hs_train = train_data[\"Z\"] == 1.0\n",
    "    Os_train = train_data[\"Z\"] == 8.0\n",
    "    Hs_valid = valid_data[\"Z\"] == 1.0\n",
    "    Os_valid = valid_data[\"Z\"] == 8.0\n",
    "\n",
    "    train_data[\"mono\"] = Hs_train * 0.1 + Os_train * -0.2\n",
    "    valid_data[\"mono\"] = Hs_valid * 0.1 + Os_valid * -0.2\n",
    "\n",
    "    # Fix n_grid shape\n",
    "    train_data[\"n_grid\"] = np.full(train_data[\"Z\"].shape[0], n_sample)\n",
    "    valid_data[\"n_grid\"] = np.full(valid_data[\"Z\"].shape[0], n_sample)\n",
    "\n",
    "    # Fix N shape  \n",
    "    train_data[\"N\"] = np.count_nonzero(train_data[\"Z\"], axis=1)\n",
    "    valid_data[\"N\"] = np.count_nonzero(valid_data[\"Z\"], axis=1)\n",
    "\n",
    "    print(\"After fixes:\")\n",
    "    batch = {k: v[0:1] if len(v.shape) > 0 else v for k, v in train_data.items()}\n",
    "    for key in ['mono', 'esp', 'vdw_surface', 'n_grid', 'N', 'R', 'Z']:\n",
    "        if key in batch:\n",
    "            print(f\"{key}: {batch[key].shape}\")\n",
    "\n",
    "    # Also check the specific values\n",
    "    print(f\"\\nmono values: {batch['mono']}\")\n",
    "    print(f\"N values: {batch['N']}\")\n",
    "    print(f\"n_grid values: {batch['n_grid']}\")\n",
    "\n",
    "    # %%\n",
    "    esp_data = train_data[\"esp\"]\n",
    "\n",
    "\n",
    "    # %%\n",
    "    params, valid_loss = train_model(\n",
    "        key=data_key, model=model,\n",
    "        writer=None,\n",
    "        train_data=train_data, valid_data=valid_data,\n",
    "        num_epochs=50, learning_rate=1e-4, batch_size=1,\n",
    "        restart_params=params if params is None else params,\n",
    "        ndcm=model.n_dcm, esp_w=1000.0*((i+1)/Nboot), chg_w=1.0/((i+1)),\n",
    "         use_grad_clip=True, grad_clip_norm=1.0,\n",
    "    )\n",
    "    new_params = params.copy()\n",
    "\n",
    "from mmml.dcmnet.dcmnet.analysis import dcmnet_analysis, prepare_batch\n",
    "from mmml.dcmnet.dcmnet.data import prepare_batches\n",
    "from mmml.dcmnet.dcmnet.analysis import dcmnet_analysis\n",
    "\n",
    "def prepare_batch_for_analysis(data, index=0):\n",
    "    \"\"\"Prepare a single batch correctly for dcmnet_analysis.\"\"\"\n",
    "    # Extract single item but keep batch dimension\n",
    "    _dict = {k: np.array(v[[index]]) for k, v in data.items()}\n",
    "    \n",
    "    # Use prepare_batches with include_id=True\n",
    "    batch = prepare_batches(jax.random.PRNGKey(0), _dict, batch_size=1, include_id=False, num_atoms =18)[0]\n",
    "    batch[\"com\"] = np.array([0,0,0])\n",
    "    batch[\"Dxyz\"] = np.array([0,0,0])\n",
    "    return batch\n",
    "\n",
    "batch = prepare_batch_for_analysis(train_data, index=0)\n",
    "output = dcmnet_analysis(params, model, batch, 18)\n",
    "print(f\"RMSE: {output['rmse_model']:.6f}\")\n",
    "print(f\"RMSE (masked): {output['rmse_model_masked']:.6f}\")\n",
    "\n",
    "import sys\n",
    "sys.exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2710b61-b8b7-4a05-af9b-0763ba05592a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
