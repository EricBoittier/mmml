{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6466d5f6",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "This notebook is meant to detail setting up the MM/ML simulations \n",
    "\n",
    "## fitting the LJs terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50642be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1120 11:50:37.115570   18776 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n",
      "W1120 11:50:37.121845   18640 cuda_executor.cc:1802] GPU interconnect information not available: INTERNAL: NVML doesn't support extracting fabric info or NVLink is not used by the device.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CudaDevice(id=0)]\n",
      "gpu\n",
      "[CudaDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import mmml\n",
    "import ase\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".99\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Check JAX configuration\n",
    "devices = jax.local_devices()\n",
    "print(devices)\n",
    "print(jax.default_backend())\n",
    "print(jax.devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127fe6ae",
   "metadata": {},
   "source": [
    "# Setup: Mock CLI Arguments (following run_sim.py structure)\n",
    "\n",
    "This cell creates a mock args object that mimics the CLI arguments from `run_sim.py`.\n",
    "This allows the notebook to follow the same structure as the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3091fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pchem-data/meuwly/boittier/home/mmml/mmml/data/top_all36_cgenff.rtf\n",
      "/pchem-data/meuwly/boittier/home/mmml/mmml/data/par_all36_cgenff.prm\n",
      "CHARMM_HOME /scicore/home/meuwly/boitti0000/mmml/setup/charmm\n",
      "CHARMM_LIB_DIR /scicore/home/meuwly/boitti0000/mmml/setup/charmm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pchem-data/meuwly/boittier/home/mmml/pycharmm/coor.py:811: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "  if self.which_set is 'main':\n",
      "/pchem-data/meuwly/boittier/home/mmml/pycharmm/coor.py:813: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "  elif self.which_set is 'comp':\n",
      "/pchem-data/meuwly/boittier/home/mmml/pycharmm/coor.py:815: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "  elif self.which_set is 'comp2':\n",
      "/pchem-data/meuwly/boittier/home/mmml/pycharmm/coor.py:825: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "  if self.which_set is 'main':\n",
      "/pchem-data/meuwly/boittier/home/mmml/pycharmm/coor.py:827: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "  elif self.which_set is 'comp':\n",
      "/pchem-data/meuwly/boittier/home/mmml/pycharmm/coor.py:829: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
      "  elif self.which_set is 'comp2':\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "/scicore/home/meuwly/boitti0000/mmml/setup/charmm/libcharmm.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import required modules (following run_sim.py structure)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmmml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcli\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     load_model_parameters,\n\u001b[32m      4\u001b[39m     resolve_checkpoint_paths,\n\u001b[32m      5\u001b[39m     setup_ase_imports,\n\u001b[32m      6\u001b[39m     setup_mmml_imports,\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmmml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpycharmmInterface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m import_pycharmm\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mic\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mmml/mmml/pycharmmInterface/import_pycharmm.py:48\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCHARMM_HOME\u001b[39m\u001b[33m\"\u001b[39m, CHARMM_HOME)\n\u001b[32m     45\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCHARMM_LIB_DIR\u001b[39m\u001b[33m\"\u001b[39m, CHARMM_LIB_DIR)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgen\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mmml/pycharmm/__init__.py:17\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# pycharmm: molecular dynamics in python with CHARMM\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Copyright (C) 2018 Josh Buckner\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# You should have received a copy of the GNU General Public License\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# along with this program.  If not, see <http://www.gnu.org/licenses/>.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01matom_info\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_atom_table\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcharmm_file\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CharmmFile\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcoor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Coordinates\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mmml/pycharmm/atom_info.py:24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcoor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcoor\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mparam\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpsf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsf\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mmml/pycharmm/coor.py:31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m  \n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpycharmm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlib\u001b[39;00m  \n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_natom\u001b[39m():  \n\u001b[32m     34\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns the number of atoms currently in the simulation  \u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[33;03m  \u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03m    Returns\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m \u001b[33;03m        number of atoms currently in the simulation  \u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m  \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mmml/pycharmm/lib.py:67\u001b[39m\n\u001b[32m     62\u001b[39m         \u001b[38;5;28mself\u001b[39m.lib.del_charmm()  \u001b[38;5;66;03m# initiates 'normal stop'\u001b[39;00m\n\u001b[32m     63\u001b[39m         \u001b[38;5;66;03m# does not work\u001b[39;00m\n\u001b[32m     64\u001b[39m         \u001b[38;5;66;03m# self.lib.dlclose(self.lib)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m charmm_lib = \u001b[43mCharmmLib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCHARMM_LIB_DIR\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m charmm = charmm_lib.lib\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mmml/pycharmm/lib.py:48\u001b[39m, in \u001b[36mCharmmLib.__init__\u001b[39m\u001b[34m(self, charmm_lib_dir)\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28mself\u001b[39m.charmm_lib_name += \u001b[33m'\u001b[39m\u001b[33m.dll\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28mself\u001b[39m.lib = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_charmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28mself\u001b[39m.dlclose = ctypes.CDLL(\u001b[38;5;28;01mNone\u001b[39;00m).dlclose  \u001b[38;5;66;03m# does not work\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mself\u001b[39m.dlclose.argtypes = [ctypes.c_void_p]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mmml/pycharmm/lib.py:58\u001b[39m, in \u001b[36mCharmmLib.init_charmm\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minit_charmm\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     \u001b[38;5;28mself\u001b[39m.lib = \u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcharmm_lib_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m.lib.init_charmm()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/mmml-full/lib/python3.12/ctypes/__init__.py:379\u001b[39m, in \u001b[36mCDLL.__init__\u001b[39m\u001b[34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28mself\u001b[39m._FuncPtr = _FuncPtr\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    381\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = handle\n",
      "\u001b[31mOSError\u001b[39m: /scicore/home/meuwly/boitti0000/mmml/setup/charmm/libcharmm.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "# Import required modules (following run_sim.py structure)\n",
    "from mmml.cli.base import (\n",
    "    load_model_parameters,\n",
    "    resolve_checkpoint_paths,\n",
    "    setup_ase_imports,\n",
    "    setup_mmml_imports,\n",
    ")\n",
    "from mmml.pycharmmInterface import import_pycharmm\n",
    "import pycharmm\n",
    "import pycharmm.ic as ic\n",
    "import pycharmm.psf as psf\n",
    "import pycharmm.energy as energy\n",
    "from mmml.pycharmmInterface.mmml_calculator import setup_calculator, CutoffParameters\n",
    "from mmml.physnetjax.physnetjax.data.data import prepare_datasets\n",
    "from mmml.physnetjax.physnetjax.data.batches import prepare_batches_jit\n",
    "from mmml.pycharmmInterface.setupBox import setup_box_generic\n",
    "from mmml.pycharmmInterface import setupRes, setupBox\n",
    "from mmml.pycharmmInterface.import_pycharmm import reset_block, coor\n",
    "from mmml.pycharmmInterface.pycharmmCommands import CLEAR_CHARMM\n",
    "\n",
    "# Setup ASE imports\n",
    "Atoms = setup_ase_imports()\n",
    "CutoffParameters, ev2kcalmol, setup_calculator, get_ase_calc = setup_mmml_imports()\n",
    "\n",
    "# Additional imports for simulation\n",
    "import ase.io as ase_io\n",
    "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution, Stationary, ZeroRotation\n",
    "from ase.md.verlet import VelocityVerlet\n",
    "import ase.optimize as ase_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# MOCK CLI ARGUMENTS (spoofing run_sim.py CLI)\n",
    "# ========================================================================\n",
    "# Create a mock args object that mimics the CLI arguments from run_sim.py\n",
    "# This allows the notebook to follow the same structure as the script\n",
    "\n",
    "class MockArgs:\n",
    "    \"\"\"Mock CLI arguments following run_sim.py structure\"\"\"\n",
    "    def __init__(self):\n",
    "        # Paths\n",
    "        self.pdbfile = None  # Will be created from valid_data if needed\n",
    "        self.checkpoint = Path(RESTART) if 'RESTART' in globals() else None\n",
    "        \n",
    "        # System parameters\n",
    "        self.n_monomers = 2\n",
    "        self.n_atoms_monomer = 10\n",
    "        self.atoms_per_monomer = 10  # Alias for compatibility\n",
    "        \n",
    "        # Calculator parameters\n",
    "        self.ml_cutoff = 4.0\n",
    "        self.mm_switch_on = 4.0\n",
    "        self.mm_cutoff = 4.0\n",
    "        self.include_mm = True\n",
    "        self.skip_ml_dimers = False\n",
    "        self.debug = False\n",
    "        \n",
    "        # MD simulation parameters\n",
    "        self.temperature = 210.0\n",
    "        self.timestep = 0.1\n",
    "        self.nsteps_jaxmd = 100_000\n",
    "        self.nsteps_ase = 10000\n",
    "        self.ensemble = \"nvt\"\n",
    "        self.heating_interval = 500\n",
    "        self.write_interval = 100\n",
    "        self.energy_catch = 0.5\n",
    "        \n",
    "        # Output\n",
    "        self.output_prefix = \"md_simulation\"\n",
    "        self.cell = None  # No PBC by default\n",
    "        \n",
    "        # Validation\n",
    "        self.validate = False\n",
    "\n",
    "# Create mock args object\n",
    "args = MockArgs()\n",
    "\n",
    "# Override with notebook-specific values if needed\n",
    "if 'ATOMS_PER_MONOMER' in globals():\n",
    "    args.n_atoms_monomer = ATOMS_PER_MONOMER\n",
    "    args.atoms_per_monomer = ATOMS_PER_MONOMER\n",
    "if 'N_MONOMERS' in globals():\n",
    "    args.n_monomers = N_MONOMERS\n",
    "\n",
    "print(f\"Mock args created:\")\n",
    "print(f\"  n_monomers: {args.n_monomers}\")\n",
    "print(f\"  n_atoms_monomer: {args.n_atoms_monomer}\")\n",
    "print(f\"  ml_cutoff: {args.ml_cutoff}\")\n",
    "print(f\"  mm_switch_on: {args.mm_switch_on}\")\n",
    "print(f\"  mm_cutoff: {args.mm_cutoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11368175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System parameters (can be overridden by args)\n",
    "ATOMS_PER_MONOMER = args.n_atoms_monomer\n",
    "N_MONOMERS = args.n_monomers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b2da6",
   "metadata": {},
   "source": [
    "# Load Data and Prepare Batches (following run_sim.py structure)\n",
    "\n",
    "This cell loads the validation data and prepares batches that will be used to initialize simulations.\n",
    "Note: The residue numbers in the PDB/PSF may need to be adjusted based on the actual system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90571cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# LOAD DATA AND PREPARE BATCHES (following run_sim.py structure)\n",
    "# ========================================================================\n",
    "\n",
    "# Initialize random key for data loading\n",
    "if 'data_key' not in globals():\n",
    "    data_key = jax.random.PRNGKey(42)\n",
    "\n",
    "# Load datasets (assuming SCICORE and data file path are defined)\n",
    "# Note: Adjust data file path as needed\n",
    "if 'SCICORE' in globals():\n",
    "    data_file = SCICORE / \"mmml/mmml/data/fixed-acetone-only_MP2_21000.npz\"\n",
    "else:\n",
    "    # Fallback: adjust path as needed\n",
    "    data_file = Path(\"/scicore/home/meuwly/boitti0000/mmml/mmml/data/fixed-acetone-only_MP2_21000.npz\")\n",
    "\n",
    "print(f\"Loading data from: {data_file}\")\n",
    "\n",
    "# Prepare datasets\n",
    "train_data, valid_data = prepare_datasets(\n",
    "    data_key, \n",
    "    10500,  # num_train\n",
    "    10500,  # num_valid\n",
    "    [data_file], \n",
    "    natoms=ATOMS_PER_MONOMER * N_MONOMERS\n",
    ")\n",
    "\n",
    "# Prepare batches for validation data (used to initialize simulations)\n",
    "valid_batches = prepare_batches_jit(data_key, valid_data, 1, num_atoms=ATOMS_PER_MONOMER * N_MONOMERS)\n",
    "# train_batches = prepare_batches_jit(data_key, train_data, 1, num_atoms=ATOMS_PER_MONOMER * N_MONOMERS)\n",
    "\n",
    "print(f\"Loaded {len(valid_data['R'])} validation samples\")\n",
    "print(f\"Prepared {len(valid_batches)} validation batches\")\n",
    "print(f\"Each batch contains {len(valid_batches[0]['R'])} atoms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa53722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional utility imports (if needed)\n",
    "from ase.visualize.plot import plot_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10117af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional PyCHARMM imports (already imported in cell 3, but kept for reference)\n",
    "from mmml.pycharmmInterface import setupRes, setupBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9430ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# LOAD MODEL AND SETUP CALCULATOR (following run_sim.py structure)\n",
    "# ========================================================================\n",
    "uid = \"test-84aa02d9-e329-46c4-b12c-f55e6c9a2f94\"\n",
    "SCICORE = Path('/scicore/home/meuwly/boitti0000/')\n",
    "RESTART=str(SCICORE / \"ckpts\" / f\"{uid}\" / \"epoch-5450\" / \"json_checkpoint\")\n",
    "\n",
    "# ========================================================================\n",
    "# JSON-BASED CHECKPOINT LOADER (no orbax/pickle required)\n",
    "# ========================================================================\n",
    "def load_model_parameters_json(epoch_dir, natoms, use_orbax=False):\n",
    "    \"\"\"\n",
    "    Load model parameters from checkpoint using JSON (no orbax/pickle required).\n",
    "    \n",
    "    This function tries to load checkpoints from JSON files first, then falls back\n",
    "    to pickle if needed. JSON is preferred for portability.\n",
    "    \n",
    "    Args:\n",
    "        epoch_dir: Path to checkpoint epoch directory\n",
    "        natoms: Number of atoms\n",
    "        use_orbax: If True, try orbax first (default: False)\n",
    "    \n",
    "    Returns:\n",
    "        params, model: Model parameters and model instance\n",
    "    \"\"\"\n",
    "    from mmml.physnetjax.physnetjax.models.model import EF\n",
    "    import json\n",
    "    import pickle\n",
    "    \n",
    "    epoch_dir = Path(epoch_dir)\n",
    "    \n",
    "    # Try orbax first if requested\n",
    "    if use_orbax:\n",
    "        try:\n",
    "            from mmml.physnetjax.physnetjax.restart.restart import get_params_model\n",
    "            params, model = get_params_model(str(epoch_dir), natoms=natoms)\n",
    "            if model is not None:\n",
    "                print(\"✓ Loaded checkpoint using orbax\")\n",
    "                return params, model\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: orbax loading failed: {e}\")\n",
    "            print(\"Falling back to JSON/pickle-based loading...\")\n",
    "    \n",
    "    # Helper function to convert JSON-serialized arrays back to JAX arrays\n",
    "    def json_to_jax(obj):\n",
    "        \"\"\"Recursively convert JSON lists to JAX arrays.\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: json_to_jax(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            # Check if it's a nested list (array)\n",
    "            if len(obj) > 0 and isinstance(obj[0], (list, int, float)):\n",
    "                arr = jnp.array(obj)\n",
    "                return arr\n",
    "            else:\n",
    "                return [json_to_jax(item) for item in obj]\n",
    "        elif isinstance(obj, (int, float)):\n",
    "            return obj\n",
    "        else:\n",
    "            return obj\n",
    "    \n",
    "    # Try JSON-based loading first (preferred)\n",
    "    json_candidates = [\n",
    "        epoch_dir / \"params.json\",\n",
    "        epoch_dir / \"best_params.json\",\n",
    "        epoch_dir / \"checkpoint.json\",\n",
    "        epoch_dir / \"final_params.json\",\n",
    "    ]\n",
    "    \n",
    "    params = None\n",
    "    params_source = None\n",
    "    \n",
    "    # Try JSON files first\n",
    "    for json_path in json_candidates:\n",
    "        if json_path.exists():\n",
    "            print(f\"Loading parameters from JSON: {json_path}\")\n",
    "            try:\n",
    "                with open(json_path, 'r') as f:\n",
    "                    checkpoint_data = json.load(f)\n",
    "                \n",
    "                # Extract params\n",
    "                if isinstance(checkpoint_data, dict):\n",
    "                    params_data = checkpoint_data.get('params') or checkpoint_data.get('ema_params') or checkpoint_data\n",
    "                else:\n",
    "                    params_data = checkpoint_data\n",
    "                \n",
    "                # Convert JSON arrays back to JAX arrays\n",
    "                params = json_to_jax(params_data)\n",
    "                params_source = \"json\"\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"  Failed to load from {json_path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Fall back to pickle if JSON not found\n",
    "    if params is None:\n",
    "        pickle_candidates = [\n",
    "            epoch_dir / \"params.pkl\",\n",
    "            epoch_dir / \"best_params.pkl\",\n",
    "            epoch_dir / \"checkpoint.pkl\",\n",
    "            epoch_dir / \"final_params.pkl\",\n",
    "        ]\n",
    "        \n",
    "        for pkl_path in pickle_candidates:\n",
    "            if pkl_path.exists():\n",
    "                print(f\"Loading parameters from pickle: {pkl_path}\")\n",
    "                with open(pkl_path, 'rb') as f:\n",
    "                    checkpoint_data = pickle.load(f)\n",
    "                \n",
    "                # Extract params\n",
    "                if isinstance(checkpoint_data, dict):\n",
    "                    params = checkpoint_data.get('params') or checkpoint_data.get('ema_params') or checkpoint_data\n",
    "                else:\n",
    "                    params = checkpoint_data\n",
    "                params_source = \"pickle\"\n",
    "                break\n",
    "    \n",
    "    if params is None:\n",
    "        all_candidates = [str(p) for p in json_candidates + [\n",
    "            epoch_dir / \"params.pkl\",\n",
    "            epoch_dir / \"best_params.pkl\",\n",
    "            epoch_dir / \"checkpoint.pkl\",\n",
    "            epoch_dir / \"final_params.pkl\",\n",
    "        ]]\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find parameters in {epoch_dir}.\\n\"\n",
    "            f\"Tried JSON: {[str(p) for p in json_candidates]}\\n\"\n",
    "            f\"Tried pickle: {[str(p) for p in pickle_candidates if p.exists()]}\\n\"\n",
    "            f\"Please ensure checkpoint files exist.\"\n",
    "        )\n",
    "    \n",
    "    # Load model config (prefer JSON)\n",
    "    config_candidates = [\n",
    "        epoch_dir / \"model_config.json\",\n",
    "        epoch_dir.parent / \"model_config.json\",\n",
    "        epoch_dir / \"model_config.pkl\",\n",
    "        epoch_dir.parent / \"model_config.pkl\",\n",
    "    ]\n",
    "    \n",
    "    model_kwargs = {}\n",
    "    for config_path in config_candidates:\n",
    "        if config_path.exists():\n",
    "            print(f\"Loading model config from: {config_path}\")\n",
    "            try:\n",
    "                if config_path.suffix == '.json':\n",
    "                    with open(config_path, 'r') as f:\n",
    "                        model_kwargs = json.load(f)\n",
    "                else:\n",
    "                    with open(config_path, 'rb') as f:\n",
    "                        model_kwargs = pickle.load(f)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Failed to load config from {config_path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # If no config found, try to extract from checkpoint directory structure\n",
    "    if not model_kwargs:\n",
    "        print(\"Warning: No model config found, using defaults\")\n",
    "        # Try to infer from directory name or use defaults\n",
    "        model_kwargs = {\n",
    "            'features': 64,\n",
    "            'cutoff': 8.0,\n",
    "            'max_degree': 2,\n",
    "            'num_iterations': 3,\n",
    "        }\n",
    "    \n",
    "    # Set natoms\n",
    "    model_kwargs['natoms'] = natoms\n",
    "    \n",
    "    # Create model\n",
    "    model = EF(**model_kwargs)\n",
    "    model.natoms = natoms\n",
    "    \n",
    "    print(f\"✓ Loaded checkpoint using {params_source} (no orbax required)\")\n",
    "    print(f\"  Model: {model}\")\n",
    "    \n",
    "    return params, model\n",
    "\n",
    "# Resolve checkpoint paths\n",
    "if args.checkpoint is not None:\n",
    "    base_ckpt_dir, epoch_dir = resolve_checkpoint_paths(args.checkpoint)\n",
    "    print(f\"Checkpoint base dir: {base_ckpt_dir}\")\n",
    "    print(f\"Checkpoint epoch dir: {epoch_dir}\")\n",
    "else:\n",
    "    # Fallback if RESTART is defined\n",
    "    if 'RESTART' in globals():\n",
    "        base_ckpt_dir = Path(RESTART)\n",
    "        epoch_dir = base_ckpt_dir\n",
    "    else:\n",
    "        raise ValueError(\"Checkpoint path must be provided via args.checkpoint or RESTART variable\")\n",
    "\n",
    "# Load model parameters (using JSON-based loader to avoid orbax/pickle requirement)\n",
    "natoms = ATOMS_PER_MONOMER * N_MONOMERS\n",
    "\n",
    "# Try JSON-based loading first (preferred, no orbax/pickle required)\n",
    "try:\n",
    "    params, model = load_model_parameters_json(epoch_dir, natoms, use_orbax=False)\n",
    "    print(f\"Model loaded using JSON/pickle: {model}\")\n",
    "except Exception as e:\n",
    "    print(f\"JSON/pickle-based loading failed: {e}\")\n",
    "    print(\"Trying orbax-based loading (requires GPU environment)...\")\n",
    "    try:\n",
    "        params, model = load_model_parameters(epoch_dir, natoms)\n",
    "        model.natoms = natoms\n",
    "        print(f\"Model loaded using orbax: {model}\")\n",
    "    except Exception as e2:\n",
    "        raise RuntimeError(\n",
    "            f\"Failed to load model with all methods:\\n\"\n",
    "            f\"  JSON/pickle: {e}\\n\"\n",
    "            f\"  Orbax: {e2}\\n\"\n",
    "            f\"Make sure checkpoint files exist in {epoch_dir}\\n\"\n",
    "            f\"Preferred format: JSON files (params.json, model_config.json)\"\n",
    "        )\n",
    "\n",
    "# Setup calculator factory (following run_sim.py)\n",
    "calculator_factory = setup_calculator(\n",
    "    ATOMS_PER_MONOMER=args.n_atoms_monomer,\n",
    "    N_MONOMERS=args.n_monomers,\n",
    "    ml_cutoff_distance=args.ml_cutoff,\n",
    "    mm_switch_on=args.mm_switch_on,\n",
    "    mm_cutoff=args.mm_cutoff,\n",
    "    doML=True,\n",
    "    doMM=args.include_mm,\n",
    "    doML_dimer=not args.skip_ml_dimers,\n",
    "    debug=args.debug,\n",
    "    model_restart_path=base_ckpt_dir,\n",
    "    MAX_ATOMS_PER_SYSTEM=natoms,\n",
    "    ml_energy_conversion_factor=1,\n",
    "    ml_force_conversion_factor=1,\n",
    "    cell=args.cell,\n",
    ")\n",
    "\n",
    "# Create cutoff parameters\n",
    "CUTOFF_PARAMS = CutoffParameters(\n",
    "    ml_cutoff=args.ml_cutoff,\n",
    "    mm_switch_on=args.mm_switch_on,\n",
    "    mm_cutoff=args.mm_cutoff,\n",
    ")\n",
    "print(f\"Cutoff parameters: {CUTOFF_PARAMS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f0d9e",
   "metadata": {},
   "source": [
    "## Fit Lennard-Jones Parameters to Training Data\n",
    "\n",
    "Before running simulations, we can optimize the LJ parameters (epsilon and sigma scaling factors) to better match the training dataset. This fits only the MM part of the hybrid potential.\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f027e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# IMPORT OPTIMIZATION FUNCTIONS FROM UTILITY MODULE\n",
    "# ========================================================================\n",
    "# All optimization functions have been moved to mmml.utils.hybrid_optimization\n",
    "# Import them here for use in the notebook\n",
    "\n",
    "from mmml.utils.hybrid_optimization import (\n",
    "    extract_lj_parameters_from_calculator,\n",
    "    fit_hybrid_potential_to_training_data_jax,\n",
    "    fit_lj_parameters_to_training_data_jax,\n",
    ")\n",
    "\n",
    "extract_lj_parameters_from_calculator?\n",
    "fit_hybrid_potential_to_training_data_jax?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db3360-6763-4c0e-8456-a3a0cae5f3f3",
   "metadata": {},
   "source": [
    "# Initialize Simulations from valid_data Batches\n",
    "\n",
    "This section initializes simulations using positions and atomic numbers from `valid_data` batches.\n",
    "Each batch can be used to create an ASE Atoms object and run a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7be65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# SETUP Pycharmm SYSTEM FIRST (required before MM contributions)\n",
    "# ========================================================================\n",
    "# IMPORTANT: PyCHARMM system must be initialized BEFORE creating calculators\n",
    "# that use MM contributions, otherwise charges won't be available\n",
    "#\n",
    "# This generates residues in PyCHARMM and builds the structure.\n",
    "# The atom ordering from PyCHARMM will be used to reorder valid_data batch atoms.\n",
    "\n",
    "# Clear CHARMM state\n",
    "CLEAR_CHARMM()\n",
    "reset_block()\n",
    "\n",
    "                                                                                                                                                                                                    # Generate residues in PyCHARMM\n",
    "# For N_MONOMERS=2, we generate \"ACO ACO\" (two acetone molecules)\n",
    "# Adjust the residue string based on N_MONOMERS and your system\n",
    "residue_string = \" \".join([\"ACO\"] * N_MONOMERS)\n",
    "print(f\"Generating {N_MONOMERS} residues: {residue_string}\")\n",
    "\n",
    "try:\n",
    "    # Generate residues (this creates the PSF structure)\n",
    "    setupRes.generate_residue(residue_string)\n",
    "    print(\"Residues generated successfully\")\n",
    "    \n",
    "    # Build the structure using internal coordinates\n",
    "    ic.build()\n",
    "    print(\"Structure built using internal coordinates\")\n",
    "    \n",
    "    # Show coordinates\n",
    "    coor.show()\n",
    "    \n",
    "    # Get PyCHARMM atom ordering information\n",
    "    # This will be used to reorder valid_data batch atoms\n",
    "    pycharmm_atypes = np.array(psf.get_atype())[:N_MONOMERS * ATOMS_PER_MONOMER]\n",
    "    pycharmm_resids = np.array(psf.get_res())[:N_MONOMERS * ATOMS_PER_MONOMER]\n",
    "    pycharmm_iac = np.array(psf.get_iac())[:N_MONOMERS * ATOMS_PER_MONOMER]\n",
    "    \n",
    "    print(f\"PyCHARMM atom types: {pycharmm_atypes}\")\n",
    "    print(f\"PyCHARMM residue IDs: {pycharmm_resids}\")\n",
    "    print(f\"PyCHARMM has {len(pycharmm_atypes)} atoms\")\n",
    "    \n",
    "    # View PyCHARMM state\n",
    "    mmml.pycharmmInterface.import_pycharmm.view_pycharmm_state()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not initialize PyCHARMM system: {e}\")\n",
    "    print(\"You may need to adjust residue names/numbers\")\n",
    "    print(\"MM contributions will be disabled if PyCHARMM is not initialized\")\n",
    "    if args.include_mm:\n",
    "        print(\"Setting include_mm=False since PyCHARMM initialization failed\")\n",
    "        args.include_mm = False\n",
    "    pycharmm_atypes = None\n",
    "    pycharmm_resids = None\n",
    "    pycharmm_iac = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8dd6e-a1a2-431e-8a1f-8ee2c4a66104",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmml.pycharmmInterface.import_pycharmm.view_pycharmm_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358e851f-dbd3-4b4b-92d8-3b1322e48f02",
   "metadata": {},
   "source": [
    "# Setup PyCHARMM System (REQUIRED before MM contributions)\n",
    "\n",
    "**IMPORTANT**: The PyCHARMM system must be initialized BEFORE creating calculators that use MM contributions. \n",
    "\n",
    "This cell:\n",
    "1. Generates residues using `setupRes.generate_residue()` (e.g., \"ACO ACO\" for two acetone molecules)\n",
    "2. Builds the structure using `ic.build()`\n",
    "3. Gets the atom ordering from PyCHARMM\n",
    "\n",
    "**Note on atom reordering**: The atoms from `valid_data` batches may need to be reordered to match PyCHARMM's atom ordering. \n",
    "The `reorder_atoms_to_match_pycharmm()` function handles this, but you may need to customize it based on your system.\n",
    "\n",
    "- Residue names (e.g., \"ACO\" for acetone) must match your system\n",
    "- The number of residues should match `N_MONOMERS`\n",
    "- If PyCHARMM initialization fails, MM contributions will be automatically disabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2600b4-b631-45d4-ac2d-ee35413e4969",
   "metadata": {},
   "source": [
    "# Initialize Multiple Simulations from valid_data Batches\n",
    "\n",
    "This cell demonstrates how to initialize multiple simulations from different batches.\n",
    "Each simulation can be run independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aba5343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmml.utils.simulation_utils import (\n",
    "    reorder_atoms_to_match_pycharmm,\n",
    "    initialize_simulation_from_batch,\n",
    "    initialize_multiple_simulations,\n",
    ")\n",
    "# initialize_simulation_from_batch?\n",
    "# Initialize first simulation from batch 0\n",
    "# atoms, hybrid_calc = initialize_simulation_from_batch(valid_batches[0], calculator_factory, CUTOFF_PARAMS, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee68fda-f64d-4cca-b6fa-c17e394cbdde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Extract base LJ parameters (do this once, after calculator_factory is created)\n",
    "lj_params = extract_lj_parameters_from_calculator(ATOMS_PER_MONOMER=10, N_MONOMERS=2 )\n",
    "lj_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d325010-bed8-4349-9653-4da4fd0c1924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# MODE 1: Optimize LJ parameters only\n",
    "# ========================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"MODE 1: Optimizing LJ parameters only\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "result_lj = fit_hybrid_potential_to_training_data_jax(\n",
    "    train_batches=train_batches,\n",
    "    base_calculator_factory=calculator_factory,\n",
    "    model=model,\n",
    "    model_params=params,\n",
    "    atc_epsilons=lj_params[\"atc_epsilons\"],\n",
    "    atc_rmins=lj_params[\"atc_rmins\"],\n",
    "    atc_qs=lj_params[\"atc_qs\"],\n",
    "    at_codes=lj_params[\"at_codes\"],\n",
    "    pair_idx_atom_atom=lj_params[\"pair_idx_atom_atom\"],\n",
    "    cutoff_params=CUTOFF_PARAMS,  # Optional\n",
    "    args=args,  # Optional\n",
    "    optimize_mode=\"lj_only\",\n",
    "    n_samples=20,\n",
    "    energy_weight=1.0,\n",
    "    force_weight=1.0,\n",
    "    learning_rate=0.01,\n",
    "    n_iterations=100,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "opt_ep_scale_lj = result_lj[\"ep_scale\"]\n",
    "opt_sig_scale_lj = result_lj[\"sig_scale\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960711b-f792-4ad4-89c7-7925deeae614",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ep_scale_lj, opt_sig_scale_lj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd79fcd-5678-4a59-8351-d00cd42dad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================================================\n",
    "# # MODE 2: Optimize ML parameters only\n",
    "# # ========================================================================\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"MODE 2: Optimizing ML parameters only\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# result_ml = fit_hybrid_potential_to_training_data_jax(\n",
    "#     train_batches=train_batches,\n",
    "#     base_calculator_factory=calculator_factory,\n",
    "#     model=model,\n",
    "#     model_params=params,\n",
    "#     atc_epsilons=lj_params[\"atc_epsilons\"],\n",
    "#     atc_rmins=lj_params[\"atc_rmins\"],\n",
    "#     atc_qs=lj_params[\"atc_qs\"],\n",
    "#     at_codes=lj_params[\"at_codes\"],\n",
    "#     pair_idx_atom_atom=lj_params[\"pair_idx_atom_atom\"],\n",
    "#     optimize_mode=\"ml_only\",\n",
    "#     n_samples=20,\n",
    "#     energy_weight=1.0,\n",
    "#     force_weight=1.0,\n",
    "#     learning_rate=0.001,  # Lower LR for ML params\n",
    "#     n_iterations=100,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# opt_ml_params = result_ml[\"ml_params\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa1681-74fd-4053-bdaf-ee537c9f0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================================================\n",
    "# # MODE 3: Optimize both ML and LJ parameters together\n",
    "# # ========================================================================\n",
    "# print(\"\\n\" + \"=\" * 60)\n",
    "# print(\"MODE 3: Optimizing both ML and LJ parameters together\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# result_both = fit_hybrid_potential_to_training_data_jax(\n",
    "#     train_batches=train_batches,\n",
    "#     base_calculator_factory=calculator_factory,\n",
    "#     model=model,\n",
    "#     model_params=params,\n",
    "#     atc_epsilons=lj_params[\"atc_epsilons\"],\n",
    "#     atc_rmins=lj_params[\"atc_rmins\"],\n",
    "#     atc_qs=lj_params[\"atc_qs\"],\n",
    "#     at_codes=lj_params[\"at_codes\"],\n",
    "#     pair_idx_atom_atom=lj_params[\"pair_idx_atom_atom\"],\n",
    "#     optimize_mode=\"both\",\n",
    "#     n_samples=20,\n",
    "#     energy_weight=1.0,\n",
    "#     force_weight=1.0,\n",
    "#     learning_rate=0.01,\n",
    "#     n_iterations=100,\n",
    "#     verbose=True\n",
    "# )\n",
    "\n",
    "# opt_ml_params_both = result_both[\"ml_params\"]\n",
    "# opt_ep_scale_both = result_both[\"ep_scale\"]\n",
    "# opt_sig_scale_both = result_both[\"sig_scale\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04762708-b18b-480e-bec4-14bac6186540",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fit_hybrid_potential_to_training_data_jax(\n",
    "    train_batches=train_batches,\n",
    "    base_calculator_factory=calculator_factory,\n",
    "    model=model,\n",
    "    model_params=params,\n",
    "    atc_epsilons=lj_params[\"atc_epsilons\"],\n",
    "    atc_rmins=lj_params[\"atc_rmins\"],\n",
    "    atc_qs=lj_params[\"atc_qs\"],\n",
    "    at_codes=lj_params[\"at_codes\"],\n",
    "    pair_idx_atom_atom=lj_params[\"pair_idx_atom_atom\"],\n",
    "    cutoff_params=CUTOFF_PARAMS,\n",
    "    optimize_mode=\"cutoff_only\",\n",
    "    initial_ml_cutoff=2.0,  # optional\n",
    "    initial_mm_switch_on=5.0,  # optional\n",
    "    initial_mm_cutoff=1.0,  # optional\n",
    "    n_samples=20,\n",
    "    learning_rate=0.01,\n",
    "    n_iterations=100,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85757c4-420a-4849-93b7-209c1bc36506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================================================\n",
    "# # Use optimized parameters in subsequent calculations\n",
    "# # ========================================================================\n",
    "# # For LJ-only optimization:\n",
    "from mmml.utils.hybrid_optimization import expand_scaling_parameters_to_full_set\n",
    "# Expand to full parameter set\n",
    "full_ep_scale, full_sig_scale = expand_scaling_parameters_to_full_set(\n",
    "   opt_ep_scale_lj, opt_sig_scale_lj, lj_params\n",
    ")  # Shape: (163,) - all types\n",
    "\n",
    "\n",
    "calculator_factory_lj_optimized = setup_calculator(\n",
    "    ATOMS_PER_MONOMER=args.n_atoms_monomer,\n",
    "    N_MONOMERS=args.n_monomers,\n",
    "    ml_cutoff_distance=args.ml_cutoff,\n",
    "    mm_switch_on=args.mm_switch_on,\n",
    "    mm_cutoff=args.mm_cutoff,\n",
    "    doML=True,\n",
    "    doMM=args.include_mm,\n",
    "    doML_dimer=not args.skip_ml_dimers,\n",
    "    debug=args.debug,\n",
    "    model_restart_path=base_ckpt_dir,\n",
    "    MAX_ATOMS_PER_SYSTEM=natoms,\n",
    "    ml_energy_conversion_factor=1,\n",
    "    ml_force_conversion_factor=1,\n",
    "    cell=args.cell,\n",
    "    ep_scale=np.array(full_ep_scale),\n",
    "    sig_scale=np.array(full_sig_scale),\n",
    ")\n",
    "\n",
    "# # For ML-only optimization, you would need to save and reload the model\n",
    "# # with the optimized parameters (not shown here, but similar to checkpoint saving)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1fd14-6a2f-4805-9ff3-1f66d8b67d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmml.utils.simulation_utils import (\n",
    "    reorder_atoms_to_match_pycharmm,\n",
    "    initialize_simulation_from_batch,\n",
    "    initialize_multiple_simulations,\n",
    ")\n",
    "# initialize_simulation_from_batch?\n",
    "# Initialize first simulation from batch 0\n",
    "atoms, hybrid_calc = initialize_simulation_from_batch(valid_batches[0], calculator_factory_lj_optimized, CUTOFF_PARAMS, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d6f40-0a5f-4778-a417-1344de98cc58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e2b6c-598e-4903-ade8-2190e344e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_multiple_simulations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize multiple simulations\n",
    "# Adjust n_simulations as needed\n",
    "simulations = initialize_multiple_simulations(valid_batches[:2], calculator_factory_lj_optimized, CUTOFF_PARAMS, args)\n",
    "print(f\"\\nInitialized {len(simulations)} simulations from valid_data batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c267b4",
   "metadata": {},
   "source": [
    "# Example: Run a Simple Energy Calculation\n",
    "\n",
    "This demonstrates how to use the initialized simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # ========================================================================\n",
    "# EXAMPLE: RUN ENERGY CALCULATIONS\n",
    "# ========================================================================\n",
    "\n",
    "# Example: Calculate energy for the first simulation\n",
    "if len(simulations) > 0:\n",
    "    atoms_example, calc_example = simulations[0]\n",
    "    energy = atoms_example.get_potential_energy()\n",
    "    forces = atoms_example.get_forces()\n",
    "    print(f\"Example simulation energy: {energy:.6f} eV\")\n",
    "    print(f\"Example simulation forces shape: {forces.shape}\")\n",
    "    print(f\"Max force magnitude: {np.abs(forces).max():.6f} eV/Å\")\n",
    "else:\n",
    "    print(\"No simulations initialized. Check batch data and system parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67dccc-3610-442a-8be6-40acef3901b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.visualize import view\n",
    "view(atoms_example, viewer=\"x3d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e58856-1d84-4ade-bace-b2f45053ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c02ec6-4438-4354-bc16-60a79bef72b7",
   "metadata": {},
   "source": [
    "# Next Steps: Running MD Simulations\n",
    "\n",
    "To run MD simulations following `run_sim.py`, you can:\n",
    "1. Use the `minimize_structure` function from run_sim.py\n",
    "2. Use the `run_ase_md` function for ASE-based MD\n",
    "3. Use JAX-MD for more advanced simulations\n",
    "\n",
    "See `run_sim.py` for complete MD simulation setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff70ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# HELPER FUNCTIONS (from run_sim.py)\n",
    "# ========================================================================\n",
    "# These functions can be copied from run_sim.py for running MD simulations\n",
    "\n",
    "def minimize_structure(atoms, run_index=0, nsteps=60, fmax=0.0006, charmm=False, calculator=None):\n",
    "    \"\"\"\n",
    "    Minimize structure using BFGS optimizer (from run_sim.py)\n",
    "    \n",
    "    Args:\n",
    "        atoms: ASE Atoms object (must have calculator set, or provide calculator)\n",
    "        run_index: Index for trajectory file naming\n",
    "        nsteps: Maximum number of optimization steps\n",
    "        fmax: Force convergence criterion\n",
    "        charmm: If True, run CHARMM minimization first\n",
    "        calculator: Optional calculator to set if atoms doesn't have one\n",
    "    \"\"\"\n",
    "    # Ensure calculator is set\n",
    "    if atoms.calc is None:\n",
    "        if calculator is not None:\n",
    "            atoms.calc = calculator\n",
    "        else:\n",
    "            # Try to create calculator from atoms\n",
    "            Z = atoms.get_atomic_numbers()\n",
    "            R = atoms.get_positions()\n",
    "            try:\n",
    "                calc, _ = calculator_factory(\n",
    "                    atomic_numbers=Z,\n",
    "                    atomic_positions=R,\n",
    "                    n_monomers=args.n_monomers,\n",
    "                    cutoff_params=CUTOFF_PARAMS,\n",
    "                    doML=True,\n",
    "                    doMM=args.include_mm,\n",
    "                    doML_dimer=not args.skip_ml_dimers,\n",
    "                    backprop=True,\n",
    "                    debug=args.debug,\n",
    "                    energy_conversion_factor=1,\n",
    "                    force_conversion_factor=1,\n",
    "                )\n",
    "                atoms.calc = calc\n",
    "                print(\"  Created calculator for minimization\")\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Cannot minimize: atoms has no calculator and cannot create one: {e}\")\n",
    "    \n",
    "    if charmm:\n",
    "        pycharmm.minimize.run_abnr(nstep=1000, tolenr=1e-6, tolgrd=1e-6)\n",
    "        pycharmm.lingo.charmm_script(\"ENER\")\n",
    "        pycharmm.energy.show()\n",
    "        atoms.set_positions(coor.get_positions())\n",
    "\n",
    "    traj = ase_io.Trajectory(f'bfgs_{run_index}_{args.output_prefix}_minimized.traj', 'w')\n",
    "    print(\"Minimizing structure with hybrid calculator\")\n",
    "    print(f\"Running BFGS for {nsteps} steps\")\n",
    "    print(f\"Running BFGS with fmax: {fmax}\")\n",
    "    _ = ase_opt.BFGS(atoms, trajectory=traj).run(fmax=fmax, steps=nsteps)\n",
    "    # Sync with PyCHARMM\n",
    "    import pandas as pd\n",
    "    xyz = pd.DataFrame(atoms.get_positions(), columns=[\"x\", \"y\", \"z\"])\n",
    "    coor.set_positions(xyz)\n",
    "    traj.write(atoms)\n",
    "    traj.close()\n",
    "    return atoms\n",
    "\n",
    "# Example: Minimize the first simulation\n",
    "if len(simulations) > 0:\n",
    "    # Get atoms and calculator from the simulation\n",
    "    atoms_to_minimize, calc_to_minimize = simulations[0]\n",
    "    # Create a copy but preserve the calculator\n",
    "    atoms_to_minimize = atoms_to_minimize.copy()\n",
    "    atoms_to_minimize.calc = calc_to_minimize  # Ensure calculator is set\n",
    "    print(\"Running minimization...\")\n",
    "    print(\"Note: Calculator is preserved from the initialized simulation\")\n",
    "    # Uncomment to run minimization:\n",
    "    # atoms_minimized = minimize_structure(atoms_to_minimize, run_index=0, nsteps=100, fmax=0.0006)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75311f",
   "metadata": {},
   "source": [
    "# Notes on Residue Numbers and Atom Ordering\n",
    "\n",
    "When setting up PyCHARMM simulations:\n",
    "\n",
    "**Residue Setup:**\n",
    "- Use `setupRes.generate_residue(\"ACO ACO\")` to generate residues (for 2 acetone molecules)\n",
    "- Use `ic.build()` to build the structure\n",
    "- The number of residues should match `N_MONOMERS`\n",
    "\n",
    "**Atom Ordering:**\n",
    "- PyCHARMM has a specific atom ordering based on residue and atom type\n",
    "- The `valid_data` batch atoms **must be reordered** to match PyCHARMM's ordering\n",
    "- The `reorder_atoms_to_match_pycharmm()` function tries different orderings and selects the one that **minimizes CHARMM internal energy** (`energy.get_term_by_name(\"INTE\")`)\n",
    "- Common swaps tested: indices 0↔3, 10↔13, and combinations\n",
    "- The function automatically finds the best ordering by energy minimization\n",
    "\n",
    "**To customize reordering:**\n",
    "1. Add more swap patterns to the `candidate_orderings` list in `reorder_atoms_to_match_pycharmm()`\n",
    "2. The function will automatically test all candidates and select the one with minimum INTE energy\n",
    "3. Example swaps: `fix_idxs[0] = _fix_idxs[3]; fix_idxs[3] = _fix_idxs[0]` (swap 0↔3)\n",
    "4. The energy-based selection ensures the correct ordering is found automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4bc23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# SUMMARY\n",
    "# ========================================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"Simulation Setup Complete\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Number of simulations initialized: {len(simulations)}\")\n",
    "print(f\"Number of atoms per simulation: {ATOMS_PER_MONOMER * N_MONOMERS}\")\n",
    "print(f\"Number of monomers: {N_MONOMERS}\")\n",
    "print(f\"Atoms per monomer: {ATOMS_PER_MONOMER}\")\n",
    "print(f\"ML cutoff: {args.ml_cutoff} Å\")\n",
    "print(f\"MM switch on: {args.mm_switch_on} Å\")\n",
    "print(f\"MM cutoff: {args.mm_cutoff} Å\")\n",
    "print(f\"Valid data batches available: {len(valid_batches)}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTo run MD simulations, use the helper functions or refer to run_sim.py\")\n",
    "print(\"Note: Residue numbers may need adjustment based on your system\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b866507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8595b560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf9486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1337a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095e87ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fe25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10af74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = valid_batches[0][\"R\"]\n",
    "Z = valid_batches[0][\"Z\"]\n",
    "R,Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeaeb21-1bbf-4fe1-a6c3-9c24638370d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba84f3-3dd6-4fc2-a895-7f7be4248234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1244fe0-5b95-41f5-ae1c-0409187cc454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
