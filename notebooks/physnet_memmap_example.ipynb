{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PhysNet Training: Energies and Forces with Memmap Data\n",
        "\n",
        "Train PhysNet on large datasets using memory-mapped data loading.\n",
        "\n",
        "**Hardware**: A100 GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import e3x\n",
        "from mmml.data.packed_memmap_loader import PackedMemmapLoader, split_loader\n",
        "from mmml.physnetjax.physnetjax.models.model import EF\n",
        "from mmml.physnetjax.physnetjax.training.trainstep import train_step\n",
        "from mmml.physnetjax.physnetjax.training.evalstep import eval_step\n",
        "from mmml.physnetjax.physnetjax.training.optimizer import get_optimizer\n",
        "\n",
        "print(f\"JAX devices: {jax.devices()}\")\n",
        "print(f\"Default backend: {jax.default_backend()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data path\n",
        "DATA_PATH = \"openqdc_packed_memmap\"  # Change to your data path\n",
        "\n",
        "# Training parameters\n",
        "BATCH_SIZE = 64        # A100 can handle large batches\n",
        "NUM_ATOMS = 60         # Max atoms per molecule\n",
        "NUM_EPOCHS = 10        # Adjust as needed\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# Model parameters\n",
        "FEATURES = 128\n",
        "NUM_ITERATIONS = 3\n",
        "CUTOFF = 5.0\n",
        "\n",
        "# Loss weights\n",
        "ENERGY_WEIGHT = 1.0\n",
        "FORCES_WEIGHT = 52.91  # kcal/mol conversion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create loader\n",
        "loader = PackedMemmapLoader(\n",
        "    path=DATA_PATH,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    bucket_size=8192,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "print(f\"Total molecules: {loader.N}\")\n",
        "print(f\"Max atoms: {loader.n_atoms.max()}\")\n",
        "print(f\"Min atoms: {loader.n_atoms.min()}\")\n",
        "print(f\"Mean atoms: {loader.n_atoms.mean():.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into train/validation\n",
        "train_loader, valid_loader = split_loader(loader, train_fraction=0.9, seed=42)\n",
        "\n",
        "print(f\"Training molecules: {train_loader.N}\")\n",
        "print(f\"Validation molecules: {valid_loader.N}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = EF(\n",
        "    features=FEATURES,\n",
        "    max_degree=2,\n",
        "    num_iterations=NUM_ITERATIONS,\n",
        "    num_basis_functions=16,\n",
        "    cutoff=CUTOFF,\n",
        "    max_atomic_number=118,\n",
        "    charges=False,\n",
        "    natoms=NUM_ATOMS,\n",
        "    n_res=3,\n",
        "    zbl=True,\n",
        ")\n",
        "\n",
        "print(\"Model created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "key = jax.random.PRNGKey(42)\n",
        "key, init_key = jax.random.split(key)\n",
        "\n",
        "# Get sample batch for initialization\n",
        "sample_batch = next(train_loader.batches(num_atoms=NUM_ATOMS))\n",
        "dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(NUM_ATOMS)\n",
        "\n",
        "params = model.init(\n",
        "    init_key,\n",
        "    atomic_numbers=sample_batch[\"Z\"][0],\n",
        "    positions=sample_batch[\"R\"][0],\n",
        "    dst_idx=dst_idx,\n",
        "    src_idx=src_idx,\n",
        ")\n",
        "\n",
        "n_params = sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
        "print(f\"Model initialized: {n_params:,} parameters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer, transform, schedule_fn, _ = get_optimizer(\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    schedule_fn=None,\n",
        "    optimizer=None,\n",
        "    transform=None,\n",
        ")\n",
        "\n",
        "ema_params = params\n",
        "opt_state = optimizer.init(params)\n",
        "transform_state = transform.init(params)\n",
        "\n",
        "print(\"Optimizer ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Starting training...\\\\n\")\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Train\n",
        "    train_loss = 0.0\n",
        "    train_e_mae = 0.0\n",
        "    train_f_mae = 0.0\n",
        "    \n",
        "    for i, batch in enumerate(train_loader.batches(num_atoms=NUM_ATOMS)):\n",
        "        batch_size = int(batch[\"Z\"].shape[0])\n",
        "        \n",
        "        # Flatten batch arrays (model expects flattened)\n",
        "        batch[\"Z\"] = batch[\"Z\"].reshape(-1)\n",
        "        batch[\"R\"] = batch[\"R\"].reshape(-1, 3)\n",
        "        batch[\"F\"] = batch[\"F\"].reshape(-1, 3)\n",
        "        \n",
        "        # Add masks that train_step expects\n",
        "        batch[\"atom_mask\"] = (batch[\"Z\"] > 0).astype(jnp.float32)\n",
        "        batch[\"batch_mask\"] = jnp.ones_like(batch[\"dst_idx\"], dtype=jnp.float32)\n",
        "        \n",
        "        (\n",
        "            params,\n",
        "            ema_params,\n",
        "            opt_state,\n",
        "            transform_state,\n",
        "            loss,\n",
        "            energy_mae,\n",
        "            forces_mae,\n",
        "            _,\n",
        "        ) = train_step(\n",
        "            model_apply=model.apply,\n",
        "            optimizer_update=optimizer.update,\n",
        "            transform_state=transform_state,\n",
        "            batch=batch,\n",
        "            batch_size=batch_size,\n",
        "            energy_weight=ENERGY_WEIGHT,\n",
        "            forces_weight=FORCES_WEIGHT,\n",
        "            dipole_weight=0.0,\n",
        "            charges_weight=0.0,\n",
        "            opt_state=opt_state,\n",
        "            doCharges=False,\n",
        "            params=params,\n",
        "            ema_params=ema_params,\n",
        "            debug=False,\n",
        "        )\n",
        "        \n",
        "        train_loss += (loss - train_loss) / (i + 1)\n",
        "        train_e_mae += (energy_mae - train_e_mae) / (i + 1)\n",
        "        train_f_mae += (forces_mae - train_f_mae) / (i + 1)\n",
        "    \n",
        "    # Validate\n",
        "    valid_loss = 0.0\n",
        "    valid_e_mae = 0.0\n",
        "    valid_f_mae = 0.0\n",
        "    \n",
        "    for i, batch in enumerate(valid_loader.batches(num_atoms=NUM_ATOMS)):\n",
        "        batch_size = int(batch[\"Z\"].shape[0])\n",
        "        \n",
        "        # Flatten batch arrays (model expects flattened)\n",
        "        batch[\"Z\"] = batch[\"Z\"].reshape(-1)\n",
        "        batch[\"R\"] = batch[\"R\"].reshape(-1, 3)\n",
        "        batch[\"F\"] = batch[\"F\"].reshape(-1, 3)\n",
        "        \n",
        "        # Add masks for eval_step\n",
        "        batch[\"atom_mask\"] = (batch[\"Z\"] > 0).astype(jnp.float32)\n",
        "        batch[\"batch_mask\"] = jnp.ones_like(batch[\"dst_idx\"], dtype=jnp.float32)\n",
        "        \n",
        "        loss, energy_mae, forces_mae, _ = eval_step(\n",
        "            model_apply=model.apply,\n",
        "            batch=batch,\n",
        "            batch_size=batch_size,\n",
        "            energy_weight=ENERGY_WEIGHT,\n",
        "            forces_weight=FORCES_WEIGHT,\n",
        "            dipole_weight=0.0,\n",
        "            charges_weight=0.0,\n",
        "            charges=False,\n",
        "            params=ema_params,\n",
        "        )\n",
        "        \n",
        "        valid_loss += (loss - valid_loss) / (i + 1)\n",
        "        valid_e_mae += (energy_mae - valid_e_mae) / (i + 1)\n",
        "        valid_f_mae += (forces_mae - valid_f_mae) / (i + 1)\n",
        "    \n",
        "    # Print results\n",
        "    print(f\"Epoch {epoch}/{NUM_EPOCHS}:\")\n",
        "    print(f\"  Train: Loss={train_loss:.6f}, E_MAE={train_e_mae:.6f}, F_MAE={train_f_mae:.6f}\")\n",
        "    print(f\"  Valid: Loss={valid_loss:.6f}, E_MAE={valid_e_mae:.6f}, F_MAE={valid_f_mae:.6f}\")\n",
        "\n",
        "print(\"\\\\nTraining complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a test batch\n",
        "test_batch = next(valid_loader.batches(num_atoms=NUM_ATOMS))\n",
        "batch_size = int(test_batch[\"Z\"].shape[0])\n",
        "\n",
        "# Flatten arrays\n",
        "test_batch[\"Z\"] = test_batch[\"Z\"].reshape(-1)\n",
        "test_batch[\"R\"] = test_batch[\"R\"].reshape(-1, 3)\n",
        "test_batch[\"F\"] = test_batch[\"F\"].reshape(-1, 3)\n",
        "\n",
        "# Predict energies and forces\n",
        "outputs = model.apply(\n",
        "    ema_params,\n",
        "    atomic_numbers=test_batch[\"Z\"],\n",
        "    positions=test_batch[\"R\"],\n",
        "    dst_idx=test_batch[\"dst_idx\"],\n",
        "    src_idx=test_batch[\"src_idx\"],\n",
        "    batch_segments=test_batch[\"batch_segments\"],\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "print(f\"Predicted energies: {outputs['energy']}\")\n",
        "print(f\"True energies: {test_batch['E']}\")\n",
        "print(f\"\\\\nEnergy MAE: {jnp.mean(jnp.abs(outputs['energy'] - test_batch['E'])):.6f} kcal/mol\")\n",
        "\n",
        "# Check forces\n",
        "mask = (test_batch[\"Z\"] > 0).astype(jnp.float32)\n",
        "forces_pred = outputs['forces']\n",
        "forces_true = test_batch[\"F\"]\n",
        "forces_diff = (forces_pred - forces_true) * mask[:, None]\n",
        "\n",
        "print(f\"Forces MAE: {jnp.mean(jnp.abs(forces_diff)):.6f} kcal/mol/Ã…\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
