# Cube Data (ESP, Density) Support

Guide for working with cube file data (electrostatic potential, electron density, etc.) in the MMML pipeline.

## Overview

The Molpro XML parser now automatically detects and loads cube file data referenced in XML output files. This includes:
- **ESP (Electrostatic Potential)**: For charge models and non-bonded interactions
- **Electron Density**: For density-based analysis
- **Molecular Orbitals**: Individual orbital cube data
- **Custom properties**: Any cube-format data generated by Molpro

## Generating Cube Files in Molpro

To generate ESP or density cubes in your Molpro calculation:

```molpro
! In your Molpro input file
hf
cube,esp,file=esp.cube         ! Generate ESP cube
cube,density,file=density.cube ! Generate density cube
```

Molpro will create the cube files and reference them in the XML output.

## XML to NPZ Conversion

The converter automatically detects and includes cube data:

```bash
# Standard conversion - automatically includes cube data
python -m mmml.cli xml2npz calculations/*.xml -o dataset.npz --validate

# The cube files must be in the same directory as the XML files
```

## NPZ Data Format

Cube data is stored with the following keys:

```python
import numpy as np

data = np.load('dataset.npz', allow_pickle=True)

# For ESP cube:
esp_values = data['cube_esp']           # (n_structures, n_grid_points)
esp_origin = data['cube_esp_origin']    # (n_structures, 3)
esp_dims = data['cube_esp_dimensions']  # (n_structures, 3) - nx, ny, nz
esp_axes = data['cube_esp_axes']        # (n_structures, 9) - 3x3 matrix flattened

# For density cube:
density_values = data['cube_density']
density_origin = data['cube_density_origin']
# ... etc
```

## Python API Usage

### Parsing XML with Cube Data

```python
from mmml.parse_molpro import read_molpro_xml

# Load XML with cube data
data = read_molpro_xml('output.xml', load_cubes=True)

# Access cube data
if 'esp' in data.cube_data:
    esp_cube = data.cube_data['esp']
    
    print(f"ESP cube shape: {esp_cube['values'].shape}")
    print(f"Origin: {esp_cube['origin']}")
    print(f"Dimensions: {esp_cube['dimensions']}")
    print(f"Grid axes:\n{esp_cube['axes']}")
    print(f"Source file: {esp_cube['file']}")

if 'density' in data.cube_data:
    density_cube = data.cube_data['density']
    print(f"Density cube shape: {density_cube['values'].shape}")
```

### Converting to NPZ

```python
from mmml.data import batch_convert_xml

# Convert with cube data
batch_convert_xml(
    xml_files=['calc1.xml', 'calc2.xml'],
    output_file='dataset.npz',
    padding_atoms=60,
    include_variables=True
)

# Cube data is automatically included if present
```

### Loading and Using Cube Data

```python
import numpy as np

# Load NPZ file
data = np.load('dataset.npz', allow_pickle=True)

# Check metadata for cube information
metadata = data['metadata'][0]
if 'cube_files' in metadata:
    print("Available cubes:", list(metadata['cube_files'].keys()))
    
    for cube_name, cube_info in metadata['cube_files'].items():
        print(f"\n{cube_name}:")
        print(f"  Type: {cube_info['type']}")
        print(f"  Method: {cube_info['method']}")
        print(f"  File: {cube_info['file']}")

# Reconstruct 3D cube from flattened data
if 'cube_esp' in data:
    esp_flat = data['cube_esp'][0]  # First structure
    esp_dims = data['cube_esp_dimensions'][0].astype(int)
    
    # Reshape to 3D grid
    esp_3d = esp_flat.reshape(esp_dims)
    
    print(f"ESP 3D cube shape: {esp_3d.shape}")
    
    # Get grid parameters
    origin = data['cube_esp_origin'][0]
    axes = data['cube_esp_axes'][0].reshape(3, 3)
    
    print(f"Origin: {origin}")
    print(f"Axes:\n{axes}")
```

## Cube File Format

The parser supports standard Gaussian cube file format:

```
Comment line 1
Comment line 2
N_atoms  X_origin  Y_origin  Z_origin
Nx      X_step    0         0
Ny      0         Y_step    0
Nz      0         0         Z_step
Atom1_Z  Atom1_charge  Atom1_x  Atom1_y  Atom1_z
...
data_1  data_2  data_3  ...
```

## Use Cases

### 1. Training ESP-based Models (DCMNet)

```python
from mmml.data import load_npz

# Load dataset with ESP
data = load_npz('dataset.npz')

# Check if ESP is available
if 'cube_esp' in data:
    esp_values = data['cube_esp']
    esp_grid_info = {
        'origin': data['cube_esp_origin'],
        'dimensions': data['cube_esp_dimensions'],
        'axes': data['cube_esp_axes']
    }
    
    # Prepare for DCMNet training
    # ... (model-specific preparation)
```

### 2. Visualizing Electron Density

```python
import matplotlib.pyplot as plt
import numpy as np

# Load data
data = np.load('dataset.npz', allow_pickle=True)

if 'cube_density' in data:
    density = data['cube_density'][0]  # First structure
    dims = data['cube_density_dimensions'][0].astype(int)
    
    # Reshape to 3D
    density_3d = density.reshape(dims)
    
    # Plot a 2D slice
    z_slice = density_3d.shape[2] // 2
    plt.figure(figsize=(8, 6))
    plt.imshow(density_3d[:, :, z_slice], cmap='viridis')
    plt.colorbar(label='Electron Density')
    plt.title(f'Density Slice (z={z_slice})')
    plt.show()
```

### 3. Computing Properties from Cubes

```python
import numpy as np

def compute_esp_at_points(esp_cube, origin, axes, dimensions, points):
    """
    Interpolate ESP values at arbitrary points.
    
    Args:
        esp_cube: 3D ESP grid
        origin: Grid origin (x, y, z)
        axes: 3x3 matrix of grid vectors
        dimensions: Grid dimensions (nx, ny, nz)
        points: Points to evaluate (n_points, 3)
    
    Returns:
        ESP values at points
    """
    from scipy.interpolate import RegularGridInterpolator
    
    # Create grid coordinates
    nx, ny, nz = dimensions
    x = np.arange(nx)
    y = np.arange(ny)
    z = np.arange(nz)
    
    # Create interpolator
    interpolator = RegularGridInterpolator(
        (x, y, z), esp_cube, 
        method='linear', bounds_error=False, fill_value=0.0
    )
    
    # Convert points to grid coordinates
    # (simplified - assumes orthogonal grid)
    step_x = np.linalg.norm(axes[0, :]) / nx
    step_y = np.linalg.norm(axes[1, :]) / ny
    step_z = np.linalg.norm(axes[2, :]) / nz
    
    grid_points = (points - origin) / np.array([step_x, step_y, step_z])
    
    # Interpolate
    esp_values = interpolator(grid_points)
    
    return esp_values
```

## Troubleshooting

### Cube Files Not Found

**Problem:** "Warning: Could not read cube file..."

**Solutions:**
1. Ensure cube files are in the same directory as XML files
2. Check file permissions
3. Verify file paths in XML match actual file names

### Missing Cube Data

**Problem:** No cube data in NPZ file

**Check:**
```python
from mmml.parse_molpro import read_molpro_xml

data = read_molpro_xml('output.xml', load_cubes=True)
print(f"Cubes found: {len(data.cube_data)}")
print(f"Cube names: {list(data.cube_data.keys())}")
```

### Large File Sizes

**Problem:** NPZ files are very large

Cube files can be large (millions of grid points). Consider:
1. Reducing grid resolution in Molpro
2. Storing only necessary cubes
3. Using compression (automatic with `np.savez_compressed`)

## Advanced: Custom Cube Processing

```python
from mmml.parse_molpro.read_molden import MolproXMLParser

# Manual parsing with custom cube handling
parser = MolproXMLParser('output.xml')

# Parse cube metadata only (don't load files)
cube_metadata = parser.parse_cubes(xml_dir=None)

# Or load cubes from custom directory
cube_data = parser.parse_cubes(xml_dir='/path/to/cubes/')
```

## Best Practices

1. **File Organization**: Keep XML and cube files in the same directory
2. **Naming Convention**: Use descriptive names for cube files (esp.cube, density.cube)
3. **Documentation**: Store cube metadata in JSON summaries:
   ```bash
   python -m mmml.cli xml2npz *.xml -o data.npz --summary summary.json
   ```
4. **Validation**: Always validate after conversion to ensure data integrity
5. **Compression**: Use compressed NPZ format (default) for large datasets

## See Also

- [Data Pipeline Guide](data_pipeline.md)
- [NPZ Schema](npz_schema.md)
- [DCMNet Documentation](../examples/dcm/README.md)

